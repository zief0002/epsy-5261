[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "An Introduction to Data Analysis and Randomization Methods",
    "section": "",
    "text": "Foreword\nThis work in progress is ultimately going to be the primarily textbook resource for EPSY 5261 students. (Note: If you want to contribute to this, create a Pull Request or send me an email.) Also, feel free to offer criticism, suggestion, and feedback. You can either open an issue on the book‚Äôs github page or send me an email directly."
  },
  {
    "objectID": "index.html#colophon",
    "href": "index.html#colophon",
    "title": "An Introduction to Data Analysis and Randomization Methods",
    "section": "Colophon",
    "text": "Colophon\nArtwork by @allison_horst\nIcon and note ideas and prototypes by Desir√©e De Leon.\nThe book is typeset using Crimson Text for the body font, Raleway for the headings and Sue Ellen Francisco for the title. The color palette was generated using coolors.co.\nStatistical Computing\n\nLaptop icon made by Tomas Knop from www.flaticon.com\nDirectory icon made by Darius Dan from www.flaticon.com\nBrain icon made by Aranagraphics from www.flaticon.com\nInternet icon made by Freepik from www.flaticon.com"
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "An Introduction to Data Analysis and Randomization Methods",
    "section": "License",
    "text": "License\nThis work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License."
  },
  {
    "objectID": "01-00-statistical-computation.html",
    "href": "01-00-statistical-computation.html",
    "title": "Statistical Computation",
    "section": "",
    "text": "The first set of tools we will discuss will be related to statistical computation. Although there are many computational tools for statistical analysis, the first tools we will add to your computational toolkit is R. R is a free software environment for statistical computing and graphics. It can be installed on a variety of operating systems, including the MacOS, Windows, and UNIX platforms. To really make use of the computational power of R, we are also going to introduce you to RStudio, an open-source front-end1 to R.\nThe initial chapters of this document will address:\n\nInstalling R and RStudio;\nGetting started with R‚Äôs computational syntax;\nWrangling data using functions from the dplyr package; and\nVisualizing data using functions from the ggplot2 package.\n\n\n\n\n\n\n\nSpecifically, RStudio is branded as an ‚Äúintegrated development environment (IDE) [that] includes a console, syntax-highlighting editor that supports direct code execution, as well as tools for plotting, history, debugging and workspace management.‚Äù‚Ü©Ô∏é"
  },
  {
    "objectID": "01-01-r-and-rstudio-installation.html#installing-r",
    "href": "01-01-r-and-rstudio-installation.html#installing-r",
    "title": "1¬† R and RStudio: Installation and Setup",
    "section": "1.1 Installing R",
    "text": "1.1 Installing R\nTo install R, navigate your web browser to:\n\nhttps://www.r-project.org/\n\nThen,\n\nClick the CRAN link under Download on the left-hand side of the page.\nSelect a mirror site. These should all be the same, but I tend to choose the Iowa State University link under USA.1\nIn the Download and Install R box, choose the binary that matches the operating system (OS) for your computer.\n\nThis is where the installation directions diverge depending on your OS.\nMac Instructions\nSo long as you are running MacOS 10.13 or higher just click the first link for the PKG, which will download the installer for the most current version of R (4.1.1 as of August 16, 2021). Once the download completes, open the installer and follow the directions to install R on your computer.\nIf you are running an older version of MacOS, you will have to install an older version of R. You can find these links under the Binaries for legacy OS X systems heading further down the install page. Click the appropriate PKG link for R your version of MacOS. Once the download completes, open the installer and follow the directions to install R on your computer.\nIf you are unsure which version of the MacOS is running on your computer, select About this Mac from the Apple menu in your toolbar.\nWindows Instructions\nClick the link that says Install R for the first time (or click base; they go to the same place). Then click the Download R 4.1.1 for Windows link, which will download the installer for the most current version of R (4.0.2 as of July 24, 2020). Once the download completes, open the installer and follow the directions to install R on your computer.\nLinux Instructions\nIf you are running Linux, you should know how to install things on your computer. üòÉ"
  },
  {
    "objectID": "01-01-r-and-rstudio-installation.html#installing-rstudio-desktop",
    "href": "01-01-r-and-rstudio-installation.html#installing-rstudio-desktop",
    "title": "1¬† R and RStudio: Installation and Setup",
    "section": "1.2 Installing RStudio Desktop",
    "text": "1.2 Installing RStudio Desktop\nAfter you have installed R, you next need to install RStudio Desktop. To do this, navigate your web browser to:\n\nhttps://rstudio.com/products/rstudio/download/\n\nThen,\n\nSelect the blue Download button under the free, open-source version of RStudio Desktop.\nSelect the installer associated with your computer‚Äôs OS.\nOnce the download completes, open the installer and follow the directions to install RStudio Desktop on your computer."
  },
  {
    "objectID": "01-01-r-and-rstudio-installation.html#checking-that-things-worked",
    "href": "01-01-r-and-rstudio-installation.html#checking-that-things-worked",
    "title": "1¬† R and RStudio: Installation and Setup",
    "section": "1.3 Checking that Things Worked",
    "text": "1.3 Checking that Things Worked\nFrom your Applications or Programs folder, open RStudio. If you have successfully downloaded both programs, this should open the application and you should see a message indicating that you are using ‚ÄúR version 4.1.1‚Äù (or whichever version of R you installed) in the console pane.\n\n\n\n\n\nOnce you open RStudio, you should see a message indicating that you are using R version 4.1.1 (or whichever version of R you installed) in the console pane. Here the console pane is on the left-side, but it may be in a different location for you. Your RStudio may also have a white background rather than the black background seen here."
  },
  {
    "objectID": "01-01-r-and-rstudio-installation.html#customizing-rstudio",
    "href": "01-01-r-and-rstudio-installation.html#customizing-rstudio",
    "title": "1¬† R and RStudio: Installation and Setup",
    "section": "1.4 Customizing RStudio",
    "text": "1.4 Customizing RStudio\nWhile the information in this section is not crucial for making things work, it is useful to get RStudio looking good and setting some default settings. Open the Tools > Options menu (Windows) or RStudio > Preferences (Mac).\n\n\n\n\n\nThe RStudio options/preferences menu has many settings to customize RStudio.\n\n\n\n\n\nIn the General > Basic settings, change the option on Save workspace to .Rdata on exit to be ‚ÄúNever‚Äù. Click the ‚ÄúApply‚Äù button.\nIn the Appearance settings, customize the look of RStudio to something aesthetically appealing to you. When you are finished, click the ‚ÄúApply‚Äù button.\nThere are also options you can set in the Accessibility settings if you use a screen reader. If you change anything, don‚Äôt forget to click the ‚ÄúApply‚Äù button.\n\nWhen you are finished customizing RStudio, click the ‚ÄúOK‚Äù button."
  },
  {
    "objectID": "01-01-r-and-rstudio-installation.html#install-rtoolscommand-line-tools",
    "href": "01-01-r-and-rstudio-installation.html#install-rtoolscommand-line-tools",
    "title": "1¬† R and RStudio: Installation and Setup",
    "section": "1.5 Install Rtools/Command Line Tools",
    "text": "1.5 Install Rtools/Command Line Tools\nYou may need to install some additional functionality to your system in order to get certain packages to install or load properly. On a Windows machine, you might need to install Rtools. Mac users might need to add the Command Line Tools. These tools also allow you to write and compile your own R packages. RStudio has well written instructions for adding these tools at: https://support.rstudio.com/hc/en-us/articles/200486498-Package-Development-Prerequisites."
  },
  {
    "objectID": "02-00-data.html",
    "href": "02-00-data.html",
    "title": "Data",
    "section": "",
    "text": "The American Statistical Association defines statistics as, ‚Äúthe science of learning from data, and of measuring, controlling and communicating uncertainty‚Äù (American Statistical Association, 2023). The methods you learn throughout this textbook, and the EPSY 5261 course, will help you to learn from data and to measure, control, and communicate about uncertainty.\nAn important learning goal of statistics is therefore to understand the vocabulary and ideas related to data. To this end, in Chapter¬†2 you will learn about the structure of data and attribute classification. You will also learn how to judge the quality of data including questions you should ask about the data. ?sec-importing-data will introduce the syntax we use to import data into R. Finally, ?sec-design will introduce how the collection of the data impacts the type of inferences and conclusions we can draw.\n\n\n\n\nAmerican Statistical Association. (2023). ASA newsroom. Website. https://www.amstat.org/asa-newsroom"
  },
  {
    "objectID": "02-01-data-structure-and-attributes.html#classifying-attributes",
    "href": "02-01-data-structure-and-attributes.html#classifying-attributes",
    "title": "2¬† Data Structure and Attribute Classification",
    "section": "2.1 Classifying Attributes",
    "text": "2.1 Classifying Attributes\nOur ultimate goal is often to analyze the data we have to learn from it. For example, in our NYT Best Seller data, we may be interested in the proportion of authors that identify as female. Or, we may want to. know how many weeks a book stays on the Best Sellers list. The type of analyses we can do, however, depend on the type of attributes we have.\nWe typically classify attributes as either categorical attributes or quantitative attributes. These classifications are based on the type of information (data) in the attribute. A categorical attribute has values that represent categorical (or qualitative) differences between the cases, whereas a quantitative attribute represents numerical (or quantitative) differences between cases. For example, in the NYT Best Seller data, title and author are categorical variables, whereas year, and total number of weeks the book was on the NYT Best Sellers list are quantitative attributes.\nTypically attributes that have numerical values are quantitative, but not always. In our data, consider the attribute that indicates whether the author identifies as a female. Although the values in the data are numeric, these numbers actually represent different categories: 0 = no (not female) and 1 = yes (female). Therefore, this attribute is actually a categorical attribute, not a quantitative attribute.\nOne check of whether anattribute is actually quantitative is whether numeric computations, such as finding an average of the attribute, can be carried out and the result makes conceptual sense. For example, we cannot compute the mean author value (it is thus a categorical attribute). If we compute the mean of the female attribute we get a result, but it does not indicate anything about the gender identity of a NYT best selling author. The mean does not make conceptual sense and thus we classify female as a categorical attribute.\n\nYour Turn\nClassify the best_rank attribute (the book‚Äôs highest rank while it was on the NYT Best Sellers list) as either categorical or quantitative. Explain.\n\nShow/Hide Solution\n\n\nThe attribute best_rank is a quantitative attribute. The data in this attribute are numeric values, and it makes conceptual sense to compute summaries such as the mean for this attribute.\n\n\n\n\n2.1.1 Further Classifications of Attributes\nWhile categorizing each attribute as categorical or quantitative is a good first step, statisticians and data analysts often go a step further and classify attributes based on their scale of measurement. This classification is based on how attributes were measured (i.e., how we assign numerals to objects of events) and what this implies about the empirical statements we can make about the constructs measured on that particular scale. The most common taxonomy for this was described by Stevens (1946) who classified four scales of measurement: nominal, ordinal, interval, or ratio (NOIR). Below we describe each of these scales of measurement:\nNominal Scale of Measurement: In nominal scales of measurement, any numerals assigned to different values would only be useful as labels, for distinguishing or organizing values. Most categorical attributes have this scale of measurement. For example, in the NYT bests sellers data, the numerical values in the gender identity attribute (female) are only useful as labels and for distinguishing authors who identify as female and authors who don‚Äôt. Because of this, only the following type of statement would be meaningful:\n\nIn the NYT bestseller data, more authors identify as female (15) than do not identify as female (10).\n\nThe only type of empirical statements we can make are comparisons of the number of cases between different labels (e.g., counts, percentages).\nOrdinal Scale of Measurement: Data measured using an ordinal scales of measurement, is still categorical. It has all the features of nominal measured data (e.g., labeling, distinguishing, organizing), but we can also rank order the values in a meaningful way. A classic example of the ordinal scale of measurement is in the 5-star review rating used on sites like Amazon. All of these statements would be meaningful:\n\nThere are more 4-star reviews than 5-star reviews (comparison of counts).\nA review of 3 stars is better than a review of 2 stars (rank ordering).\n\nWith this scale of measurement, it is reasonable to not only provide counts of the different values (e.g., the number of 5-star reviews), but now because there is a rank ordering, we can also make empirical statements related to the rank ordering of the measured construct based on the numeral values. In nominal level data, these latter types of statements are not appropriate since the values for the labels are arbitrary. For example, authors with a gender identity of female were assigned a 1 and others were assigned a 0. This is arbitrary in that authors identifying as female could just as easily have been assigned a value of 0 and those that didn‚Äôt identify as female a value of 1. This implies that even though the numeral 1 is greater than the numeral 0, the attribute values associated with these numerals (identifying as female or not) do not have any meaningful rank order. Because of this, saying something about one identity being greater than or less than another is inappropriate.\nInterval Scale of Measurement: In interval level data, the rank order of the numbers assigned to attribute values is meaningful, similar to ordinal data. Moreover, the difference between consecutive values represents the same amount of difference on the underlying attribute. For example, consider the Fahrenheit temperature scale. All of these statements would be meaningful:\n\nThere are more 30 degrees F days than 0 degrees F days (comparison of counts).\nA day that is 10 degrees F is warmer than a day that is 9 degrees F (rank ordering).\nThe difference in temperature when you are comparing days that are 9 and 10 degrees F is the same as when you are comparing days that are 0 and 1 degrees F. (interval comparison).\n\nThe critical component is that on an interval scale, the difference in consecutive numerals has the same level of difference in the construct being measured, regardless of scale location. Again consider our 5-star rating system. The difference between a 1- and 2-star review is not the same as the difference between a 4- and 5-star review. While the numbers themselves have a constant difference, the difference in the amount of the underlying construct (satisfaction, happiness with the product, etc.) does not. With interval level scales we can compute summaries like means, standard deviations, and correlations.\nRatio Scale of Measurement: With attributes that have the ratio scale of measurement, the rank ordering of the numbers assigned to attribute values is meaningful, the differences between consecutive numerals indicates the same amount of difference in the underlying construct being measured, and ratio type statements about these differences are also meaningful. For example, the amount of snowfall is an attribute on the ratio scale of measurement. All of these statements would be meaningful:\n\nThere are more days with 0 inches of snowfall than days with 10 inches of snowfall (comparison of counts).\nA day with 8 inches of snowfall got more snow than a day with 4 inches of snowfall (rank ordering).\nThe difference in snowfall when you are comparing days with 8 inches of snowfall and 7 inches of snowfall is the same as when you are comparing days with 15 and 16 inches of snow (interval comparison).\nA day with 8 inches of snow got twice the amount of snow as a day with 4 inches of snow (ratio comparison).\n\nGoing back to our temperature scale, we cannot make these ratio type statements. For example, a day that is 60 degrees F is not twice as warm as a day that is 30 degrees F. This is because the Fahrenheit scale does not have a ‚Äútrue‚Äù zero value. (Zero degrees F does not indicate absence of temperature.) Whereas, in our snowfall attribute, a day with 0 inches of snow does indeed indicate no snow fell on that day.\nAside from the type of empirical statements we can make, the level of measurement also puts limits on the type of statistical analyses that are appropriate.\n\n\n\n\n\n\nTable¬†2.1:  The four measurement scales and the types of empirical statements and statistical summaries that are appropriate for each scale. \n  \n    \n    \n      Scale\n      Empirical Statement\n      Statistical Summaries\n    \n  \n  \n    Nominal\n\nComparison of counts\n\nCounts, percentages\n\n    Ordinal\n\nComparison of counts  Rank ordering\n\nCounts, percentages  Median, percentiles\n\n    Interval\n\nComparison of counts  Rank ordering  Interval comparisons\n\nCounts, percentages  Median, percentiles  Mean, standard deviation\n\n    Ratio\n\nComparison of counts  Rank ordering  Interval comparisons  Ratio comparisons\n\nCounts, percentages  Median, percentiles  Mean, standard deviation  Coefficient of variation"
  },
  {
    "objectID": "02-01-data-structure-and-attributes.html#how-were-the-data-generated",
    "href": "02-01-data-structure-and-attributes.html#how-were-the-data-generated",
    "title": "2¬† Data Structure and Attribute Classification",
    "section": "2.2 How Were the Data Generated?",
    "text": "2.2 How Were the Data Generated?\nAnother question that has direct implications on the methods used in data analysis is: How were the data generated or collected? Were they collected from a survey? Were they mined from the web? Were they generated as part of an experimental study? Knowing the answer to these questions also is important for the degree to which we can draw conclusions from the analysis.\nUnderstanding how the data were generated allows us to determine whether the data we have constitute a sample of cases or the entire population of cases we are interested in learning about. Importantly, whether you have a sample or the entire population depends on how you define the cases/observations you are interested in drawing conclusions about.\n\nA population includes all cases/observations of interest, whereas a. sample includes a subset of cases from the population.\n\nFor example, consider a child psychologist who wants to draw conclusions about all students at a particular school in Minnesota. To do this, she collects data from every student in that school. Since her data includes every case (student) she is interest in drawing conclusions for, her data would be a population, Now consider a second child psychologist who is interested in drawing conclusions about all students in Minnesota. This psychologist also collects data from every student in the same school as the first psychologist. This second psychologist‚Äôs data would be considered a sample since the cases they included in their data are only a subset of the cases they want to draw conclusions about.\n\nYour Turn\nIs the New York Time best sellers data a population or a sample? Explain.\n\nShow/Hide Solution\n\n\nThe New York Time best sellers data is a sample since it is only a subset of all the New York Times best selling books.\n\n\n\n\n2.2.1 Drawing Conclusions from a Sample\nIn practice, we rarely have data collected from an entire population, but we still want to use the data we have in our sample to draw conclusions about that population. Drawing conclusions about an entire population when you only have data from a subset cases is what statisticians call statistical inference.\n\n\n\n\n\nFigure¬†2.1: A sample of data is drawn from the population. Information from the sample is then analyzed and used to make a statistical inference about the population.\n\n\n\n\nThis can be a very tricky thing to do since the sample does not give us complete information about the population. As an example, consider if you wanted to figure out the average monthly living expenses for all graduate students at the University of Minnesota. To do this you collect data on the monthly living expenses for the students in your EPSY 5261 class and compute the average monthly living expense based on the data you collected and use that value as a guess for the average monthly living expenses for all graduate students at the University of Minnesota. (Note that the cases in your data (students in your EPSY 5261 class) are a subset of the population you want to draw conclusions about (all graduate students at the University of Minnesota) and thus are a sample.)\n\nSummaries computed from the population are referred to as parameters and summaries computed from a sample are referred to as statistics.\n\nIn statistical inference the statistics we compute from a sample are estimates for the population parameters that we are interested in. The word ‚Äúestimate‚Äù may have clued you in that the value of a statistic is generally not equal to the value of the parameter. In our example, the average monthly living expenses we computed based on your sample of cases is probably not the same as the average monthly living expenses for all graduate students at the University of Minnesota. This is because our sample only includes data for some (not all) of the cases.\nWe don‚Äôt expect the value of the statistic to be the same as that for the parameter we are trying to estimate, but a key question is: Is the value of the statistic a reasonable estimate of the parameter? The answer to this question can sometimes be difficult to answer. What do we mean by reasonable? In statistical analysis, there are a few ways that we consider reasonableness of an estimate. We will explore these below.\n\n\n2.2.1.1 Sampling Error: Quantifying the Amount of Uncertainty in our Sample Estimate\nOne way we consider whether an answer is reasonable is how much uncertainty we have in the estimate from our sample. Imagine if you repeated the study, but this time, you collected data on the monthly living expenses in a different section of EPSY 5261. The average computed from these data would likely be different from the average you computed from your section of EPSY 5261, and therefore your guess for the average monthly living expenses for all graduate students at the University of Minnesota would be different. This is because you would have different cases in your sample.\n\nWhen using a sample to infer about a population, our guesses or estimates vary depending on the cases in our sample. This means that when we make inferences there is always some degree of uncertainty in our estimates.\n\nThe idea that estimates from samples vary depending on the cases in your sample is well known and is referred to as sampling error. In carrying out statistical inference, we not only acknowledge that we have uncertainty in our guess from the sample data, but we also try and quantify how much uncertainty there is in that estimate. For example, do we think that the average monthly living expenses for all graduate students at the University of Minnesota is within a few dollars of our sample estimate? Or do we think that it is within a few hundred dollars of our sample estimate? By providing this estimate of the uncertainty, it lets other people know ‚Äúhow reasonable‚Äù our guess might be.\n\n\n\n\n\nFigure¬†2.2: Estimates for the mean living expense for all graduate students at the University of Minnesota will vary from sample to sample because of sampling error. In statistical inference this is expected and quantifying the amount of sampling error gives us an indication of how much uncertainty we have in our estimate.\n\n\n\n\n\n\n\n2.2.1.2 Sampling Bias: Does the Sample Represent the Population?\nA second way we consider whether an answer is reasonable is to consider whether our sample of cases is representative of the population as a whole. In our example, we are asking the question of whether the students in your section of EPSY 5261 are representative of all graduate students at the University of Minnesota when it comes to living expenses. This is a really difficult question to answer, but generally (unless you have selected your sample randomly from the population), your sample is not representative. The key here is that the sampling method (how you chose your cases) matters!\n\nWhen a sample is not randomly selected from the population we say that the sampling method is biased.\n\nA biased sampling method leads to systematically wrong answers. For example, again say you were interested in determining the average monthly living expenses for all graduate students at the University of Minnesota. This time, your sampling method is to collect data about the monthly living expenses from all the graduate students who live in a particular apartment building in Downtown Minneapolis. Would these students‚Äô living expenses be representative of all graduate students at the University of Minnesota?\nAgain, probably not. The living expenses in Downtown Minneapolis are different (generally higher) than the living expenses of students who live in Dinkytown or one of the suburbs. Because the cases in your sample all come from the same apartment building in Downtown Minneapolis, their average monthly living expense will be systematically higher than the average monthly living expenses for all graduate students at the University of Minnesota.\nWhat about our original sampling method of collecting data from each of the graduate students in your EPSY 5261 section? While these students might live in different areas, and seem more representative, this sampling method is likely still biased. Even if we have a hard time identifying how, the estimate for the average monthly living expenses based on students in EPSY 5261 is likely systematically different than the average monthly living expenses for all graduate students at the University of Minnesota. (It may be systematically too low, or too high.)\n\nThe only sampling method that is guaranteed to be unbiased (and therefore representative) is to select your sample randomly from the population.\n\n\n\n\n\n2.2.2 Random Sampling\nThere are many methods for randomly selecting a sample from the population. The simplest method that incorporates randomness into the sampling process is Simple Random Sampling. In simple random sampling each case in the population has an equal probability of being selected into the sample.1\n\nIn the discipline of statistics, there are words that we use that have very different meanings from their use in colloquial English. ‚ÄúRandom‚Äù is one of those words. In our everyday language ‚Äúrandom‚Äù might mean happenstance or unexpected. For example: It was so random that I saw Ferris Bueller at the 31 Flavors last night. In statistics, ‚Äúrandom‚Äù does not mean happenstance at all. Random sampling is quite formal in ensuring that cases have a specified probability of being selected into the sample.\n\nOne of the most compelling and useful results in statistics is that a simple random sample is representative of the population, and moreover that even small samples that are selected with this method can be representative of very large populations. This is powerful!\nBut, it can sometimes be very difficult to draw a simple random sample in practice. For one thing, it requires that you have a list of all the cases in the population (called a sampling frame). This allows you to make sure that everyone in the population has the same probability of being selected. While it might be possible to obtain a list of all graduate students enrolled at the University of Minnesota, it is another thing to obtain a list of all people living in Minnesota. Or even a list of people living in Dinkytown. Depending on your population of interest you may not be able to get a simple random sample.2\n\nYour Turn\nWhat is the sampling method for the New York Time best sellers data. Based on this method, are the estimates of the population parameters we compute from these data going to be biased or unbiased?\n\nShow/Hide Solution\n\n\nThe New York Time best sellers data was sampled using simple random sampling. Because the sampling method employed randomness, the estimates we compute from the data are unbiased estimates of the population parameters."
  },
  {
    "objectID": "02-01-data-structure-and-attributes.html#summary",
    "href": "02-01-data-structure-and-attributes.html#summary",
    "title": "2¬† Data Structure and Attribute Classification",
    "section": "2.3 Summary",
    "text": "2.3 Summary\nEvery time you encounter data, you should identify the cases and attributes in the data. Understanding the cases, especially in relation to the cases you want to draw conclusions about, helps you identify whether you have a sample, or the entire population. Classifying the attributes helps you think about the type of analysis you can undertake. If your data are a sample (rather than a population), you also need to ask how they were collected. Were they collected using randomness in the sampling method? Or is the sampling method used to collect the data biased?"
  },
  {
    "objectID": "02-01-data-structure-and-attributes.html#references",
    "href": "02-01-data-structure-and-attributes.html#references",
    "title": "2¬† Data Structure and Attribute Classification",
    "section": "2.4 References",
    "text": "2.4 References\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGould, R., & Ryan, C. (2013). Introductory statistics: Exploring the world through data. Pearson.\n\n\nPruett, J. (2021). NYT hardcover fiction bestsellers. Post45 Data Collective, V1. https://doi.org/https://doi.org/10.18737/CNJV1733p4520220211\n\n\nStevens, S. S. (1946). On the theory of scales of measurement. Science, 103(2684), 677‚Äì680."
  },
  {
    "objectID": "03-00-exploring-and-describing-data.html#goals-for-summarization-and-visualization",
    "href": "03-00-exploring-and-describing-data.html#goals-for-summarization-and-visualization",
    "title": "Summarizing and Visualizing Data",
    "section": "Goals for Summarization and Visualization",
    "text": "Goals for Summarization and Visualization\nData scientists and statisticians visualize data and compute numerical summaries to explore and understand data. In addition to visualizing distributions of data, it is common to also summarize certain feature of the data using numbers. (For example, the mean is one summarization of a distribution of quantitative data.) Together visualizing and summarizing data can help analysts identify features in the data such as typical or extreme observations, and also describe and explore the variation in the data. Data exploration is an important first step in any statistical analysis."
  },
  {
    "objectID": "03-00-exploring-and-describing-data.html#college-scorecard-data",
    "href": "03-00-exploring-and-describing-data.html#college-scorecard-data",
    "title": "Summarizing and Visualizing Data",
    "section": "College Scorecard Data",
    "text": "College Scorecard Data\nThroughout the chapters in this section we will use the College Scorecard data to illustrate the methods of data exploration. These data were collected and made available by the U.S. Department of Education (DOE). The DOE publishes data on institutions of higher education in their College Scorecard to facilitate transparency and provide information for interested stakeholders (e.g., parents, students, educators). A subset of this data is provided in the file college-scorecard.csv.\n\nCSV File\nData Codebook"
  },
  {
    "objectID": "03-01-categorical-attributes.html#hypothetical-example-pet-ownership",
    "href": "03-01-categorical-attributes.html#hypothetical-example-pet-ownership",
    "title": "3¬† Summarizing and Visualizing Categorical Attributes",
    "section": "3.1 Hypothetical Example: Pet Ownership",
    "text": "3.1 Hypothetical Example: Pet Ownership\nImagine you have surveyed 10 pet owners about the type of pet they own.1 The data you collected is shown in Figure¬†3.1.\n\n\n\n\n\nFigure¬†3.1: Data collected from 10 pet owners about the type of pet the own.\n\n\n\n\nOur goal in exploratory analysis is to describe the data. One way of describing the data is to list all of the values. For example here we could say the sample included a turtle, a fish, a cat, a dog, another dog, another fish, another cat, another cat, another cat, and another dog. While this is an accurate description, it isn‚Äôt very generalizable. (Imagine trying to describe the data from 1000 pet owners or 10,000 pet owners!)\n\n\n3.1.1 Numerically Summarizing Categorical Attributes\nA more natural way to describe these data is to summarize them by providing counts of each pet type. For example, describing our sample data using counts:\n\n1 of the pet owners sampled owned a turtle,\n2 of the pet pet owners sampled owned a fish,\n3 of the pet pet owners sampled owned a dog, and\n4 of the pet pet owners sampled owned a cat.\n\nSummarizing each type of pet owned by reporting counts of them is a much more natural way of describing the data. (This is also useful when the sample size is much larger.)\nAnother summary that could be used to describe this sample is to give the proportion of each type of pet owned. To compute the proportion, we take the count of each type of pet owned, and divide it by the total sample size.\n\\[\n\\mathrm{Proportion} = \\frac{\\mathrm{Count~of~Pet~Type}}{\\mathrm{Total~Sample~Size}}\n\\]\nFor example, to compute the proportion of pet owners in our sample that owned a dog, we use:\n\\[\n\\mathrm{Proportion~of~Dogs} = \\frac{3}{10} = 0.30\n\\]\n\nProportions will always be between 0 and 1. If you add all of the proportions of each category together you will get 1, so long as values can only belong to one category.\n\nDescribing our sample data using proportions:\n\n0.10 of the pet owners sampled owned a turtle,\n0.20 of the pet pet owners sampled owned a fish,\n0.30 of the pet pet owners sampled owned a dog, and\n0.40 of the pet pet owners sampled owned a cat.\n\nThe count and proportion values are often reported in a table, especially if there are more than a couple values in the categorical attribute. Table¬†3.1 is an example table indicating the counts and proportions of values in our hypothetical pet example.\n\n\n\n\n\n  \n  Table¬†3.1:  Counts and proportions of pet owners who own each type of pet. \n  \n    \n    \n      Pet\n      Count\n      Proportion\n    \n  \n  \n    \n3\n0.30\n    \n4\n0.40\n    \n2\n0.20\n    \n1\n0.10\n  \n  \n  \n\n\n\n\n\n\n\n\n3.1.2 Visualizing Categorical Attributes\nTo visualize categorical attributes we typically use a bar chart. Figure¬†3.2 shows a bar chart of the pet data.\n\n\n\n\n\nFigure¬†3.2: Bar chart indicating the counts of each type of pet owned.\n\n\n\n\nA bar chart (also known as a bar graph) shows a bar for each category of the categorical attribute. In our example, we have four bars, one for each pet type. The height of the bar indicates the count of each category. For example, the bar for cats has a height of four on the y-axis.\nSometimes the axes in the bar chart are transposed; categories are placed on the y-axis and counts on the x axis. Also, you might see a bar chart indicating proportions rather than counts. Figure¬†3.3 shows a transposed bar chart indicating the proportion of each pet type.\n\n\n\n\n\nFigure¬†3.3: Bar chart indicating the counts of each type of pet owned. In this plot the categories are placed on the y-axis and the scale on the the x axis indicates proportions rather than counts.\n\n\n\n\n\nWhen proportions are used in a bar chart, it is coventional to extend that axis from 0 to 1 (the range of potential proportions).\n\n\n\n3.1.2.1 Bar Chart Variations\nThere are several variations on the bar chart that you may see in practice. For example, the segmented bar chart is a variation of the bar chart. This variation of the plot, which always uses proportions rather than counts, has a single bar that is split into segments‚Äîone for each category. A segmented bar chart summarizing the pet data is shown in Figure¬†3.4.\n\n\n\n\n\nFigure¬†3.4: Segmented bar chart indicating the proportion of each type of pet owned.\n\n\n\n\nAnother variation of the bar chart is the donut chart. A donut chart is simply a segmented bar chart that is presented in a circular layout. Figure¬†3.5 presents a donut chart summarizing the pet data. Because there is no axis to indicate the proportion of each category in a donut chart, it is conventional to indicate the percentages of each category in the plot. Here percentages are used rather than proportions.\n\n\n\n\n\nFigure¬†3.5: Donut chart indicating the percentage of each type of pet owned. A donut chart is simply a segmented bar chart presented in a circular layout.\n\n\n\n\n\n\n\n3.1.2.2 Pie Charts\nOne last plot used to visualize summaries of categorical dat is the pie chart. Figure¬†3.6 shows a pie chart summarizing the pet data. Unlike any of the bar charts that we have looked at, a pie chart uses the proportional area of a circle to indicate the proportion or percentage of each pet type rather than the length of a bar.\n\n\n\n\n\nFigure¬†3.6: Pie chart indicating the percentage of each type of pet owned. A pie chart uses the proportional area of a circle to indicate the proportion or percentage of each pet type.\n\n\n\n\n\nIn a pie chart, each section of the pie is determined by proportionally dividing the 360¬∞ of the circle based on the data, and then making each section have the computed angle. For example the proportion of pet owners who have a cat is 0.4, and 0.4 of 360¬∞ is 144¬∞‚Äîso the cats section has an angle of 144¬∞. While these computations and the drawing of the pie chart would be done by the computer, it has implications for interpretations. Namely, research has suggested that humans may not be as adept at making accurate comparisons involving angles and the areas of sections based on those angles. Because of this, the recommendation from the data visualization community is to use bar charts rather than pie charts when displaying summaries of categorical data."
  },
  {
    "objectID": "03-01-categorical-attributes.html#using-r-to-numerically-summarize-categorical-attributes",
    "href": "03-01-categorical-attributes.html#using-r-to-numerically-summarize-categorical-attributes",
    "title": "3¬† Summarizing and Visualizing Categorical Attributes",
    "section": "3.2 Using R to Numerically Summarize Categorical Attributes",
    "text": "3.2 Using R to Numerically Summarize Categorical Attributes\nTo illustrate how we can summarize and visualize categorical attributes using R, we will use the college-scorecard.csv data. As a reminder, we will start by loading three libraries: {tidyverse}, {ggformula}, and {mosaicCore}. Then we will import the college scorecard data using the read_csv() function and assign the data into an object called colleges. Finally, we view the data to make sure it read in properly.\n\nlibrary(tidyverse)\nlibrary(ggformula)\nlibrary(mosaicCore)\n\n# Import data\ncolleges <- read_csv(\"https://raw.githubusercontent.com/zief0002/epsy-5261/main/data/college-scorecard.csv\")\n\n# View data\ncolleges\n\n\n\n  \n\n\n\nRecall that in these data each case in these data is an institution of higher education and there are 234 institutions in our sample. This dataset has several categorical attributes, including: state, region, type of institution, and control.\nThe first attribute we will summarize and visualize is the control variable. Looking at the data codebook we find that this attribute can take on three different values: Public, Private nonprofit, and Private for-profit. Our first task is to get institution counts for each category of control. To do this, we will use the df_stats() function. The general syntax to obtain these counts is shown below.\n\n# General syntax to counts the categories in a categorical attribute\ndf_stats( ~ attribute_name, data = data_name, counts)\n\nWe first need to identify the name of the categorical attribute. To tell df_stats() that this is an attribute, we place a tilde (~) in front of the attribute name. Then we use the data= argument to identify the data object that includes our categorical attribute. Finally, we use counts to indicate that we want to compute the category counts.\n\nIt is a good idea to learn how to read R syntax. The tilde operator indicates a special kind of expression called a formula, and can be read as ‚Äúmodel‚Äù. So the general syntax above is read as, ‚Äúmodel the attribute_name found in the data_name data by counting the categories in the attribute‚Äù.\n\nPutting this into practice to count the categories in the control attribute which is in our colleges data:\n\n# Syntax to count the categories in the control attribute\ndf_stats(~control, data = colleges, counts)\n\n\n\n  \n\n\n\nIf we were to read this syntax, ‚Äúmodel the control attribute found in the colleges data by counting the categories in the attribute‚Äù.\nBased on the counts, we find that most of the institutions of higher learning in our sample are private nonprofit institutions (n = 146). There are also several public institutions of higher learning in our sample (n = 71). Lastly, there are also a few private for-profit institutions of higher learning in our sample (n = 13).\n\nIt is common to use n or N to denote sample size. Some textbooks and authors will use N to indicate the overall sample size (e.g., in the college scorecard data, N = 234) and n to indicate the sample size of subgroups within the sample (e.g., n = 71 for public institutions). Other authors might use n to define the overall sample size (e.g., n = 234) and then use subscripts on n to denote the sample size of different groups (e.g., \\(n_{\\mathrm{Public}}=71\\)). There is not a single unified agreed upon way to denote these things.\n\nWe also might want to compute the proportions for each category of control. To do this, we can again use the function df_stats(), but instead of providing counts we will provide props.\n\n# Syntax to compute the proportion for each category in the control attribute\ndf_stats(~control, data = colleges, props)\n\n\n\n  \n\n\n\nThese proportions (which can also be turned into percentages2) tell a similar story to what the counts did. Most of the institutions in our sample are private nonprofit (63.5%) and public (30.9%) institutions. There is a smaller percentage of institutions that are private for-profit (5.7%).3 As we did with the numerical summaries of the pet data, we can include these values in a table.\n\n\n\n\n\n  \n  Table¬†3.2:  Counts and proportions of institutions of higher learning by control. \n  \n    \n    \n      Control\n      Count\n      Proportion\n    \n  \n  \n    Public\n71\n0.309\n    Private Nonprofit\n146\n0.635\n    Private For-Profit\n13\n0.057\n  \n  \n  \n\n\n\n\n\n\n\nYour Turn\nWrite the syntax to compute the counts of the region attribute.\n\nShow/Hide Solution\n\n\n\ndf_stats(~ region, data = colleges, counts)\n\n\n\n  \n\n\n\n\nWrite the syntax to compute the proportions of the region attribute.\n\nShow/Hide Solution\n\n\n\ndf_stats(~ region, data = colleges, counts)"
  },
  {
    "objectID": "03-01-categorical-attributes.html#creating-a-bar-chart-to-summarize-counts-using-r",
    "href": "03-01-categorical-attributes.html#creating-a-bar-chart-to-summarize-counts-using-r",
    "title": "3¬† Summarizing and Visualizing Categorical Attributes",
    "section": "3.3 Creating a Bar Chart to Summarize Counts using R",
    "text": "3.3 Creating a Bar Chart to Summarize Counts using R\nTo create a bar chart, we will use the gf_counts() function. This general syntax for gf_counts() is\n\n# General syntax to create a bar chart\ngf_counts(~ attribute_name, data = data_name)\n\nIn this function we indicate the name of the attribute we want to create a bar chart for with a tilde (~) precedeing the attribute name. We also give the name of the data object in the data= argument. For example, the syntax to create a bar chart summarizing the counts of the control attribute is:\n\n# Syntax to create a bar chart for the control attribute\ngf_counts(~ control, data = colleges)\n\n\n\n\nFigure¬†3.7: Bar chart summarizing the counts of the control attribute.\n\n\n\n\n\nReading the syntax: Create a bar chart by modeling the counts of the control attribute in the colleges data object.\n\nWe can make this plot nicer by changing the axes labels. For example, we might change the y-axis label to ‚ÄúCount‚Äù and the x-axis label to ‚ÄúType of Institution‚Äù. To do this we include the xlab= and ylab= arguments in the gf_counts() function. The labels we want depicted are given as text inside of quotation marks. Remember that each argument needs to be separated by a comma!\n\nAs you include additional arguments in the function, it can be useful to include each argument on different lines. This will help you troubleshoot syntax that doesn‚Äôt work.\n\n\n# Syntax to create a bar chart for the control attribute\ngf_counts( \n  ~ control, data = colleges,\n  xlab = \"Type of Institution\",\n  ylab = \"Count\"\n  )\n\n\n\n\nFigure¬†3.8: Bar chart summarizing the counts of institutions of higher learning by type.\n\n\n\n\n\nYour Turn\nWrite the syntax to create a bar chart that summarizes the counts of the region attribute.\n\nShow/Hide Solution\n\n\n\ngf_counts(~ region, data = colleges)\n\n\n\n\n\nAdd better labels to the x- and y-axis of the bar chart you just created.\n\nShow/Hide Solution\n\n\n\ngf_counts(\n  ~ region, data = colleges,\n  xlab = \"Region of the United States\",\n  ylab = \"Count\"\n  )"
  },
  {
    "objectID": "03-01-categorical-attributes.html#creating-a-bar-chart-to-summarize-proportions-using-r",
    "href": "03-01-categorical-attributes.html#creating-a-bar-chart-to-summarize-proportions-using-r",
    "title": "3¬† Summarizing and Visualizing Categorical Attributes",
    "section": "3.4 Creating a Bar Chart to Summarize Proportions using R",
    "text": "3.4 Creating a Bar Chart to Summarize Proportions using R\nTo create a bar chart that summarizes the proportion of each category (rather than counts) we can use the gf_props() function. The syntax for this function is identical to that of gf_counts(). The syntax to create a bar chart summarizing the proportion of the control attribute is:\n\n# Syntax to create a bar chart for the control attribute\ngf_props(\n  ~control, data = colleges,\n  xlab = \"Type of Institution\",\n  ylab = \"Count\"\n  )\n\n\n\n\nFigure¬†3.9: Bar chart summarizing the proportions of institutions of higher learning by type.\n\n\n\n\nYou can also create a bar chart that summarizes the percentage of each category using the gf_percents() function.\n\n# Syntax to create a bar chart for the control attribute\ngf_percents(\n  ~control, data = colleges,\n  xlab = \"Type of Institution\",\n  ylab = \"Percent\"\n  )\n\n\n\n\nFigure¬†3.10: Bar chart summarizing the percentage of institutions of higher learning by type.\n\n\n\n\n\nYour Turn\nWrite the syntax to create a bar chart that summarizes the proportions of the region attribute. Also change the axis labels on both the x- and y-axes.\n\nShow/Hide Solution\n\n\n\ngf_props(\n  ~ region, data = colleges,\n  xlab = \"Region of the United States\",\n  ylab = \"Proportion\"\n  )"
  },
  {
    "objectID": "03-01-categorical-attributes.html#creating-horizontal-bar-charts-using-r",
    "href": "03-01-categorical-attributes.html#creating-horizontal-bar-charts-using-r",
    "title": "3¬† Summarizing and Visualizing Categorical Attributes",
    "section": "3.5 Creating Horizontal Bar Charts Using R",
    "text": "3.5 Creating Horizontal Bar Charts Using R\nTo create horizontal bar charts we can use gf_countsh(), gf_propsh(), or gf_percentsh(). These functions again take the same syntax as their vertical counterparts. For example, to create a horizontal bar chart summarizing the counts of each type of institution we can use the following syntax:\n\n# Syntax to create a hirizontal bar chart for the control attribute\ngf_countsh(\n  ~control, data = colleges,\n  xlab = \"Count\",\n  ylab = \"Type of Institution\"\n  )\n\n\n\n\nFigure¬†3.11: Horizontal bar chart summarizing the number of institutions of higher learning by type.\n\n\n\n\n\nYour Turn\nWrite the syntax to create a horizontal bar chart that summarizes the percent of the region attribute. Also change the axis labels on both the x- and y-axes.\n\nShow/Hide Solution\n\n\n\ngf_percentsh(\n  ~ region, data = colleges,\n  xlab = \"Percent\",\n  ylab = \"Region of the United States\"\n  )"
  },
  {
    "objectID": "03-01-categorical-attributes.html#summary",
    "href": "03-01-categorical-attributes.html#summary",
    "title": "3¬† Summarizing and Visualizing Categorical Attributes",
    "section": "3.6 Summary",
    "text": "3.6 Summary\nThere are several R functions that are useful for summarizing categorical attributes. Table¬†4.1 shows the functions (and their descriptions) you will use to summarize and visualize categorical attributes. Note that they all have very parallel syntax.\n\n\n\n\n\n  \n  Table¬†3.3:  The functions and their descriptions to summarize and visualize categorical attributes. \n  \n    \n    \n      Function\n      Description\n    \n  \n  \n    \n      Summarize\n    \n    df_stats(~attribute, data = data_object, counts)\n\nCompute counts of a categorical attribute\n    df_stats(~attribute, data = data_object, props)\n\nCompute proportions of a categorical attribute\n    df_stats(~attribute, data = data_object, percs)\n\nCompute percentages of a categorical attribute\n    \n      Visualize\n    \n    gf_counts(~attribute, data = data_object)\n\nCreate bar chart of counts\n    gf_props(~attribute, data = data_object)\n\nCreate bar chart of proportions\n    gf_percs(~attribute, data = data_object)\n\nCreate bar chart of percentages\n    gf_countsh(~attribute, data = data_object)\n\nCreate horizontal bar chart of counts\n    gf_propsh(~attribute, data = data_object)\n\nCreate horizontal bar chart of proportions\n    gf_percsh(~attribute, data = data_object)\n\nCreate horizontal bar chart of percentages\n  \n  \n  \n\n\n\n\n\nLastly, there are several optional arguments you can include in the visualization (gf_) functions to improve the aesthetic quality of your plot. Some of these are listed in Table¬†3.4.\n\n\n\n\n\n  \n  Table¬†3.4:  Optional argumnents that can be included in the visualization (gf_) functions. \n  \n    \n    \n      Argument\n    \n  \n  \n    \n      Labels\n    \n    xlab = \"x-axis label\"\n\n    ylab = \"y-axis label\"\n\n    title = \"Title for your plot.\"\n\n    subtitle = \"Subtitle for your plot.\"\n\n    caption = \"Caption for your plot.\"\n\n    \n      Color\n    \n    fill = \"color name for bar color\"\n\n    color = \"color name for bar outlines\"\n\n  \n  \n  \n\n\n\n\n\nRemember to separate each argument with a comma if you include multiple arguments in the function."
  },
  {
    "objectID": "03-02-quantitative-attributes.html#importing-the-data",
    "href": "03-02-quantitative-attributes.html#importing-the-data",
    "title": "4¬† Summarizing and Visualizing Quantitative Attributes",
    "section": "4.1 Importing the Data",
    "text": "4.1 Importing the Data\nTo illustrate how we can summarize and visualize quantitative attributes using R, we will again use the college-scorecard.csv data. As a reminder, we will start by loading three libraries, {tidyverse}, {ggformula}, and {mosaicCore}. Then we will import the college scorecard data using the read_csv() function and assign the data into an object called colleges. Finally, we view the data to make sure it read in properly.\n\nlibrary(ggformula)\nlibrary(mosaicCore)\nlibrary(tidyverse)\n\n\n# Import data\ncolleges <- read_csv(\"https://raw.githubusercontent.com/zief0002/epsy-5261/main/data/college-scorecard.csv\")\n\n# View data\ncolleges\n\n\n\n  \n\n\n\nRecall that in these data each case in these data is an institution of higher education and there are 234 institutions in our sample. This dataset has several quantitative attributes, including: admission rate, number of undergraduate students, median debt for all students, median debt for graduates, and median earnings."
  },
  {
    "objectID": "03-02-quantitative-attributes.html#histograms",
    "href": "03-02-quantitative-attributes.html#histograms",
    "title": "4¬† Summarizing and Visualizing Quantitative Attributes",
    "section": "4.2 Histograms",
    "text": "4.2 Histograms\nThe first visualization we will examine is a histogram. We can create a histogram of the admission rates using the gf_histogram() function.1 This function takes the same general syntax as the gf_ functions you learned about in Chapter¬†3:\n\nThe first argument is a formula using the tilde operator (~) that identifies the attribute to be plotted, and\nThe second argument, data =, specifies the data object that was assigned on data import.\n\nThe syntax used to create a histogram of the admission rates is:\n\ngf_histogram(~ adm_rate, data = colleges)\n\n\n\n\nFigure¬†4.1: Histogram of admission rates for the institutions of higher learning in the sample.\n\n\n\n\n\n\n4.2.1 Interpretting Histograms\nHistograms are created by collapsing the data into bins and then counting the number of observations that fall into each bin. To show this more clearly in the figure created previously, we can color the bin lines to highlight the different bins. To do this we include an additional argument, color =, in the gf_histogram() function. We can also set the color for the bins themselves using the fill = argument. Here we color the bin lines black and set the bin color to yellow.2\n\ngf_histogram(\n  ~ adm_rate, data = colleges, \n  color = \"black\", \n  fill = \"yellow\",\n  xlab = \"Admission Rate\",\n  ylab = \"Count\"\n  )\n\n\n\n\nFigure¬†4.2: Histogram of college admission rates. Here the color of the bin lines to black and fill in the bars with yellow. Axes labels are also added to the plot.\n\n\n\n\nEach bar in a histogram represents indicates the number of cases with a range of values for the plotted variable. For example, the bar that is just to the right of 0.50, shows there are approximately 16 institutions of higher learning with admissions rates between about 0.50 and 0.54. Similar interpretations can be made for all of the other bars as well.\nOne common assumption made with a histogram is that the width of each bar covers the same range over the attribute plotted. In this histogram, there are 25 total bars, which means that the range of each is 0.04 on the admission rate scale (i.e., 25 * .04 = 1.00 which is the rtange of the entire attribute).\n\nYour Turn\nInterpret the bar that is immediately to the left of 1.00.\n\nShow/Hide Solution\n\n\nThere are approximately 12 institutions of higher learning with admissions rates between about 0.96 and 1.00.\n\n\n\n\n4.2.2 Describing the Distribution\nRather than focusing on any one bin, we typically want to describe the distribution of the attribute plotted as a whole. For example, it appears as though most institutions admit a high proportion of applicants since the bins to the right of 0.50 have higher counts than the bins that are below 0.50. (In fact, the highest bins seem to be above 0.75.) There are a few institutions, however, that are quite selective, admitting fewer than 25% of the students who apply.\nStatistically we would say that the distribution of admission rates is left-skewed. A left skewed distribution has the majority of cases on the right side of the distribution (i.e., at higher values of the attribute). In contrast, a distribution that has the majority of cases on the left side of the distribution (i.e., at lower values of the attribute) is called right-skewed. Figure¬†4.3 shows examples of both a left-skewed and right-skewed distribution.\n\n\n\n\n\n\n\n(a) Left-Skewed Distribution\n\n\n\n\n\n\n\n(b) Right-Skewed Distribution\n\n\n\n\nFigure¬†4.3: Examples of a left-skewed and right-skewed distribution.\n\n\nThe skewness of a distribution describes a characteristic that we refer to as the shape of the distribution. Some distributions are not skewed, these distributions have a symmetric shape. Figure¬†4.4 shows an example of a symmetric distribution.\n\n\n\n\n\nFigure¬†4.4: Example of a symmetric distribution."
  },
  {
    "objectID": "03-02-quantitative-attributes.html#density-plots",
    "href": "03-02-quantitative-attributes.html#density-plots",
    "title": "4¬† Summarizing and Visualizing Quantitative Attributes",
    "section": "4.3 Density plots",
    "text": "4.3 Density plots\nAnother plot that is sometimes more useful for determining the shape of the distribution for a quantitative attribute is the density plot. This plot is a smoothed out version of a histogram.\nDensity plots can be created with the gf_density() function which takes the same arguments as the other gf_ functions. Similar to these function, you can include optional arguments to color the plot and add axis labels.\nFigure¬†4.5 shows the density plot for the density plot for the admissions rate attribute plotted earlier in a histogram.\n\ngf_density(\n  ~ adm_rate, data = colleges,\n  color = \"black\", \n  fill = \"yellow\",\n  xlab = \"Admission Rate\",\n  ylab = \"Density\"\n  )\n\n\n\n\nFigure¬†4.5: Density plot of college admission rates.\n\n\n\n\nBased on the density plot, we can see that the shape of the distribution of admission rates is left-skewed.\n\nThe metric on the y-axis in a density plot is no longer counts, it is ‚Äúprobability density‚Äù, or just ‚Äúdensity‚Äù. We don‚Äôt interpret those values, but rather focus on the relative height of the curve. That is, areas of the density curve that are higher indicate more data in those areas of the attribute of interest. Places where the density curve is lower indicates areas where data occur infrequently. Density plots are interpreted similarly to a histogram in that\n\nOur interpretation of the distribution of admission rates remains that most institutions of higher learning admit a high proportion of applicants. In fact, colleges that admit around 75% of their applicants have the highest probability density, indicating this is where most of the institutions are found in the distribution. Additionally, there are just a few institutions that are have an admission rate 25% or less.\n\n\n4.3.1 More about Shape\nIn addition to the overall symmetry or direction of skewness, another aspect of shape that we should describe is the number of modes in the distribution. The distributions we have looked as so far have been unimodal, that is, they have a single mode or ‚Äúhump‚Äù in the distribution.\nOther distributions have multiple modes. For example, the distribution in Figure¬†4.6 is bimodal (it has two modes). If a distribution has more than one mode, it often indicates that there are different groups that have been mixed into the data. For example, in Figure¬†4.6 we see one mode around 180 minutes (3 hours) and another taller mode around 300 minutes (5 hours). This might indicate that there are two different groups of runners that competed in the Legacy Marathon‚Äîone smaller group that was faster (e.g., elite runners) and one larger group that was slower.\n\n\n\n\n\nFigure¬†4.6: Distribution of times for a random sample of runners who competed in the 2022 Legacy Marathon.\n\n\n\n\n\n\n\n4.3.2 Center and Variation: Two Additional Characteristics to Describe\nIn addition to the describing the shape of the distribution, there are two other characteristics of a quantitative distribution that we want to describe: the center and the variation.\nThe ‚Äúcenter‚Äù of a distribution is misleading in that it doesn‚Äôt literally mean the center of the distribution. What it really means is ‚Äútypical value‚Äù. In the distribution of admission rates presented in Figure¬†4.5, a typical admission rate might be around 0.75. This value is at the mode in the distribution.\nWe also need to describe the variation in the distribution. When estimating the variation from a density plot we typically describe the overall range of values, as well as, the range of values within which most of the data falls. In the distribution of admission rates presented in Figure¬†4.5, there are admission rates between 0 and 1, but most of the institutions of higher learning have an admission rate between 0.65 and 0.85. This could also be given as a range of values around the typical value‚Äî\\(0.75 \\pm 0.10\\)\n\nA full description of a quantitative distribution includes shape, center, and variation. Here is how we might descirbe the distribution of admission rates presented in Figure¬†4.5:\n\nThe distribution of admission rates is left-skewed. Most institutions admit a high proportion of applicants. A typical institution in the distribution admits around 75% of its applicants (\\(\\pm\\) 10%). There are, however, a few institutions that are quite selective, admitting fewer than 25% of the students who apply.\n\n\nIn a multi-modal distribution, the identification of center and variation is more difficult, since there are multiple typical values. For example, in the distribution of marathon times presented in Figure¬†4.6, there are two typical values, one around 180 minutes and another around 300 minutes. Similarly, in describing the variation we often describe a range of values around each typical value that depicts where most of the data fall. From Figure¬†4.6, most of the faster runners finished the Legacy Marathon between 160 and 190 minutes, whereas most of the slower runners finished with a time between 200 and 400 minutes.\n\nYour Turn\nCreate a density plot for the distribution of median earnings for students. Add appropriate labels to the axes.\n\nShow/Hide Solution\n\n\n\ngf_density(\n  ~ median_earnings, data = colleges,\n  color = \"black\", \n  fill = \"yellow\",\n  xlab = \"Median Earnings\",\n  ylab = \"Density\"\n  )\n\n\n\n\n\nDescribe the shape, center, and variation of this distribution and what it tells you about students‚Äô median earnings 10 years after being enrolled in college.\n\nShow/Hide Solution\n\n\nThe distribution of median earnings is right skewed. The median amount of money earned 10 years after graduation is around $50k (\\(\\pm \\$10k\\)). There are some institutions where the median earnings of students is quite high (~100k)."
  },
  {
    "objectID": "03-02-quantitative-attributes.html#numerically-summaries",
    "href": "03-02-quantitative-attributes.html#numerically-summaries",
    "title": "4¬† Summarizing and Visualizing Quantitative Attributes",
    "section": "4.4 Numerically Summaries",
    "text": "4.4 Numerically Summaries\nIn the previous examples, we estimated the typical value (center) and variation from a visualization of the distribution. If the distribution is unimodal, we can also obtain more precise values for these characteristics by computing different numerical summaries.3\n\n4.4.1 Learn More\nIn this class we will focus on the computation of these values using R and their interpretations rather than on the mathematical manipulation and formulas. Here are some links to learn more about the underlying calculations of the measures that we will focus on in this class if you are interested: mean, median, and mode, range interquartile range (IQR), standard deviation.\n\nIn describing the center of the distribution, we estimated the typical value based on the value for the ‚Äúmodal hump‚Äù in the density plot. There are two numerical values that are often computed to summarize the center of the distribution: the mean and the median.\nIn a perfectly symmetric distributions, the mean and median are the same value. In practice, they are rarely exactly the same. If the distribution is roughly symmetric, these values should be similar. In skewed distributions, the mean and median will be different. In these distributions, the mean will be further in the tail of the distribution than the median. Comparing the mean and median is another way to verify the symmetry or asymmetry of the distribution.\n\n\n\n\n\n\n\n(a) Left-Skewed Distribution\n\n\n\n\n\n\n\n(b) Symmetric Distribution\n\n\n\n\n\n\n\n(c) Right-Skewed Distribution\n\n\n\n\nFigure¬†4.7: Mean, median, and modal values in a left-skewed, symmetric, and right-skewed distribution.\n\n\nIn a symmetric distribution, any of the three center values (mean, median, or mode) are a good summarization of a typical value since they are all roughly the same. In skewed distributions, because the mean is further in the tail, it is often not a good reflection of a typical value in the distribution. Instead, the median or mode is often a better summary in these distributions.\n\n\n4.4.2 Computing Numerical Summaries in R\nTo compute numerical summary values, including the mean and median, we use the df_stats() function from the {mosaicCore} package. This function takes the exact same arguments as the gf_ functions. The syntax below shows how to compute numerical summaries for the admissions rate attribute.\n\n# Compute numerical summaries\ndf_stats(~adm_rate, data = colleges)\n\n\n\n  \n\n\n\nThe mean, or average, of the 230 institutions‚Äô admission rates is 0.68 and the median admission rate for these institutions is 0.72. The slightly lower mean value is consistent with how the mean and median compare in a left-skew distribution. Because the distribution is skewed the median of 0.68, or modal value of 0.75, is a better indication of a typical admission rate.\n\nYour Turn\nCompute the mean and median for the distribution of students‚Äô median earnings 10 years after being enrolled in college\n\nShow/Hide Solution\n\n\n\ndf_stats(~median_earnings, data = colleges)\n\n\n\n  \n\n\n\nThe mean earnings is $51,134 and the median earnings is $49,316.\n\nBased on the distribution of students‚Äô median earnings 10 years after being enrolled in college is the mean or median a better summary of a typical value in the distribution? Explain.\n\nShow/Hide Solution\n\n\nBecause the distribution of earnings is right-skewed, the median is a better summary of a typical value in the distribution.\n\n\n\n\n\n4.4.3 Numerically Summarizing Variation\nThere are several summary measures that statisticians use to summarize the variation in a quantitative distribution. In this class we will focus on three of these measures: the range, the standard deviation, and the interquartile range (IQR).\n\nThe range is the difference between the maximum and minimum values in the distribution.\nThe standard deviation is measure of how far, on average, values in the distribution are from the mean.\nThe interquartile ranger (IQR) is the range of the middle 50% of the distribution.\n\nTo illustrate how to compute these values, we will again use df_stats() to compute the summaries for the admission rate attribute.\n\n# Compute numerical summaries\ndf_stats(~adm_rate, data = colleges)\n\n\n\n  \n\n\n\nThe range of the distribution is \\(1 - 0.0519 = 0.9481\\). Note that the range is a single value. Alternatively, we can say the admission rates range from 0.0519 to 1. This summary indicates the overall variation in the attribute.\nThe standard deviation is computed and returned in the sd column of the df_stats() output. The standard deviation of the admission rates is 0.217. Interpreting this, we would say that on average, most admission rates are within .216 of the mean. That is, most admission rates are between 0.47 and 0.90. To compute this range:\n\\[\n\\begin{split}\n&\\mathrm{Mean} \\pm \\mathrm{SD}\\\\[2ex]\n&0.683 - 0.217 = 0.47 \\\\[2ex]\n&0.47 + 0.217 = 0.90\n\\end{split}\n\\] The last summary measure of variation we will compute is the IQR. The IQR is the difference between the 75th-percentile value (Q3) and the 25th-percentile value (Q1). In the admission rates attribute this is:\n\\[\n\\begin{split}\n\\mathrm{IQR} &= 0.840975 - 0.5597 \\\\[2ex]\n&= 0.281\n\\end{split}\n\\]\nThat is the middle 50% of the admission rates have a range of 0.281‚Äîthey range from 0.56 to 0.84.\n\nYour Turn\nCompute the range, IQR, and standard deviation for the distribution of students‚Äô median earnings 10 years after being enrolled in college.\n\nShow/Hide Solution\n\n\n\ndf_stats(~median_earnings, data = colleges)\n\n\n\n  \n\n\n# Range = 132969 - 19513 = 113456\n# IQR = 56535.75 - 43031 = 13504.75\n# SD = 14.601k\n\n\nBased on the distribution of students‚Äô median earnings 10 years after being enrolled in college which summary measure(s) of variation would you report? Explain.\n\nShow/Hide Solution\n\n\nBecause the distribution of earnings is right-skewed, we might report the IQR in addition to the range.\n\n\nSimilar to the numerical summaries for the center of a distribution, some measures of variation are better suited toward summarizing symmetric distributions and others for skewed distributions. For all distributions, the range is typically provided to summarize the overall variation. In addition, for symmetric distributions, the standard deviation is also conventionally used to summarize the variation for most cases. In skewed distributions, the IQR is a better numerical summary of the variation than the standard deviation.\n\nAdding the numerical summaries to our previous description of the distribution of admission rates presented in Figure¬†4.5:\n\nThe distribution of admission rates is left-skewed. There is a great deal of variation in addmission rates, with institutions of higher learning admitting as few as .5% of their applicants, and some as many as 100%. A typical institution in the distribution admits around 72% (median) of its applicants with half admitting between 56% (Q1) and 84% (Q3) of their applicants. This suggests that most institutions admit a high proportion of applicants. There are, however, a few institutions that are quite selective, admitting fewer than 25% of the students who apply.\n\n\nThere is no one correct way to summarize and report the characteristics of a quantitative distribution. You will want to describe the shape, center, and variation, but how you do that may be different from how another person chooses to do that. For example, in the description of the distribution of admission rates I chose to report the characteristics using text/prose. Another researcher might have instead chosen to report this information in a table rather than writing about it. As an applied scientist or researcher you need to be able to do both.\n\nIn practice you might try multiple reporting strategies within a paper before you settle on one that is ‚Äúbest‚Äù for that paper. Think of it like you do in drafting writing‚Äîoften your first attempt isn‚Äôt the same as the final product, and it may take several iterations to get to that final draft."
  },
  {
    "objectID": "03-02-quantitative-attributes.html#summary",
    "href": "03-02-quantitative-attributes.html#summary",
    "title": "4¬† Summarizing and Visualizing Quantitative Attributes",
    "section": "4.5 Summary",
    "text": "4.5 Summary\nThere are several R functions that are useful for summarizing categorical attributes. Table¬†4.1 shows the functions (and their descriptions) you will use to summarize and visualize quantitative attributes. Note that they all have very parallel syntax.\n\n\n\n\n\n  \n  Table¬†4.1:  The functions and their descriptions to summarize and visualize quantitative attributes. \n  \n    \n    \n      Function\n      Description\n    \n  \n  \n    \n      Summarize\n    \n    df_stats(~attribute, data = data_object)\n\nCompute common summaries of a quantitative attribute\n    \n      Visualize\n    \n    gf_histogram(~attribute, data = data_object)\n\nCreate histogram\n    gf_density(~attribute, data = data_object)\n\nCreate density plot\n  \n  \n  \n\n\n\n\n\nWhen describing a quantitative distribution, there are three characteristics to attend to: shape, center, and variation. These can be estimated from a plot of the distribution, and the center and variation can also be summarized numerically. Often the shape of the distribution dictates which measures are provided in the description of the attribute. Table¬†4.2 presents a guide for thinking about what should be reported based on the shape of the distribution.\n\n\n\n\n\n  \n  Table¬†4.2:  Characteristics (shape, center, and variation) of different quantitative distributions that might get reported to summarize them. \n  \n    \n    \n      Example\n      Shape\n      Center\n      Variation\n    \n  \n  \n    \nLeft-skewed\nMedian\\nMode\nRange (overall) and IQR (typical)\n    \nSymmetric\nMean, Median, or Mode\nRange (overall) and SD (typical)\n    \nRight-skewed\nMedian or Mode\nRange (overall) and IQR (typical)"
  },
  {
    "objectID": "04-00-comparing-to-a-standard.html",
    "href": "04-00-comparing-to-a-standard.html",
    "title": "Comparing Data to a Standard",
    "section": "",
    "text": "One task that is commonly performed in research is to compare the data you have to a specified standard or value. For example, is the average income for a community higher than the poverty level? Or, is the mean admission rate for institutions of higher learning in the United States higher than 0.50?\nIn previous chapters you learned how to compute characteristics of the distribution (e.g., the mean) that would allow us to answer these questions about the sample. For example, in ?sec-quantitative, we found that the average admission rate for our 230 sample institutions of higher learning was 0.68. Based on this, we could say that the average admission rate for our sample of 230 schools was higher than 0.50. But, is this true when we grow our sample to ALL institutions of higher learning? Is the mean admission rate for ALL institutions of higher learning in the United States higher than 0.50?\nDrawing conclusions beyond the data we have is called inference, and the associated methods that allow researchers to allows us to learn from incomplete or imperfect data are referred to as statistical inference (Gelman & Hill, 2007). In this part of the textbook, you will learn about a set of statistical inferential methods that allow you to compare a sample of data to some standard in order to draw inferences about how the population compares to that standard (e.g., is the average income for a community higher than the poverty level?). To answer this type of inferential question, you will learn about how we quantify the amount of uncertainty associated with our sample numerical estimate when we have incomplete data (i.e., only a sample of data from the population we want to infer to). You will also learn how we then use that quantification in a one-sample hypothesis test to draw an inference about how the population compares to that standard. Finally, you will learn about how sampling bias might distort our inferences, and how to evaluate whether particular sampling methods used to collect the sample data might suffer from sampling bias.\n\n\n\n\nGelman, A., & Hill, J. (2007). Data analysis using regression and multilevel/hierarchical models. Cambridge University Press."
  },
  {
    "objectID": "04-01-case-study-teen-sleep.html#descriptive-analysis",
    "href": "04-01-case-study-teen-sleep.html#descriptive-analysis",
    "title": "5¬† Case Study: Teen Sleep",
    "section": "5.1 Descriptive Analysis",
    "text": "5.1 Descriptive Analysis\nAfter importing the data, we will start by exploring the data. Because we are interested in the hours of sleep teens are getting, we will visualize and numerically describe the hrs_sleep attribute.\n\n# Create density plot\ngf_density(\n  ~ hrs_sleep, data = teen_sleep,\n  color = \"black\", \n  fill = \"skyblue\",\n  xlab = \"Hours of Sleep\",\n  ylab = \"Density\"\n  )\n\n# Compute numerical summaries\ndf_stats(~hrs_sleep, data = teen_sleep)\n\n\n\n\n\n\nFigure¬†5.1: Density plot of the hours of sleep for 75 teenagers.\n\n\n\n\n\n\nFigure¬†5.2: Density plot of the hours of sleep for 75 teenagers.\n\n\n\n\nDescribing the amount of sleep teens get we might say:\n\nThere is a great deal of variation in the hours of sleep that teens get, with some teenagers getting as much as 11 hours of sleep a night, and others getting as little as 4 hours. A typical teen in the sample gets around 7.5 hours of sleep a night. The SD of 1.5 further indicates most teens get between 6 and 9 hours of sleep a night. There is some evidence in the density plot that suggests the distribution of teen sleep may be bimodal, with a much smaller group of teens averaging around 5 hours of sleep a night.\n\nBased on the visual and numerical evidence, we might conclude that, on average, teens are not getting the recommended 9 hours of sleep a night. The key words here in the conclusion are: ‚Äúon average‚Äù. Statistically, we are saying that a typical teen in the distribution (around 7.5 hours of sleep a night) is not getting the recommended 9 hours of sleep a night. It is important to note that we are not talking about individual teens here (some of the teens in the sample are getting 9 or more hours of sleep a night), but rather are asking the question: on average, are teens getting the recommended 9 hours of sleep a night.\nUsing this interpretation, we can definitively say that the 75 teens in our sample are, on average, not getting 9 or more hours of sleep a night‚Äîthey are averaging 7.4 hours of sleep a night (based on the sample mean). Our research question, however is not whether these 75 teens are getting the recommended amount of sleep, but whether teens more generally are getting the recommended 9 hours of sleep a night. To answer this requires that we infer beyond our sample of 75 teens to the broader population of teens from which they were sampled from."
  },
  {
    "objectID": "04-01-case-study-teen-sleep.html#statistical-inference-using-sample-data-to-draw-conclusions-about-the-population",
    "href": "04-01-case-study-teen-sleep.html#statistical-inference-using-sample-data-to-draw-conclusions-about-the-population",
    "title": "5¬† Case Study: Teen Sleep",
    "section": "5.2 Statistical Inference: Using Sample Data to Draw Conclusions about the Population",
    "text": "5.2 Statistical Inference: Using Sample Data to Draw Conclusions about the Population\nIn many studies, the primary interest is to learn about one or more characteristics about a population. Although these characteristics must be estimated from sample data, the sample (and thus the estimate computed from the sample) form an incomplete picture of the population. As an example, consider the pictures of Goldy Figure¬†5.3. In the left-hand panel every pixel of the picture is shown. In the right-hand panel, we have only shown a random sample of the pixels. While the picture on the right is incomplete, we can still infer what the original picture looks like. This idea is similar to how we can make inferences about a population from a subset of cases (i.e., a sample).\n\n\n\n\n\n\n\n(a) Population\n\n\n\n\n\n\n\n(b) Sample\n\n\n\n\nFigure¬†5.3: Goldy.\n\n\nThe issue with using the sample data to draw a conclusion about the larger population is that the sample is an incomplete picture of the larger population. This means that any estimate we obtain from the sample needs to account for this incompleteness or uncertainty. For example, in the right-hand panel of Figure¬†5.3 the incomplete data leads to uncertainty about the actual picture. The information there allows us to make some inferences (e.g., it is a photo of Goldy), but there is still uncertainty because some of the pixels are not shown.\nIn our example of determining whether teenagers are sleeping 9 or more hours, we used sample data to obtain an estimate of the average amount of sleep teens are getting in a night, namely 7.4 hours of sleep a night. Because we based this estimate on incomplete data (i.e., from a sample) there is uncertainty associated with this estimate‚Äî7.4 hours is probably not the average number of hours ALL teens sleep a night. Quantifying the uncertainty gives us a better estimate. For example, this quantification might suggest that teens sleep, on average, between 6.0 and 8.8 hours a night.\n\n\n5.2.1 Sources of Uncertainty\nWhy does incomplete data lead to uncertainty? It turns out, there are several sources of uncertainty, the most common of which are:\n\nSampling variation (a.k.a, sampling error); and\nMeasurement variation (a.k.a., measurement error)\n\nSampling variation is the idea that different samples that can be drawn from the same population produce different estimates.\nFor example, what if if we had used a different sample of 75 teenagers. The amount of sleep these teens got would likely be different than our original 75 teens, which means that their average amount of sleep (the sample mean) would also be different than the original average of 7.4. This tells us that the uncertainty in the estimate is a function of the random nature of the sampling.\nAnother source of uncertainty in estimates is imperfect measurement, or measurement error. This arises most often when the constructs we are measuring can not be directly observed (i.e., they are latent) and we have to use proxies of these construct in our analysis. For example, the way the researchers in the original study measured the amount of sleep was via a self-report survey; they asked teens and their parents to indicate the teen‚Äôs typical bedtime and wake-up time using a drop down menu that gave times in 5 minute increments. Self-reporting, even with the parent responses as a check, are likely imperfect measures of the amount of sleep a teen gets. Further, if we compute a numerical summary, say the mean, from scores that are imperfect measures, then that mean will also be an uncertain estimate. The uncertainty in the sample estimate is now not only due to sampling error, but also because of the measurement error inherent in its computation.\nIn practice, despite these being very different sources of variation, measurement error and sampling error are often combined and treated as if all of the uncertainty was due to sampling error. This\n\nEPsy 5261, we will focus on quantifying uncertainty via estimating the sampling variation/sampling error. You can learn more about how to compute and account for measurement error in courses like EPsy 5221: Priciples of Educational and Psychological Measurment."
  },
  {
    "objectID": "04-01-case-study-teen-sleep.html#uncertainty-due-to-sampling-error",
    "href": "04-01-case-study-teen-sleep.html#uncertainty-due-to-sampling-error",
    "title": "5¬† Case Study: Teen Sleep",
    "section": "5.3 Uncertainty Due to Sampling Error",
    "text": "5.3 Uncertainty Due to Sampling Error\nTo give you a better sense of the uncertainty in an estimate that is due to sampling error and the methods we use to quantify sampling error, consider the following thought experiment: Imagine the population of amount of sleep per night taken for every teenager (past, present, and future). There would be an infinite number of these values, but theoretically, we could plot all of these values, and compute numerical summaries such as the mean and standard deviation of these values. (The mean of this distribution is what we are trying to estimate using our sample data.) The conceptual idea of estimating sampling variation is that we are going to draw a sample of 75 students and compute the mean amount of sleep for that sample. Then we are going to repeat this process again, and again, each time drawing 75 observations and computing the mean amount of sleep. Figure¬†6.1 shows a visual depiction of this thought experiment that was carried out 1000 times.\n\n\n\n\n\nFigure¬†5.4: Thought experiment for drawing random samples of size 75 from the population to obtain different samples. The average amount of sleep per night is computed for each sample drawn.\n\n\n\n\nThe 1000 sample means can then be plotted, and we can compute a numeric summary of the variability in the distribution of sample means.\n\n\n\n\n\nFigure¬†5.5: Distribution of 1000 sample means. Each observation in the distribution is a mean indicating the average amount of sleep per night for one sample. The red dots show the means computed from Figure¬†6.1.\n\n\n\n\nIn Figure¬†5.5 each observation plotted in the distribution is one of the means from a sample drawn in our thought experiment. For example, the red dots indicate the five sample means reported in Figure¬†6.1, namely 7.48 (mean of Sample 1), 6.90 (mean of Sample 2), 7.78 (mean of Sample 3), 7.32 (mean of Sample 4), and 7.24 (mean of Sample 1000). When the cases in a distribution are numerical summaries, we call that distribution a sampling distribution. The distribution in Figure¬†5.5 is a sampling distribution of the mean, indicating that the numerical summaries being plotted are means.\nRemember that our purpose for producing this distribution is to summarize the variation in the mean values, that is, we want to produce a numerical summary of the variation in the sampling distribution of the means shown in Figure¬†5.5. This distribution is approximately normal (unimodal and symmetric), so the standard deviation will be a good summary of the variation in this distribution.\n\nIf you have a distribution that is unimodal and symmetric, you can estimate the standard deviation by determining the halfway point of the height of the middle of the distribution. You can then follow that out to either side of the distribution and that width is a good guess for the standard deviation.\n\n\n\n\n\nFigure¬†5.6: Visual depiction of how to estimate the standard deviation in a unimodal symmetric distribution.\n\n\n\n\n\nIn the sampling distribution, in Figure¬†5.5, we estimate the standard deviation to be approximately 0.2. Because this standard deviation is quantifying the variability in a distribution of summary statistics, we refer to it as a standard error (SE).\nRecall that each of the samples were randomly sampled from the same population and that the sample mean is a guess for the value of the population mean‚Äîthe average amount of nightly sleep for ALL teens. Since the only source of variation in the sampling distribution is sampling error (that is, the only reason the sample means are different is that different teens were chosen to be a part of each sample), the SE is a quantification of the uncertainty due to sampling error we expect in our estimate. Based on a typical value in the distribution of about 7.4, and using our SE of 0.20, we can say:\n\nWe think that the mean amount of sleep each night for ALL teens is between 7.2 and 7.6. This range of values captures the uncertainty in the estimate (the sample mean) that is due to sampling error."
  },
  {
    "objectID": "04-01-case-study-teen-sleep.html#looking-ahead",
    "href": "04-01-case-study-teen-sleep.html#looking-ahead",
    "title": "5¬† Case Study: Teen Sleep",
    "section": "5.4 Looking Ahead",
    "text": "5.4 Looking Ahead\nIn practice, you do not draw 1000 samples; you have one sample of data that you have collected. So one of the things we will need to learn is how to produce a standard error based on only one sample of data. You will also learn about how to use the standard error in hypothesis tests evaluate how well data conforms to particular quantitative hypotheses we may have about the population. Finally, you will learn about a theoretical result in statistics known as the Empirical Rule, which will help us put probabilistic statements around the quantification of uncertainty to produce confidence intervals."
  },
  {
    "objectID": "04-01-case-study-teen-sleep.html#references",
    "href": "04-01-case-study-teen-sleep.html#references",
    "title": "5¬† Case Study: Teen Sleep",
    "section": "5.5 References",
    "text": "5.5 References\n\n\n\n\nJohns Hopkins University. (2023). Teenagers and sleep: How much sleep is enough? https://www.hopkinsmedicine.org/health/wellness-and-prevention/teenagers-and-sleep-how-much-sleep-is-enough\n\n\nNational Institutes of Health. (2021). Good sleep for good health: Get the rest you need. In NIH News in Health. https://newsinhealth.nih.gov/2021/04/good-sleep-good-health"
  },
  {
    "objectID": "04-02-simulation.html#bootstrapping",
    "href": "04-02-simulation.html#bootstrapping",
    "title": "6¬† Bootstrapping: Using Simulation to Estimate the Uncertainty",
    "section": "6.1 Bootstrapping",
    "text": "6.1 Bootstrapping\nThe key question addressed by using any statistical method of inference is ‚Äúhow much variation is expected in a particular test statistic if one repeatedly draws random samples from the same population?‚Äù In the thought experiment we introduced in Chapter¬†5, the method for quantifying the uncertainty was to repeatedly sample from the population and measure the variation in the sample means. Recall that the quantification of the uncertainty (i.e., variation in the sample means) is referred to as the standard error.\n\n\n\n\n\nFigure¬†6.1: Thought experiment for drawing random samples of size 75 from the population to obtain different samples. The average amount of sleep per night is computed for each sample drawn.\n\n\n\n\nBradley Efron introduced the methodology of bootstrapping in the late 1970s as an alternative method to compute the standard error.\ncomputer-based simulation framework to replace the inaccurate and complicated approximations that theoretical methods provide.1\nEfron‚Äôs big discovery was that in the thought experiment, we could replace the population with a sample, and then randomly sample from that initial sample. He proved that using this methodology, you can obtain a good estimate of the sampling variation.\n\n\n\n\n\nFigure¬†6.2: Thought experiment for bootstrapping random samples of size 75 from the original sample of 75 students‚Äô sleep times to obtain different samples. The average amount of sleep per night is computed for each re-sample drawn.\n\n\n\n\nBecause we need to randomly sample 75 observations out of the original sample (which itself only includes 75 observations), we need to sample WITH REPLACEMENT when we draw our re-samples. In this way, we mimic drawing random samples from a larger population without actually needing the larger population."
  },
  {
    "objectID": "04-02-simulation.html#importing-the-teen-sleep-data",
    "href": "04-02-simulation.html#importing-the-teen-sleep-data",
    "title": "6¬† Bootstrapping: Using Simulation to Estimate the Uncertainty",
    "section": "6.2 Importing the Teen Sleep Data",
    "text": "6.2 Importing the Teen Sleep Data\nWe will use the data in teen-sleep.csv to bootstrap a standard error of the mean. These data include the bedtime, wake-up time, and hours slept for a sample of \\(n=75\\) American teens in Grades 9‚Äì12.\n\nteen-sleep.csv\nData Codebook\n\nWe will prepare for the analysis by loading in the {tidyverse}, {ggformula}, and {mosaicCore} libraries and importing the teen sleep data. We will also load the {mosiaic} package.\n\nlibrary(ggformula)\nlibrary(mosaicCore)\nlibrary(mosaic)\nlibrary(tidyverse)\n\n\n# Import data\nteen_sleep <- read_csv(\"https://raw.githubusercontent.com/zief0002/epsy-5261/main/data/teen-sleep.csv\")\n\n# View data\nteen_sleep"
  },
  {
    "objectID": "04-02-simulation.html#bootstrapping-from-the-teen-sleep-data",
    "href": "04-02-simulation.html#bootstrapping-from-the-teen-sleep-data",
    "title": "6¬† Bootstrapping: Using Simulation to Estimate the Uncertainty",
    "section": "6.3 Bootstrapping from the Teen Sleep Data",
    "text": "6.3 Bootstrapping from the Teen Sleep Data\nThe process for computing the standard error via bootstrapping is:\n\nSTEP 1: Randomly sample n observations from the observed sample of size n (with replacement) This is called a bootstrap sample or a re-sample.\nSTEP 2: Compute the mean of the bootstrap sample.\nSTEP 3: Repeat the first two steps in the process many times (say 1000 times), each time recording the mean.\nSTEP 4: Find the standard deviation of these means (i.e., the standard error of the mean).\n\nThe computations we do will parallel each step of this process. As you learn how to do this, it is easy to get lost in the computing and forget why you are doing this. Remember, the end goal is to mimic the thought experiment so we can quantify the variation in the sample means.\n\n\n6.3.1 STEP 1: Randomly sample 75 observations from the observed sample of size 75 teen sleep amounts (with replacement)\nTo randomly sample from a set of values we use the sample() function. We will need to specify the values we are sampling from (i.e., the original sample) as an input to the function. The data we want to randomly sample from is in a column called hrs_sleep inside the data object called teen_sleep. To specify a particular column in a data object we use the following notation: teen_sleep$hrs_sleep. We also need to set the number of observations to randomly sample, and tell this function that we are sampling with replacement.\nThus to draw a random sample of values from our data we use:\n\n# Randomly sample from the hrs_sleep column located in the teen_sleep data object\n# Draw 75 observations\n# Sample with replacement\nsample(teen_sleep$hrs_sleep, size = 75, replace = TRUE)\n\n [1]  6.333333  5.916667  7.666667  9.166667  7.916667  7.000000  8.333333\n [8] 10.333333  8.333333  7.500000  7.916667  7.083333  7.916667  7.583333\n[15]  7.166667  7.833333  8.083333  7.833333  4.583333  5.416667  5.833333\n[22] 11.083333 10.083333  6.750000  6.916667  8.833333  4.916667  9.916667\n[29] 10.083333  6.416667  7.500000  6.833333  8.083333  7.750000  7.000000\n[36]  7.333333  4.666667  7.916667  8.916667  4.583333  7.750000  6.333333\n[43]  6.416667  7.750000  7.833333  4.916667  7.083333  6.083333  4.666667\n[50]  7.583333  8.833333  6.333333  7.333333  8.916667  5.916667  8.583333\n[57]  6.750000  6.916667  7.666667  5.916667  7.666667  7.666667  9.083333\n[64] 11.083333  9.750000  4.666667  7.083333  6.416667  4.166667  8.583333\n[71]  6.083333 11.083333  5.166667  7.083333  6.666667\n\n\nThis is akin to drawing a bootstrap sample from the original sample. Note that because we are drawing randomly, if you are trying this on your computer, you might get a different bootstrap sample than the one shown here. If you re-run this syntax, you will get a different bootstrap sample.\n\n# Draw a second bootstrap sample of 75 observations\nsample(teen_sleep$hrs_sleep, size = 75, replace = TRUE)\n\n [1]  7.083333  6.083333  5.916667  7.916667  8.833333  9.083333  7.583333\n [8]  7.583333  7.916667  6.916667  7.750000  8.500000  7.583333  6.500000\n[15]  8.583333  7.750000  8.833333  7.833333  7.666667  7.333333  5.916667\n[22]  6.083333  7.500000  7.583333  7.000000  7.583333  4.833333 10.333333\n[29]  7.083333  9.750000 10.333333  7.583333  7.666667  6.083333  9.750000\n[36]  4.500000  6.083333  4.416667  7.583333  8.583333  7.333333  5.166667\n[43]  7.750000  4.916667  9.916667  9.750000  8.333333  9.166667  8.333333\n[50]  7.916667  7.333333  8.833333  7.500000  6.916667  6.916667  7.416667\n[57]  4.916667  7.500000  8.500000  7.666667  8.750000  7.000000  9.750000\n[64]  7.750000  7.333333  7.666667  7.500000  7.666667 10.083333  8.250000\n[71]  9.916667  7.083333  7.666667  7.083333  4.583333\n\n\n\n\n\n6.3.2 STEP 2: Compute the mean of the bootstrap sample.\nTo compute the mean of a bootstrap sample, we are just going to embed our sample() syntax inside of the mean() function. For example,\n\n# Draw a bootstrap sample of 75 observations and compute the mean\nmean(sample(teen_sleep$hrs_sleep, size = 75, replace = TRUE))\n\n[1] 7.427778\n\n\nYou could re-run this syntax to draw another bootstrap sample and compute the mean.\n\n\n\n6.3.3 STEP 3: Repeat the first two steps in the process many times (say 1000 times), each time recording the mean.\nTo repeat a set of computations, we are going to use the do() function from the {mosaic} package. As a reminder, you will need the {mosiac} package loaded prior to using this function. The syntax for the do() function takes the following format:\ndo(N times) * {Computations to repeat}\nAs an example, if we wanted to carry out our computations to draw a bootstrap sample and compute the mean 10 times, the synatx is:\n\n# Draw a bootstrap sample of 75 observations and compute the mean\n# Do this 10 times \ndo(10) * {mean(sample(teen_sleep$hrs_sleep, size = 75, replace = TRUE))}\n\n\n\n  \n\n\n\nThe computations are carried out 10 times and the results are recorded in a column (result) of a data object. Because we will ultimately want to compute on this data object, when we run this, we will want to assign the data into an object. Below, we draw 1000 bootstrap samples, each time computing the mean, and assign them into a data object called bootstrap_means.\n\n\n\n\n# Draw a bootstrap sample of 75 observations and compute the mean\n# Do this 1000 times \n# Assign these into an object called bootstrap_means\nbootstrap_means <- do(1000) * {mean(sample(teen_sleep$hrs_sleep, size = 75, replace = TRUE))}\n\n# View the results\nbootstrap_means\n\n\n\n  \n\n\n\n\n\n\n6.3.4 STEP 4: Find the standard deviation of these means (i.e., the standard error of the mean).\nRemember our goal was to compute the standard error, which quantifies the uncertainty in the sample mean estimates that is due to sampling variation. Before we do that, we will visualize the distribution of bootstrapped means.\n\n# Create a density plot of the bootstrapped means\ngf_density(\n  ~result, data = bootstrap_means,\n  xlab = \"Mean value\",\n  ylab = \"Density\"\n)\n\n\n\n\nFigure¬†6.3: Distribution of 1000 bootstrapped means.\n\n\n\n\nThe distribution of bootstrapped means is unimodal and symmetric. This indicates that the standard deviation is a reasonable numeric summary of the variation. Again, since the cases in the distribution are means (summary measures), the standard deviation is referred to as a standard error. To compute the standard error, we use df_stats():\n\n# Compute SE\ndf_stats(~result, data = bootstrap_means)\n\n\n\n  \n\n\n\nHere the standard error (found in the sd column) is 0.17.\n\nThe distribution of bootstrapped means should be centered at the value of the original sample mean. In our teen sleep example, the original sample had a mean of 7.4. This value is roughly at the center of the distribution in Figure¬†6.3. This can be a self-check when you create a bootstrap distribution."
  },
  {
    "objectID": "04-02-simulation.html#references",
    "href": "04-02-simulation.html#references",
    "title": "6¬† Bootstrapping: Using Simulation to Estimate the Uncertainty",
    "section": "6.4 References",
    "text": "6.4 References\n\n\n\n\nRaspe, R. E. (1948). Singular travels, campaigns and adventures of Baron Munchausen (J. Carswell, Ed.). Cresset Press."
  },
  {
    "objectID": "04-03-one-sample-test.html#statistical-inference-and-hypothesis-testing",
    "href": "04-03-one-sample-test.html#statistical-inference-and-hypothesis-testing",
    "title": "7¬† Hypothesis Testing: One-Sample t-Test",
    "section": "7.1 Statistical Inference and Hypothesis Testing",
    "text": "7.1 Statistical Inference and Hypothesis Testing\nOne common approach to statistical inference‚Äîthe drawing of conclusions about populations based on sample observations‚Äîis to use the sample observations to test a priori hypothesis1 about the population. Hypotheses are mathematical statements about population parameters which are often formed based on prior knowledge and substantive literature in the area of content.\nIn the social sciences, we typically write out two hypotheses about the population parameters: the null hypothesis (\\(H_0\\)), often referred to as a statement of no effect, and the alternative hypothesis (\\(H_A\\)), often termed the research (or alternative) hypothesis. For example, here are a set of potential hypotheses about teen sleep:\n\\[\n\\begin{split}\n&H_0: \\textrm{The mean amount of sleep for all teens is equal to 9 hours.} \\\\[1ex]\n&H_A: \\textrm{The mean amount of sleep for all teens is less than 9 hours.}\n\\end{split}\n\\] There are a few things to notice about these hypotheses:\n\nThe statements are about the mean amount of sleep (i.e., summary measure).\nThe statements are about the population (all teens), not the sample.\nThe null hypothesis (\\(H_0\\)) is a statement of equality (is equal to).\nThe alternative hypothesis often indicates the researcher‚Äôs belief about the population summary (e.g., we think the average amount of sleep for all teens is less than 9 hours).\n\nStatisticians often use the language of mathematics to express these hypotheses. The same hypotheses expressed via the language of mathematics are:\n\\[\n\\begin{split}\n&H_0: \\mu_{\\textrm{Sleep}}=9 \\\\[1ex]\n&H_A: \\mu_{\\textrm{Sleep}} < 9\n\\end{split}\n\\]\nThe Greek letter mu (\\(\\mu\\)) denotes a population mean. In general Greek letters represent population parameters while Roman letters represent sample statistics. Here are a list of common statistical summaries and the mathematical notation used to denote them.\n\n\n\n\n\n  \n  Table¬†7.1:  Some common statistical summaries and the mathematical notation used to denote them. \n  \n    \n    \n      Summary\n      Sample\n      Population\n    \n  \n  \n    Mean\n$$\\bar{x},~\\textit{M}$$\n$$\\mu$$\n    Standard Deviation\n$$\\textit{s},~\\textit{SD}$$\n$$\\sigma$$\n    Variance\n$$s^2,~\\textit{Var}$$\n$$\\sigma^2$$\n  \n  \n  \n\n\n\n\n\nThe alternative hypothesis is always an inequality. In this example, the alternative hypothesis is the mean is LESS THAN 9 hours. Another potential alternative hypothesis would be that the mean is GREATER THAN 9 hours, while a third possibility is that the mean is NOT EQUAL TO 9 hours. Mathematically these could be expressed as \\(\\mu_{\\textrm{Sleep}}<9\\), \\(\\mu_{\\textrm{Sleep}}>9\\), and \\(\\mu_{\\textrm{Sleep}}\\neq9\\). The alternative hypothesis you choose is based on your conjecture about the population. For example, if we believed that teens sleep, on average, less than 9 hours a night, then the alternative hypothesis we choose would be \\(\\mu_{\\textrm{Sleep}}<9\\). If we thought they sleep more than 9 hours, on average, we would adopt the alternative hypothesis of \\(\\mu_{\\textrm{Sleep}}>9\\). If we are unsure about whether they sleep less or more than 9 hours, then our alternative hypothesis would be \\(\\mu_{\\textrm{Sleep}}\\neq9\\).\n\n\n7.1.1 The Null Model\nA hypothesis test is predicated on the assumption that the null hypothesis is true. Thus, we want to produce a sampling distribution of potential sample summaries that we could see if \\(H_0: \\mu_{\\textrm{Sleep}}=9\\) is actually true. In other words, we are carrying out a thought experiment assuming that the average amount of sleep for all teens is actually 9 hours.\n\n\n\n\n\nFigure¬†7.1: Visual depiction of the thought experiment underlying a hypothesis test assuming that the mean amount of sleep for all tennagers is 9 hours.\n\n\n\n\nIf we were able to carry out this thought experiment, here is what the sampling distribution of the sample means would look like:\n\n\n\n\n\nFigure¬†7.2: Density plot of the sampling distribution of the sample means based on the thought experiment underlying a hypothesis test assuming that the mean amount of sleep for all tennagers is 9 hours.\n\n\n\n\nThis distribution is also known as the null distribution since it is the sampling distribution that arises from the thought experiment assuming the null hypothesis is true. Describing the features (shape, center, and variation) of this null distribution we find:\n\nThe distribution is unimodal and symmetric.\nThe mean (center) of the distribution is at 9 hours.\nThe SD of this distribution (the SE) is approximately 0.20.\n\nInterpreting these features, we find that in the thought experiment where we assume the mean amount of sleep is 9 hours, a typical mean is 9 hours! But, sample means will vary from 9 hours. That is, even if the true mean amount of sleep is 9 hours, we could expect a sample mean that differs from 9 hours. How much they will vary depends on the SE, which is approximately 0.20.2 So, it would not be unusual to see a sample mean as low as 8.6 (\\(9 - 2(0.20) = 8.6\\)) or as high as 9.4 (\\(9 + 2(0.20) = 9.4\\)).\n\nThe null distribution will always be centered at the parameter value specified in the null hypothesis! The SE of the null distribution gives us an indication of how much a sample statistic is likely to vary from the parameter specified in the null hypothesis. We expect most values will be within 2 standard errors of the center.\n\n\n\n\n7.1.2 Evaluating the Observed Sample Mean\nThe null distribution gives us an indication of the range of sample mean values that are expected assuming the null hypothesis is true. Using the null distribution as a reference, we can evaluate the mean we obtained from the observed data, which was 7.5 hours (see Chapter¬†5).\n\n\n\n\n\nFigure¬†7.3: Density plot of the sampling distribution of the sample means based on the thought experiment underlying a hypothesis test assuming that the mean amount of sleep for all tennagers is 9 hours. The blue shaded area represents the sample mean values we expect under the hypothesis that the average amount of sleep for all tennagers is 9 hours. The pink dot represnts the sample mean of 7.5 that we observed in the teen sleep data.\n\n\n\n\nWe can see from Figure¬†7.3 that the observed mean of 7.5 is not a value we expect if the population mean amount of sleep teenagers get is truly 9 hours. It is, in fact, far less than we expect. In other words,\n\nThe sample mean of 7.5 hours of sleep we observed in the data is not consistent with the hypothesis that the average amount of sleep teenagers get a night is 9 hours.\n\nBecause the data were not consistent with our initial hypothesis, we would reject the null hypothesis, that is, the empirical evidence (data) does not support the hypothesis.\nWhile the method we used allows us to say whether the empirical data are consistent with the null hypothesis that teenagers get, on average, 9 hours of sleep, it does not tell us the level of consistency. Is it slightly inconsistent? Or really inconsistent? Because of this, applied researchers will often quantify this via two measures: (1) the t-value, and the p-value."
  },
  {
    "objectID": "04-03-one-sample-test.html#quantifying-the-level-of-consistency-with-the-null-hypothesis-the-t-value",
    "href": "04-03-one-sample-test.html#quantifying-the-level-of-consistency-with-the-null-hypothesis-the-t-value",
    "title": "7¬† Hypothesis Testing: One-Sample t-Test",
    "section": "7.2 Quantifying the Level of Consistency with the Null Hypothesis: The t-Value",
    "text": "7.2 Quantifying the Level of Consistency with the Null Hypothesis: The t-Value\nThe t-value quantifies how far away the observed mean is from the hypothesized mean value in standard error units. To compute the t-value we use the following:\n\\[\nt = \\frac{\\mathrm{Obs.~Mean} - \\mathrm{Hyp.~Mean}}{SE}\n\\]\nwhere, Obs. Mean is the observed sample mean from the data, Hyp. Mean is the hypothesized value in the null hypothesis, and SE is the standard error in the null distribution (which we compute via bootstrapping). Computing this for our example,\n\\[\n\\begin{split}\nt &= \\frac{7.5 - 9}{0.17} \\\\[2ex]\n&= -8.82\n\\end{split}\n\\] The t-value indicates that our observed sample mean of 7.5 is 8.82 standard errors below the hypothesized population mean value of 9. Changing the distance metric to standard error units helps standardize the distance for other scholars so they can better interpret how discrepant the observed mean is from the hypothesized value.\nFor example, if we hadn‚Äôt divided by the SE, we would have said our observed mean of 7.5 hours of sleep is 1.5 hours less than the hypothesized mean of 9 hours of sleep. Is this a lot less? Or a little less? The answer to that depends on how much we expect sample means to vary from the population mean under random sampling. This is what the SE quantifies. So dividing by the SE accounts for this expected variation and also changes the units from ‚Äúhours of sleep‚Äù to ‚Äústandard errors‚Äù.\nNow that we have a t-value, how do we judge its magnitude? To do this, we can again look back to the null distribution in Figure¬†7.3. Based on the null distribution, we said we expected sample means to fall in between 8.6 and 9.4. What are the t-values associated with 8.6 and 9.4?\n\\[\n\\begin{split}\nt &= \\frac{8.6 - 9}{0.17} \\\\[2ex]\n&= -2.35 \\\\[4em]\nt &= \\frac{9.4 - 9}{0.17} \\\\[2ex]\n&= 2.35\n\\end{split}\n\\]\nExpecting a sample mean between 8.6 and 9.4 is essentially the same as expecting a t-value between \\(-2.35\\) and 2.35.\n\nRule-of-Thumb: An observed mean that has a t-value with an absolute value less than 2 is fairly consistent with the null hypothesis being true. An observed mean that has a t-value with an absolute value greater than 2 is less consistent with the null hypothesis being true, and the further away from 2, the more evidence against the null hypothesis.\n\n\n\n7.2.1 The t-Distribution\nRecall that the null distribution is simply a distribution of sample means we expect if the null hypothesis is true. Because each case in this distribution is a sample mean, we could transform each case into a t-value. If we do that, the resulting distribution is a t-distribution.\n\n\n\n\n\nFigure¬†7.4: Density plot of the t-distribution of the sample means based on the thought experiment underlying a hypothesis test assuming that the mean amount of sleep for all tennagers is 9 hours (t value of 0). The blue shaded area represents the t-values we expect if the null hypothesis is true. The pink dot represents the observed t-value of -8.82.\n\n\n\n\nThe t-distribution is is the sampling distribution that arises from converting the null distribution from the thought experiment assuming the null hypothesis is true to t-values. Describing the features (shape, center, and variation) of this t-distribution we find:\n\nThe distribution is unimodal and symmetric.\nThe mean (center) of the t-distribution is 0.\nThe SD of this t-distribution (the SE) is approximately 1.\n\nNote that the descriptions referred to ‚Äúthis t-distribution‚Äù. That is because there are many different t-distributions; in fact there are an infinite number of them. Each t-distribution is based on a parameter called the degrees-of-freedom (df), which is in turn based on the sample size for the observed data. The df for the t-distribution is computed as:\n\\[\n\\mathit{df} = n - 1\n\\]\nwhere n is the sample size.\nThe degrees-of-freedom parameter impacts the shape and SE (variation) in the t-distribution. Figure¬†7.5 shows the t-distribution based on a few different degrees-of-freedom values. From this figure we can see:\n\nEvery t-distribution is unimodal and symmetric, although t-distributions with smaller degrees-of-freedom parameters are shorter and have thicker tails than t-distributions with higher degrees-of-freedom parameters.\nThe mean (center) of every t-distribution is 0.\nThe SD of this t-distribution (the SE) depends on the degrees-of-freedom, and t-distributions with smaller degrees-of-freedom parameters have a higher SE than t-distributions with higher degrees-of-freedom parameters.\n\n\n\n\n\n\nFigure¬†7.5: Density plot of three different t-distributions. The t-distributions shown have 3 degree-of-freedom (SE = 1.73), 5 degree-of-freedom (SE = 1.29), and 99 degree-of-freedom (SE = 1.01), respectively. Note that the degrees-of-freedom value impacts the shape and variation in the distribution.\n\n\n\n\nThe SE of a t-distribution depends directly on the degrees-of-freedom. Specifically,\n\\[\n\\mathit{SE} = \\begin{cases}\n\\mathrm{Undefined}, & \\text{if } &\\mathit{df}\\leq1\\\\[2ex]\n\\infty, & \\text{if } &1<\\mathit{df}\\leq2\\\\[2ex]\n\\sqrt{\\frac{\\mathit{df}}{\\mathit{df}-2}}, & \\text{if } &\\mathit{df}>2\n\\end{cases}\n\\]\nIn empirical data analyses, the df will almost always be higher than 2 since the sample size for most analyses will be \\(n\\geq3\\). Memorizing these formulas is not important (you an always look them up on Wikipedia), the important thing to see is that when df gets bigger the SE becomes approximately 1.\n\nWhen you report t-values or give information about a t-distribution, you should always report the degrees-of-freedom.\n\n\n\n\n7.2.2 The t-Distribution for the Teen Sleep Example\nNow that we understand a bit more about the properties of the t-distribution, we can sketch the t-distribution for the teen sleep example. Recall that the sample size for the observed data was \\(n=75\\). The df for the resulting t-distribution is:\n\\[\n\\begin{split}\n\\mathit{df} &= 75 - 1 \\\\[1ex]\n&= 74\n\\end{split}\n\\]\nThis helps us think about the properties for this t-distribution:\n\nThe distribution is unimodal and symmetric.\nThe mean (center) of the t-distribution is 0.\nThe SD of this t-distribution (the SE) is \\(\\sqrt{\\frac{74}{74-2}}=1.014\\).\n\nUsing these properties, we can sketch this t-distribution. We can also add the observed t-value of \\(-8.82\\) into the distribution. (Note: We will have to go out about 9 SEs from the center value of 0 to place the observed t-value onto the distribution!)\n\n\n\n\n\nFigure¬†7.6: Sketch of the t-distribution with 74 degrees-of-freedom. The observed value (purple dot) of -8.82 is also shown. The shaded blue area indicates the magnitude of t-values that would be expected if the null hypothesis is true.\n\n\n\n\nBeing able to create this sketch helps us understand how the observed data fit with or don‚Äôt fit with the null hypothesis. It also helps us understand the mechanics of what the computations for the t-test actually mean. In practice, you would not create this distribution for a manuscript, but rather report the pertinent information from these computations, namely the t-value, and the df for the t-distribution. In our example, we might report this as:\n\n\\(t(74)=-8.82\\)\n\nThis small amount of information allows another researcher to re-create the sketch of the t-distribution that we made in Figure¬†7.6. We can also see that the observed data is not very consistent with the null hypothesis. If the true mean amount of sleep for all teenagers is 9 hours, we would expect that the magnitude of an observed t-value would be between \\(-2.028\\) and \\(+2.2028\\). (The t-value of zero corresponds to an average of 9 hrs of sleep, but we expect deviation from this in a sample mean because of sampling variation.) In the data, we found a t-value of \\(-8.82\\)! This indicates that the sample mean for the observed data was 8.82 standard errors below the expected t-value of 0. Moreover, a t-value of \\(-8.82\\) is quite a bit lower than we would expect if teenagers actually average 9 hours of sleep a night."
  },
  {
    "objectID": "04-03-one-sample-test.html#quantifying-the-level-of-consistency-with-the-null-hypothesis-the-p-value",
    "href": "04-03-one-sample-test.html#quantifying-the-level-of-consistency-with-the-null-hypothesis-the-p-value",
    "title": "7¬† Hypothesis Testing: One-Sample t-Test",
    "section": "7.3 Quantifying the Level of Consistency with the Null Hypothesis: The p-Value",
    "text": "7.3 Quantifying the Level of Consistency with the Null Hypothesis: The p-Value\nComputing the observed t-value gives us a method for determining how far (in SE units) the sample mean for the observed data are from a mean value specified in the null hypothesis. By placing the observed t-value in the appropriate t-distribution, we can also say whether the observed data are consistent with the claim made in the null hypothesis. Applied researchers also augment this information with one more piece of evidence called the p-value.\nThe p-value provides a quantification of the probability of observing data at least as extreme as what we observed if the null hypothesis is true. In other words, with the t-value and t-distribution w can say that it is unlikely that we would observe a sample mean as small as 7.5 if teenagers really do average 9 hours of sleep a night. The p-value will take this one step further and quantify exactly how unlikely that would be.\nThe computation of the p-value is based around the alternative (research) hypothesis. Recall that the alternative hypothesis was a statement of inequality about the population mean value. In our sleep example the alternative hypotheis was:\n\\[\nH_A: \\mu < 9\n\\]\nBut it could also have been one of these other inequalities depending on the researcher‚Äôs hypothesis about how the population mean compared to 9 hours.\n\\[\n\\begin{split}\nH_A: \\mu > 9 \\\\[1ex]\nH_A: \\mu \\neq 9\n\\end{split}\n\\] In computing p-value, we have to identify values that are at least as extreme as the observed data. Extremeness varies depending on the direction of the inequality. For example in the example alternative hypothesis that we had: \\(H_A: \\mu < 9\\), a value more extreme than our observed sample mean of 7.5 would be less than 7.5. So to compute the p-value for this alternative hypothesis, w need to find:\n\\[\nP(\\bar{y} \\leq 7.5) ~~~ \\text{if the null hypothesis is true}\n\\]\nNote that \\(P(\\cdot)\\) is the notation to indicate the probability of whatever is in the parentheses. In our case we are finding the probability of a sample mean (\\(\\bar{y}\\)) that is at least as extreme as the one we saw in our observed data (7.5) where extreme is defined in the alternative hypothesis (\\(\\leq\\)).\nTo find this probability we have to go back to the null distribution‚Äîwhich is based on the null hypothesis being true. (The probability defined above assumed the null hypothesis to be true.) We then need to identify all values that are less than or equal to the observed value and find their probability within that distribution. Typically, we do this in the t-distribution, so rather than finding the probability of values less than or equal to 7.5, we need to find:\n\\[\nP(t \\leq -8.82)\n\\]\nAs an example, consider the dotplot in Figure¬†7.7.\n\n\n\n\n\nFigure¬†7.7: Dot plot of an example t-distribution. The vertical blue dashed line indicates the observed value of -8.82. The yellow dots (to the left of -8.82) are the t-values that are at least as extreme as -8.82 based the alternative hypothesis (mu < -8.82).\n\n\n\n\nThis plot shows 300 t-values that are part of a t-distribution created by assuming the null hypothesis was true. Of these 300 t-values, only 2 of them are less than or equal to the observed value of \\(-8.82\\). Thus we can compute the probability of observing data at least as extreme as what we observed as:\n\\[\n\\begin{split}\nP(t \\leq -8.82) &= \\frac{2}{300} \\\\[1ex]\n&= .007\n\\end{split}\n\\]\nThat is, if the null hypothesis is true, the probability we would observe a sample mean at least as extreme as we did is .007. (We report p-values as: p = .007) This is a very unlikely event if the null hypothesis is true. So because we did actually observe a mean this extreme, it causes us to reject the null hypothesis in favor of the alternative hypothesis. The empirical evidence does not seem consistent with teenagers getting 9 hours of sleep a night. It is more consistent with teenagers getting less than 9 hours of sleep a night, on average.\n\nRule-of-Thumb: A p-value that is less than .05 usually is evidence against the null hypothesis in favor of the alternative hypothesis. In contrast, a p-value that is .05 or higher means that the evidence is consistent with the null hypothesis.\nBeing consistent with the null hypothesis does not mean that the null hypothesis is necessarily true, but rather that it could be true. Because of this, if \\(p \\geq .05\\) we never ‚Äúaccept the null hypothesis‚Äù, but instead we ‚Äúfail to reject the null hypothesis‚Äù.\n\n\n\n7.3.1 Computing the p-Value for Other Alternative Hypotheses\nIn the example, we computed the p-value based on the alternative hypothesis, \\(H_A:\\mu<9\\). To do this we counted the cases in the t-distribution that were more extreme than our observed t-value of \\(-8.82\\), which in this alternative hypothesis corresponded to the t-values that were less than or equal to \\(-8.82\\) and computed a probability (proportion) by dividing by the total number of values in the distribution. To compute this for other null hypotheses, we do the same thing, but we have to re-define extreme.\nFor example if we had the alternative hypothesis \\(H_A:\\mu>9\\), values at least as extreme as \\(-8.82\\) correspond to all the values that are greater than or equal to \\(-8.82\\). These are shown a the yellow cases in the distribution below.\n\n\n\n\n\nFigure¬†7.8: Dot plot of an example t-distribution. The vertical blue dashed line indicates the observed value of -8.82. The yellow dots (to the right of -8.82) are the t-values that are at least as extreme as -8.82 based the alternative hypothesis (mu > -8.82).\n\n\n\n\nBased on this alternative hypothesis, we would have counted 298 cases that have a t-value greater than or equal to \\(-8.82\\). Based on this alternative hypothesis, the p-value would be computed as:\n\\[\n\\begin{split}\np &= \\frac{298}{300} \\\\[1ex]\n&= .993\n\\end{split}\n\\]\nThis level of evidence does not support the alternative hypothesis since the p-value is not less than .05. Because of this, we do not think the average amount of sleep teenagers get a night is greater than 9 hours. The empirical evidence doesn‚Äôt support this. However, it isn‚Äôt clear from this test that the empirical evidence supports that students get 9 hours of sleep (i.e., \\(\\mu=9\\)); it may be they are getting less than 9 hours of sleep (\\(\\mu<9\\)). That is why we cannot accept the null hypothesis that \\(\\mu=9\\). The test has only ruled out values for \\(\\mu\\) that are greater than 9 hours; the mean actually being 9 hours is only one possibility of many that remain after we eliminate those values greater than 9!\nAnother potential alternative hypothesis that a researcher might have is \\(H_A:\\mu\\neq9\\). In this research hypothesis the researcher is not positing a direction‚Äîthey are just saying we think it differs from 9 hours; it might be higher, it might be lower. What this means for identifying cases in the t-distribution that are at least as extreme as \\(-8.82\\) is that we have to identify all values less than or equal to \\(-8.82\\) AND all values greater than or equal to \\(+8.82\\). These are shown a the yellow cases in the distribution below.\n\n\n\n\n\nFigure¬†7.9: Dot plot of an example t-distribution. The vertical blue dashed lines indicates the observed value of -8.82 and its counterpart at +8.82. The yellow dots (to the left of -8.82 and to the right of +8.82) are the t-values that are at least as extreme as -8.82 based the alternative hypothesis (mu ‚â† -8.82).\n\n\n\n\nBased on this alternative hypothesis, we would have counted 4 cases that have a t-value at least as extreme as \\(-8.82\\). Based on this alternative hypothesis, the p-value would be computed as:\n\\[\n\\begin{split}\np &= \\frac{4}{300} \\\\[1ex]\n&= .013\n\\end{split}\n\\]\nBased on this p-value, which is less than .05, we would reject the null hypothesis in favor of the alternative hypothesis. This implies that the empirical evidence does not support the claim that teenagers get, on average, 9 hours of sleep, but rather that they get a different amount of sleep on average. Based on the results of this test, we cannot tell whether they get, on average, more or less sleep than 9 hours‚Äîonly that it is likely a different amount.\n\n\n\n7.3.2 p-Values in Density Plots\nIn the previous example we have looked at to compute the p-value, the t-distribution was presented as a dotplot. This makes it easy to count the observations at least as extreme as the observed value. In most cases, the t-distribution is presented as a density plot. Because individual cases are not shown in a density plot, we need to have another method of computing the p-value hat is not based on counting.\nThe method we use with density plots is to compute the area under the density curve that corresponds to at least as extreme as the observed value. Figure¬†7.10 shows both the dotplot and superimposed density curve for an example t-distribution. If the alternative hypothesis was \\(H_A:\\mu<9\\), rather than counting the cases to that are less than the observed value of \\(-8.82\\), we would find the area under the curve that is less than \\(-8.82\\). This area is shaded in the figure.\n\n\n\n\n\nFigure¬†7.10: Dot plot of an example t-distribution wityh superimposed density. The vertical blue dashed line indicates the observed value of -8.82. The yellow dots (to the left of -8.82) are the t-values that are at least as extreme as -8.82 based the alternative hypothesis (mu < -8.82). The area under the density curve that is less than -8.82 is also shaded.\n\n\n\n\nFinding the area under the density curve requires calculus, or software. We will show you how to use R to find this area in ?sec-using-r-for-t-tests. We can, however estimate this area for a quick approximation. Since the area under the entire density curve is 1, the shaded area (p-value) is found by determining the proportion that the shaded area is of the whole curve. (Remember that a proportion is a value between 0 and 1; it is not a percent.) In this example, the shaded area is roughly .01 of the whole curve, so we would say the p-value was .01.\n\nIt is very difficult to get an accurate p-value from estimating it from the density curve, especially when the p-value is small. In practice, we always use software to obtain the p-value. However, understanding that the software is calculating the area under the density curve is useful for ‚Äúgut-checking‚Äù the size of the p-value that the software gives us. For example, based on the shaded area in Figure¬†7.10, we would not expect a p-value of 0.5 since the shaded are is not half of the whole curve."
  },
  {
    "objectID": "04-03-one-sample-test.html#putting-it-all-together",
    "href": "04-03-one-sample-test.html#putting-it-all-together",
    "title": "7¬† Hypothesis Testing: One-Sample t-Test",
    "section": "7.4 Putting It All Together",
    "text": "7.4 Putting It All Together\nIt is important to not lose the forest in the trees when you are conducting a hypothesis test. We set out to answer a substantive question about whether or not teens are getting the recommended amount of sleep. All of the steps we carried out in the hypothesis test were a means to an end of actually answering this question based on the data we collected. So when we report results from the t-test, we need to not only report the pertinent statistical evidence (t-value, df, p-value), but we also need to answer the substantive/research question that drove this test in the first place. Below is an example write-up that an applied researcher might use:\n\nTo determine whether or not teens are getting the recommended amount of sleep, a one-sample t-test was used to compare the sample mean amount of sleep for 75 teens to a hypothesized population mean of 9 hours (the amount of sleep recommended by medical experts). The sample mean of 7.40 hours of sleep (SD = 1.52) was found to be inconsistent with the hypothesis that teens are getting 9 (or more) hours of sleep a night, on average; \\(t(74) = ‚àí8.82\\), \\(p = .007\\). This suggest that teens might not be getting the recommended amount of sleep every night."
  },
  {
    "objectID": "04-03-one-sample-test.html#looking-forward",
    "href": "04-03-one-sample-test.html#looking-forward",
    "title": "7¬† Hypothesis Testing: One-Sample t-Test",
    "section": "7.5 Looking Forward",
    "text": "7.5 Looking Forward\nIn the next chapter, we will introduce how to use R to carry out the one-sample t-test. Then in chapter ?sec-one-sample-examples, you will get you a chance to practice working through the process of carrying out a one-sample t-test.\nAs you work through these chapters, you will become more comfortable with the vocabulary and ideas that underlie hypothesis tests. This same set of vocabulary and ideas will come up again when we use hypothesis tests when we compare a sample proportion to a standard and to compare two samples. Because of this it may be useful to put together a summary of the ideas and vocabulary from this chapter that you can refer to (e.g., on a notecard). Here are some of the ideas and vocabulary that are important in hypothesis testing to get you started:\n\nStatistical inference\nNull hypothesis\nNull model\nAlternative hypothesis\nStandard error\nt-value\nt-distribution\np-value"
  },
  {
    "objectID": "04-04-one-sample-test-computation.html#teen-sleep-a-quick-re-cap",
    "href": "04-04-one-sample-test-computation.html#teen-sleep-a-quick-re-cap",
    "title": "8¬† Hypothesis Testing: One-Sample t-Test",
    "section": "8.1 Teen Sleep: A Quick Re-Cap",
    "text": "8.1 Teen Sleep: A Quick Re-Cap\nIn this case study, researchers collected data on the bedtime, wake-up time, and hours slept for a sample of \\(n=75\\) American teens in Grades 9‚Äì12. These data were used to evaluate the following statistical hypotheses For example, here are a set of potential hypotheses about teen sleep:\n\\[\n\\begin{split}\nH_0: \\mu = 9 \\\\[1ex]\nH_A: \\mu < 9\n\\end{split}\n\\] The analysis started by importing the data and visualizing and numerically describing the amopunt of sleep for the teens in our sample.\n\n# Create density plot\ngf_density(\n  ~ hrs_sleep, data = teen_sleep,\n  color = \"black\", \n  fill = \"skyblue\",\n  xlab = \"Hours of Sleep\",\n  ylab = \"Density\"\n  )\n\n# Compute numerical summaries\ndf_stats(~hrs_sleep, data = teen_sleep)\n\n\n\n\n\n\nFigure¬†8.1: Density plot of the hours of sleep for 75 teenagers.\n\n\n\n\n\n\nFigure¬†8.2: Density plot of the hours of sleep for 75 teenagers.\n\n\n\n\nThese analyses suggest that, on average, the 75 teens in the sample are not getting the recommended 9 hours of sleep a night. They seem to be getting much less sleep on average, with a typical teen in the sample getting around 7.5 hours of sleep a night (SD = 1.5). To evaluate whether this lower amount of sleep we are seeing in the sample data is only a function of sampling uncertainty, we will carry out a one-sample t-test. To do this, we need to convert our sample mean to a t-value and then evaluate it in a t-distribution with \\(n-1\\) df.\n\\[\nt = \\frac{\\mathrm{Obs.~Mean} - \\mathrm{Hyp.~Mean}}{SE}\n\\]\nWe have the observed mean (\\(\\bar{x}=7.39\\)), and the hypothesized mean (\\(\\mu=9\\)) from the data and null hypothesis, respectively. To obtain the SE we bootstrapped from the data.\n\n# Draw a bootstrap sample of 75 observations and compute the mean\n# Do this 1000 times \n# Assign these into an object called bootstrap_means\nset.seed(42)\nbootstrap_means <- do(1000) * {mean(sample(teen_sleep$hrs_sleep, size = 75, replace = TRUE))}\n\n# Compute numerical summaries to get SE\ndf_stats(~result, data = bootstrap_means)\n\n\n\n  \n\n\n\nBased on the bootstrapping, the SE is 0.170. Putting this together, we compute the t-value as:\n\\[\n\\begin{split}\nt &= \\frac{7.39 - 9}{.170} \\\\[2ex]\n&= -9.47\n\\end{split}\n\\] We can then sketch the t-distribution with 74 df, include the t-value we just computed, and shade the area under the density plot that corresponds to the alternative hypothesis.\n\n\n\n\n\nFigure¬†8.3: Density plot of the t-distribution of the sample means based on the thought experiment underlying a hypothesis test assuming that the mean amount of sleep for all tennagers is 9 hours (t value of 0). The blue shaded area represents the t-values we expect if the null hypothesis is true. The pink dot represents the observed t-value of -9.47.\n\n\n\n\nThe p-value (proportion of the pink shaded area to the whole area under the curve) is quite small. Because it is so small, it is difficult to even estimate its size‚Äî\\(p<.001\\). This small p-value leads us to reject the null hypothesis, indicating that the data suggest that the average amount of sleep teens are getting is likely less than 9 hours and that this result is not only because of sampling uncertainty. That is, the empirical evidence is pointing us to the conclusion that teens are not getting the recommended amount of sleep."
  },
  {
    "objectID": "04-04-one-sample-test-computation.html#using-the-t_test-function",
    "href": "04-04-one-sample-test-computation.html#using-the-t_test-function",
    "title": "8¬† Hypothesis Testing: One-Sample t-Test",
    "section": "8.2 Using the t_test() Function",
    "text": "8.2 Using the t_test() Function\nRather than bootstrapping the SE, we will use the t_test() function to compute the SE directly. This function is part of the {mosaic} library, and takes the following arguments:\n\nA formula using the tilde (~), similar to the gf_ and df_stats functions, that specifies the attribute to carry out the one-sample t-test on.\ndata= specifying the name of the data object,\nmu= indicating the value of the mean in the null hypothesis,\nalternative= indicating one of three potential alternative hypotheses: \"less\", \"greater\", or \"two.sided\" (not equal). Note that these need to be enclosed in quotation marks.\n\nTo carry out the one-sample t-test in the earlier case study, we will use the following syntax. We assign the reuslts of this t-test to an object (in this case, I called it my_t).\n\n# One-sample t-test\nmy_t <- t_test(~hrs_sleep, data = teen_sleep, mu = 9, alternative = \"less\")\n\nTo see the results of the test, you can just call my_t, or whatever you named the object storing the t-test results. The output, however, is a bit unorganized. Instead, we are going to use two functions from the {educate} package to view the results of the t-test: t_results() and plot_t_dist(). To use these functions, we will need to load the {educate} library. Then, we can use each of these functions by supplying it with the name of the object storing our t-test results. We begin by using the t_results() function.\n\n# Load educate library\nlibrary(educate)\n\n# View t-test results\nt_results(my_t)\n\n\n--------------------------------------------------\nOne Sample t-test\n--------------------------------------------------\n\nH[0]: mu = 9\nH[A]: mu < 9\n\nt(74) = -9.150303\np = 4.328872e-14\n\n--------------------------------------------------\n\n\nThis function outputs the null and alternative hypotheses being tested in the one-sample t-test. It also provide the observed t-value (\\(-9.15\\)) and the df (74) for the t-distribution. Finally, it outputs the p-value for the test. When p-values are really small, R will output the p-value in scientific notation. The e-14 part of the p-value means \\(\\times 10^{-14}\\), which means, move the decimal point 14 places to the left. Thus the p-value is:\n\\[\n\\begin{split}\np &= 4.328872 \\times 10^{-14} \\\\[2ex]\n&= .0000000000000433\n\\end{split}\n\\] Note that the t-value we get from this function was different than the t-value we got earlier. This is because the SE computed by the t_test() function is different than the SE we get when we bootstrap. Because of this, it is very important to indicate the method you used to get the t-value; was it based on bootstrapping a SE? Or did you use the t_test() function, which uses a normal-based method for computing the SE?\nWe can also use the plot_t_dist() to visualize the t-distribution with 74 df, where our observed t-value of \\(-9.15\\), falls in this distribution, and the shaded area under the curve associated with the p-value based on the specified alternative hypothesis. The results form the t-test will also be printed above the plot.\n\n# View t-distribution\nplot_t_dist(my_t)\n\n\n\n\nFigure¬†8.4: Density plot of the t-distribution of the sample means based on the thought experiment underlying a hypothesis test assuming that the mean amount of sleep for all tennagers is 9 hours (t value of 0). The red vertical line represents the observed t-value of -9.15. The shaded area under the curve to the left of -9.15 shows the associated p-value of \\(4.33\\times10^{-14} = .0000000000000433\\) that corresponds to the alternative hypothesis that \\(\\mu<9\\)."
  },
  {
    "objectID": "04-04-one-sample-test-computation.html#case-study-2-continuous-assessment",
    "href": "04-04-one-sample-test-computation.html#case-study-2-continuous-assessment",
    "title": "8¬† Hypothesis Testing: One-Sample t-Test",
    "section": "8.3 Case Study 2: Continuous Assessment",
    "text": "8.3 Case Study 2: Continuous Assessment\nTo study the practice of continuous assessment in Ethiopian primary schools, Abejehu (2016) collected survey responses from several primary school teachers. One tenet of continuous assessment is that to evaluate larning, teachers need to understand students‚Äô prior knowledge. One item on the survey asked teachers about this: ‚ÄúI always assess students‚Äô prior knowledge before starting new lesson.‚Äù Teachers responded on a Likert scale, with options: Strongly Agree (4), Agree (3), Disagree (2), and Strongly Disagree (1). The responses for 30 teachers is given in the prior_knowledge attribute of the continuous-assessment.csv file (see codebook for additional detail)."
  },
  {
    "objectID": "04-04-one-sample-test-computation.html#looking-forward",
    "href": "04-04-one-sample-test-computation.html#looking-forward",
    "title": "8¬† Hypothesis Testing: One-Sample t-Test",
    "section": "8.4 Looking Forward",
    "text": "8.4 Looking Forward\nIn the next chapter, we will introduce how to use R to carry out the one-sample t-test. Then in chapter ?sec-one-sample-examples, you will get you a chance to practice working through the process of carrying out a one-sample t-test.\nAs you work through these chapters, you will become more comfortable with the vocabulary and ideas that underlie hypothesis tests. This same set of vocabulary and ideas will come up again when we use hypothesis tests when we compare a sample proportion to a standard and to compare two samples. Because of this it may be useful to put together a summary of the ideas and vocabulary from this chapter that you can refer to (e.g., on a notecard). Here are some of the ideas and vocabulary that are important in hypothesis testing to get you started:\n\nStatistical inference\nNull hypothesis\nNull model\nAlternative hypothesis\nStandard error\nt-value\nt-distribution\np-value\n\n\n\n\n\n\n\nAbejehu, S. B. (2016). The Practice of Continuous Assessment in Primary Schools: The Case of Chagni, Ethiopia. Journal of Education and Practice."
  }
]