[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "An Introduction to Data Analysis",
    "section": "",
    "text": "Foreword\nThis work in progress is ultimately going to be the primarily textbook resource for EPSY 5261 students. (Note: If you want to contribute to this, create a Pull Request or send me an email.) Also, feel free to offer criticism, suggestion, and feedback. You can either open an issue on the book‚Äôs github page or send me an email directly.",
    "crumbs": [
      "Foreword"
    ]
  },
  {
    "objectID": "index.html#acknowledgments",
    "href": "index.html#acknowledgments",
    "title": "An Introduction to Data Analysis",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nMany thanks to all the students in our courses who have provided feedback; you are the world‚Äôs greatest copyeditors. In particular, we would like to thank the following students who found errors and took the time to let us know: Drake Bauer, William Cornejo, Christie Nixon, Guobin Pan, and Joel Sundstrom.",
    "crumbs": [
      "Foreword"
    ]
  },
  {
    "objectID": "index.html#colophon",
    "href": "index.html#colophon",
    "title": "An Introduction to Data Analysis",
    "section": "Colophon",
    "text": "Colophon\nArtwork by @allison_horst\nIcon and note ideas and prototypes by Desir√©e De Leon.\nThe book is typeset using Crimson Text for the body font, Raleway for the headings and Sue Ellen Francisco for the title. The color palette was generated using coolors.co.\nStatistical Computing\n\nLaptop icon made by Tomas Knop from www.flaticon.com\nDirectory icon made by Darius Dan from www.flaticon.com\nBrain icon made by Aranagraphics from www.flaticon.com\nInternet icon made by Freepik from www.flaticon.com",
    "crumbs": [
      "Foreword"
    ]
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "An Introduction to Data Analysis",
    "section": "License",
    "text": "License\nThis work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License.",
    "crumbs": [
      "Foreword"
    ]
  },
  {
    "objectID": "01-00-statistical-computation.html#footnotes",
    "href": "01-00-statistical-computation.html#footnotes",
    "title": "Statistical Computation",
    "section": "",
    "text": "Specifically, RStudio is branded as an ‚Äúintegrated development environment (IDE) [that] includes a console, syntax-highlighting editor that supports direct code execution, as well as tools for plotting, history, debugging and workspace management.‚Äù‚Ü©Ô∏é",
    "crumbs": [
      "Statistical Computation"
    ]
  },
  {
    "objectID": "01-01-r-and-rstudio-installation.html",
    "href": "01-01-r-and-rstudio-installation.html",
    "title": "1¬† R and RStudio: Installation and Setup",
    "section": "",
    "text": "1.1 Installing R\nTo install R, navigate your web browser to:\nhttps://www.r-project.org/\nThen,\nThis is where the installation directions diverge depending on your OS.\nMac Instructions\nSo long as you are running MacOS 10.13 or higher just click the first link for the PKG, which will download the installer for the most current version of R (4.1.1 as of August 16, 2021). Once the download completes, open the installer and follow the directions to install R on your computer.\nIf you are running an older version of MacOS, you will have to install an older version of R. You can find these links under the Binaries for legacy OS X systems heading further down the install page. Click the appropriate PKG link for R your version of MacOS. Once the download completes, open the installer and follow the directions to install R on your computer.\nIf you are unsure which version of the MacOS is running on your computer, select About this Mac from the Apple menu in your toolbar.\nWindows Instructions\nClick the link that says Install R for the first time (or click base; they go to the same place). Then click the Download R 4.1.1 for Windows link, which will download the installer for the most current version of R (4.0.2 as of July 24, 2020). Once the download completes, open the installer and follow the directions to install R on your computer.\nLinux Instructions\nIf you are running Linux, you should know how to install things on your computer. üòä",
    "crumbs": [
      "Statistical Computation",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>R and RStudio: Installation and Setup</span>"
    ]
  },
  {
    "objectID": "01-01-r-and-rstudio-installation.html#installing-r",
    "href": "01-01-r-and-rstudio-installation.html#installing-r",
    "title": "1¬† R and RStudio: Installation and Setup",
    "section": "",
    "text": "Click the CRAN link under Download on the left-hand side of the page.\nSelect a mirror site. These should all be the same, but I tend to choose the Iowa State University link under USA.1\nIn the Download and Install R box, choose the binary that matches the operating system (OS) for your computer.",
    "crumbs": [
      "Statistical Computation",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>R and RStudio: Installation and Setup</span>"
    ]
  },
  {
    "objectID": "01-01-r-and-rstudio-installation.html#installing-rstudio-desktop",
    "href": "01-01-r-and-rstudio-installation.html#installing-rstudio-desktop",
    "title": "1¬† R and RStudio: Installation and Setup",
    "section": "1.2 Installing RStudio Desktop",
    "text": "1.2 Installing RStudio Desktop\nAfter you have installed R, you next need to install RStudio Desktop. To do this, navigate your web browser to:\n\nhttps://rstudio.com/products/rstudio/download/\n\nThen,\n\nSelect the blue Download button under the free, open-source version of RStudio Desktop.\nSelect the installer associated with your computer‚Äôs OS.\nOnce the download completes, open the installer and follow the directions to install RStudio Desktop on your computer.",
    "crumbs": [
      "Statistical Computation",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>R and RStudio: Installation and Setup</span>"
    ]
  },
  {
    "objectID": "01-01-r-and-rstudio-installation.html#checking-that-things-worked",
    "href": "01-01-r-and-rstudio-installation.html#checking-that-things-worked",
    "title": "1¬† R and RStudio: Installation and Setup",
    "section": "1.3 Checking that Things Worked",
    "text": "1.3 Checking that Things Worked\nFrom your Applications or Programs folder, open RStudio. If you have successfully downloaded both programs, this should open the application and you should see a message indicating that you are using ‚ÄúR version 4.1.1‚Äù (or whichever version of R you installed) in the console pane.\n\n\n\n\n\nOnce you open RStudio, you should see a message indicating that you are using R version 4.1.1 (or whichever version of R you installed) in the console pane. Here the console pane is on the left-side, but it may be in a different location for you. Your RStudio may also have a white background rather than the black background seen here.",
    "crumbs": [
      "Statistical Computation",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>R and RStudio: Installation and Setup</span>"
    ]
  },
  {
    "objectID": "01-01-r-and-rstudio-installation.html#customizing-rstudio",
    "href": "01-01-r-and-rstudio-installation.html#customizing-rstudio",
    "title": "1¬† R and RStudio: Installation and Setup",
    "section": "1.4 Customizing RStudio",
    "text": "1.4 Customizing RStudio\nWhile the information in this section is not crucial for making things work, it is useful to get RStudio looking good and setting some default settings. Open the Tools &gt; Options menu (Windows) or RStudio &gt; Preferences (Mac).\n\n\n\n\n\nThe RStudio options/preferences menu has many settings to customize RStudio.\n\n\n\n\n\nIn the General &gt; Basic settings, change the option on Save workspace to .Rdata on exit to be ‚ÄúNever‚Äù. Click the ‚ÄúApply‚Äù button.\nIn the Appearance settings, customize the look of RStudio to something aesthetically appealing to you. When you are finished, click the ‚ÄúApply‚Äù button.\nThere are also options you can set in the Accessibility settings if you use a screen reader. If you change anything, don‚Äôt forget to click the ‚ÄúApply‚Äù button.\n\nWhen you are finished customizing RStudio, click the ‚ÄúOK‚Äù button.",
    "crumbs": [
      "Statistical Computation",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>R and RStudio: Installation and Setup</span>"
    ]
  },
  {
    "objectID": "01-01-r-and-rstudio-installation.html#install-rtoolscommand-line-tools",
    "href": "01-01-r-and-rstudio-installation.html#install-rtoolscommand-line-tools",
    "title": "1¬† R and RStudio: Installation and Setup",
    "section": "1.5 Install Rtools/Command Line Tools",
    "text": "1.5 Install Rtools/Command Line Tools\nYou may need to install some additional functionality to your system in order to get certain packages to install or load properly. On a Windows machine, you might need to install Rtools. Mac users might need to add the Command Line Tools. These tools also allow you to write and compile your own R packages. RStudio has well written instructions for adding these tools at: https://support.rstudio.com/hc/en-us/articles/200486498-Package-Development-Prerequisites.",
    "crumbs": [
      "Statistical Computation",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>R and RStudio: Installation and Setup</span>"
    ]
  },
  {
    "objectID": "01-01-r-and-rstudio-installation.html#footnotes",
    "href": "01-01-r-and-rstudio-installation.html#footnotes",
    "title": "1¬† R and RStudio: Installation and Setup",
    "section": "",
    "text": "When internet used to be dial-up (i.e., super slow), you wanted to choose a mirror site that was closest in proximity to your location as it sped up the download. This is less of a concern now that internet download speeds are much faster.‚Ü©Ô∏é",
    "crumbs": [
      "Statistical Computation",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>R and RStudio: Installation and Setup</span>"
    ]
  },
  {
    "objectID": "01-02-getting-started-with-r.html",
    "href": "01-02-getting-started-with-r.html",
    "title": "2¬† Getting Started with R",
    "section": "",
    "text": "2.1 Computing in the Console\nThere are a several ways to interact with R within RStudio. One of those methods is to issue commands in the RStudio console pane. Computing in the console is similar to working with a calculator: you enter syntax and R runs the syntax. The &gt; symbol in the console pane is called the ‚ÄúR prompt‚Äù and is prompting you to enter syntax. After you enter any syntax, you hit the  or  key to execute the syntax.\nThe console pane in RStudio is one way to compute with R. Syntax is entered at the R prompt and executed by hitting the  or  key.\nTo get started, we will have R carry out some arithmetic. At the prompt enter each of the following lines of syntax. After each line, hit the &lt;return&gt; or &lt;enter&gt; key.\n# Addition\n2 + 3\n\n# Subtraction\n6 - 10\n\n# Multiplication\n4 * 5\n\n# Division\n23 / 2\n\n# Exponents\n10 ^ 3\nExecuting each line of syntax returns the results of the computation in the console pane. The result, in R parlance, is referred to as a ‚Äúreturned value‚Äù. After executing the computation, the R prompt reappears and you can issue a new line of syntax.\nContinuation Prompt: At some point in your computational career, you will likely encounter the continuation prompt. Symbolized by +, this prompt appears instead of the R prompt to indicate that you did not complete the syntax you entered prior to hitting the  key. For example, suppose while entering the division syntax from above you got excited and hit the &lt;enter&gt; key after inputting the slash; before inputting the 2. You would see the continuation prompt:\nThe continuation prompt tells you that the syntax you started to enter is still active. If you now enter 2 and hit the &lt;enter&gt; key, the syntax will be executed as if you had not inadvertently hit &lt;enter&gt; in the middle of the computation. If you are in the middle of a more complex piece of syntax, you could also hit the &lt;esc&gt; key until the R prompt is re-shown. Then you can start the computation over.\nSpace in Syntax: For the computation in R, space is irrelevant. For example, each of the following syntactical statements is equivalent:\n4 * 5\n4*5\n4    *            5\nThat being said, well-written code includes space! Space in code makes it easier to read and debug, in the same way that including space in written prose helps us read and parse words, sentences, and paragraphs.",
    "crumbs": [
      "Statistical Computation",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Getting Started with R</span>"
    ]
  },
  {
    "objectID": "01-02-getting-started-with-r.html#computing-in-the-console",
    "href": "01-02-getting-started-with-r.html#computing-in-the-console",
    "title": "2¬† Getting Started with R",
    "section": "",
    "text": "&gt; 23 /\n+",
    "crumbs": [
      "Statistical Computation",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Getting Started with R</span>"
    ]
  },
  {
    "objectID": "01-02-getting-started-with-r.html#script-files-recording-your-syntax",
    "href": "01-02-getting-started-with-r.html#script-files-recording-your-syntax",
    "title": "2¬† Getting Started with R",
    "section": "2.2 Script Files: Recording Your Syntax",
    "text": "2.2 Script Files: Recording Your Syntax\nIt is important to be able to record the syntax you use. This acts as a way of ‚Äúsaving‚Äù your work, and it also acts as a record of the analysis for your collaborators in the spirit of reproducible work. One way to record the R syntax you use is to employ a script file. You can create a new script file by selecting File &gt; New File &gt; R Script from the RStudio menu bar. You can also obtain a new R script by clicking the New File icon (document with the plus-sign) on the tool bar and selecting R Script.\n\n\n\n\n\nLEFT: Create a new script file using RStudio‚Äôs File menu. RIGHT: Create a new script file by clicking on the New File icon in the toolbar.\n\n\n\n\nScript files should only include your R syntax and comments. Script files should NOT include:\n\nprompts (&gt;)\noutput\n\nComments, which are human-readable annotations or explanations of the syntax, are written using the hashtag (#). These can be placed on their own line in the script file, or can be placed at the end of a line with syntax. The comment continues until you hit the  key. Comments help other people understand your syntax and also act as a reminder for the future you of what your code actually does. Get is the habit of including comments in your syntax. Not only is it good coding practice, but it also will help you become familiar with and learn the R syntax as you describe the purpose of the syntax you are writing.\n\n\n\n\n\nExample script file with comments.\n\n\n\n\nScript files can be saved and opened the same as any other document. So, no more worrying about losing your work or objects that you created when you close your R sesssion. Just open your saved script file, highlight the parts you want to re-run, and click the Run button!\n\n\n2.2.1 Executing Syntax from a Script File\nNot only does the script file record your syntax, but it can also act as the vehicle from which you run your R syntax. Syntax in the script file can be executed by highlighting it and pressing the Run button in the toolbar. You can run one line at a time, or highlight multiple lines and execute all of them sequentially.\n\n\n\n\n\nTo execute syntax from the script file, highlight the syntax you want to run and then click the Run button in the toolbar.\n\n\n\n\nWriting syntax directly in the script file and running it is a groovy workflow for using R. Writing syntax directly in the script file also saves you from having to copy-and-paste syntax you want to save from the console. In my own work, I use this workflow almost daily.",
    "crumbs": [
      "Statistical Computation",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Getting Started with R</span>"
    ]
  },
  {
    "objectID": "01-02-getting-started-with-r.html#functions-the-workhorse-of-r",
    "href": "01-02-getting-started-with-r.html#functions-the-workhorse-of-r",
    "title": "2¬† Getting Started with R",
    "section": "2.3 Functions: The Workhorse of R",
    "text": "2.3 Functions: The Workhorse of R\nAlmost all commands in R are built around the use of a function. Functions carry out operations on their inputs (called arguments) and produce an output (called a returned value).\n\n\n\n\n\nLEFT: Arguments are inputted into a function which returns an output. RIGHT: The value 25 is inputted into the square root function which returns the value of 5.\n\n\n\n\nThe syntax for using most functions in R follows a simple structure: The name of the function is followed by a pair of parentheses. Argument values (inputs) are specified inside the parentheses. In general,\n\nfunction_name(argument)\n\nBelow are several example of this structure for some common mathematical functions.\n\n#Square root\nsqrt(100)\n\n[1] 10\n\n#Absolute value\nabs(-23)\n\n[1] 23\n\n#Factorial\nfactorial(5)\n\n[1] 120\n\n\nFunctions can take multiple arguments (inputs). If there is more than one argument, the arguments are always separated by a comma.\n\nfunction_name(argument_1, argument_2, ...)\n\nFor example, the seq() function creates a sequence of values that have a particular start and end value.\n\nseq(1, 5)\n\n[1] 1 2 3 4 5\n\n\nNote that the order of the arguments matters! Reversing the order of the arguments inputted to the seq() function returns different output.\n\nseq(5, 1)\n\n[1] 5 4 3 2 1\n\n\nEach of the arguments actually has a name, and if those names are used to assign the values we are inputting to the function, then the order of the arguments is irrelevant.\n\n# Named arguments\nseq(from = 1, to = 5)\n\n[1] 1 2 3 4 5\n\n# Order no longer matters\nseq(to = 5, from = 1)\n\n[1] 1 2 3 4 5\n\n\nIt is a good habit to use named arguments when you are writing your syntax. It makes the code more readable and easier to adapt if you come back to it later. Sometimes when the initial argument of a function is well-established, that first argument is left unnamed, but all other arguments used are named. A good example of this is the use of the lm() function in which the initial formula= argument is typically unnamed, but other arguments (e.g., data=) are named.",
    "crumbs": [
      "Statistical Computation",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Getting Started with R</span>"
    ]
  },
  {
    "objectID": "01-02-getting-started-with-r.html#connecting-computations",
    "href": "01-02-getting-started-with-r.html#connecting-computations",
    "title": "2¬† Getting Started with R",
    "section": "2.4 Connecting Computations",
    "text": "2.4 Connecting Computations\nOne powerful aspect of computing is that the output from a function can be used as input into another function. This is akin to calculations you may have encountered in mathematics course like algebra. For example,\n\\[\n\\sqrt{\\log(100)}\n\\]\nIn carrying out this calculation, you would first compute the logarithm of 100 and then take the square root of that result. Using function notation, your algebra teacher might have written\n\\[\ng(~f(x)~)\n\\]\nwhere \\(f(x)\\) is the logarithm function and \\(g(x)\\) is the square root function. Regardless of how we express this,the idea is that the output of the logarithm function is used as input to the square root function. Using R, there are two primary ways to connect computations in this manner: chaining and assignment.\n\n\n2.4.1 Chaining\nChaining is a direct reflection of the functional notation \\(g(~f(x)~)\\) in that you embed one computation directly in another. For example, to find the absolute value of all the integers between \\(-5\\) and \\(-1\\), we can chain the abs() function and the seq() functions:\n\nabs( seq(from = -5, to = -1) )\n\n[1] 5 4 3 2 1\n\n\nNote here that the output/returned value is not a single value, but five values. The absolute value function was applied to each of the values in the sequence. Compare this to the result from the following chained computations:\n\nmean( seq(from = -5, to = -1) )\n\n[1] -3\n\n\nHere the mean function applied to the sequence of values returns a single value as output. When a function is applied to a set of multiple values (i.e., a vector), some functions will apply their computations separately on each element/value (element-wise computation returns multiple values), while others will apply the computation to the set of elements as a whole (vector-wise computation returns a single value). Most of the time it will be clear from the function name or description whether the output returns a single value or multiple values.\nWe can chain as many computations together as we would like. For example here we find the square root of the absolute value of all the integers between \\(-5\\) and \\(-1\\).\n\nsqrt( abs( seq(from = -5, to = -1) ) )\n\n[1] 2.236068 2.000000 1.732051 1.414214 1.000000\n\n\n\n\n\n2.4.2 Assignment\nWe can also connect computations through assignment. With assignment, we store the output of a computation by assigning it to a named object using the assignment operator &lt;-. We can then use that named object in another computation. For example, here we first store the integers between \\(-5\\) and \\(-1\\) in an object called chili. Then we find the absolute value of each value by using chili as the argument in the abs() function.\n\n# Assign the sequence to the object chili\nchili &lt;- seq(from = -5, to = -1) \n\n# Compute the absolute values\nabs(chili)\n\n[1] 5 4 3 2 1\n\n\nTo view the contents of an object, just print the name of the object. Below, after creating the object sadie, we view its contents.\n\n# Assign values to sadie\nsadie &lt;- rep(3, times = 5) \n\n# View contents of sadie\nsadie\n\n[1] 3 3 3 3 3\n\n\nPretty much any name can be used when you create an object, with some caveats: object names cannot begin with a digit nor include hyphens or spaces. Although they are legal object names, chili and sadie are not particularly good object names. Better object names would describe the contents of the object.\nIn my own workflow, I tend to use all lowercase letters in my object names and I use underscores for word breaks. For example,\n\nses, gpa, occupation\nact_math, mothers_educ\n\n\n\n\n2.4.3 Objects in the R Working Environment\nWe can continue to use the objects you created (e.g., chili and sadie) in our computations, so long as the objects remain in our R working environment.\n\n# Sum the pairwise elements of the two objects\nchili + sadie\n\n[1] -2 -1  0  1  2\n\n# Sum all the elements in chili\nsum(chili)\n\n[1] -15\n\n# Product of all the elements in sadie\nprod(sadie)\n\n[1] 243\n\n\nIn RStudio you can see which objects are in your working environment by examining the Environment pane.\n\n\n\n\n\nThe enivironment pane shows the objects in the R working environment. It also displays the object‚Äôs class and gives a preview of the the contents.\n\n\n\n\nNot only does this pane indicate the name of the objects in the working environment, but is also displays each object‚Äôs class. In this case we can tell that chili is an integer vector and sadie is a numeric vector.1 Moreover, we are told that each vector includes five elements, shown in the environment pane as [1:5]. Lastly, we are given a preview of each object‚Äôs contents. Since these vectors only contain five elements, we see all the values in the preview.\nYou can also use syntax to obtain a list of objects that are in your working environment using the ls() function with no arguments.\n\n# List the objects in working environment\nls()\n\n[1] \"chili\" \"sadie\"\n\n\nWhen an object name is re-used, the previous value of the object is lost.\n\n# Assign the values 1 to 10 in chili\nchili &lt;- seq(from = 1, to = 10)\n\nAfter assigning new values to chili, we can see the information in the environment pane has been updated to reflect the new contents of the object.\n\n\n\n\n\nThe object chili although still an integer vector, now includes 10 elements.\n\n\n\n\nAny computations carried out with chili will use the new object.\n\n# Sum all the elements in chili\nsum(chili)\n\n[1] 55\n\n\nIf you want the previous version of chili you need to re-create the object. If you close your R session all of the objects you created will be lost.",
    "crumbs": [
      "Statistical Computation",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Getting Started with R</span>"
    ]
  },
  {
    "objectID": "01-02-getting-started-with-r.html#script-files-recording-your-syntax-1",
    "href": "01-02-getting-started-with-r.html#script-files-recording-your-syntax-1",
    "title": "2¬† Getting Started with R",
    "section": "2.5 Script Files: Recording Your Syntax",
    "text": "2.5 Script Files: Recording Your Syntax\nIt is important to be able to record the syntax you use. This acts as a way of ‚Äúsaving‚Äù your work, and it also acts as a record of the analysis for your collaborators in the spirit of reproducible work. One way to record the R syntax you use is to employ a script file. You can create a new script file by selecting File &gt; New File &gt; R Script from the RStudio menu bar. You can also obtain a new R script by clicking the New File icon (document with the plus-sign) on the tool bar and selecting R Script.\n\n\n\n\n\nLEFT: Create a new script file using RStudio‚Äôs File menu. RIGHT: Create a new script file by clicking on the New File icon in the toolbar.\n\n\n\n\nScript files should only include your R syntax and comments. Script files should NOT include:\n\nprompts (&gt;)\noutput\n\nComments, which are human-readable annotations or explanations of the syntax, are written using the hashtag (#). These can be placed on their own line in the script file, or can be placed at the end of a line with syntax. The comment continues until you hit the  key. Comments help other people understand your syntax and also act as a reminder for the future you of what your code actually does. Get is the habit of including comments in your syntax. Not only is it good coding practice, but it also will help you become familiar with and learn the R syntax as you describe the purpose of the syntax you are writing.\n\n\n\n\n\nExample script file with comments.\n\n\n\n\n\nYour Turn\nOpen a new script file and add the some syntax to sum two numbers. Also add a comment to describe this computation. Save your script file to your computer.\n\nShow/Hide Solution\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.5.1 Executing Syntax from a Script File\nNot only does the script file record your syntax, but it can also act as the vehicle from which you run your R syntax. Syntax in the script file can be executed by highlighting it and pressing the Run button in the toolbar. You can run one line at a time, or highlight multiple lines and execute all of them sequentially.\n\n\n\n\n\nTo execute syntax from the script file, highlight the syntax you want to run and then click the Run button in the toolbar.\n\n\n\n\nWriting syntax directly in the script file and running it is a groovy workflow for using R. Writing syntax directly in the script file also saves you from having to copy-and-paste syntax you want to save from the console. In my own work, I use this workflow almost daily.\n\nScript files can be saved and opened the same as any other document. So, no more worrying about losing your work or objects that you created when you close your R session. Just open your saved script file, highlight the parts you want to re-run, and click the Run button!\n\n\nYour Turn\nRun the syntax to sum two numbers from your script file.\n\nShow/Hide Solution\n\n\nIf this worked, you should see the result of your computation in the console pane. Note that when you run your script nothing changes in the script file itself; the output is printed in the console pane. Remember, we do not include output in the script file.",
    "crumbs": [
      "Statistical Computation",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Getting Started with R</span>"
    ]
  },
  {
    "objectID": "01-02-getting-started-with-r.html#installing-and-loading-r-packages",
    "href": "01-02-getting-started-with-r.html#installing-and-loading-r-packages",
    "title": "2¬† Getting Started with R",
    "section": "2.6 Installing and Loading R Packages",
    "text": "2.6 Installing and Loading R Packages\nEvery R function is housed in a package. To use the functions in a particular package, the package needs to be (1) installed, and (2) loaded into memory.\n\n\n\n\n\nPackages need to be installed and loaded.\n\n\n\n\nYou can see the packages (and which version of each package) are installed by examining the Packages tab in RStudio. Every package listed there has been installed. You will also be able to see the version number of the package that is installed. Some of those packages may be checked. These are the packages that are also loaded into memory.\n\n\n\n\n\nThe packages tab shows which packages are installed. The list of packages you have installed will likely be different. Checked packages are loaded into memory. In the packages seen here, only the base package is loaded into memory.\n\n\n\n\nTwenty-nine packages were included when you installed R on your computer. When you start an R session by opening RStudio, some of those packages are also loaded into memory.\n\n\n\n\n\nThe 29 packages installed as part of R. The base, datasets, graphics, grDevices, methods, stats, and utils packages are loaded into memory when you start an R session. The other 22 packages are installed but not loaded into memory.\n\n\n\n\n\n\n2.6.1 Loading Packages into Memory\nTo load a package that is installed, you use the library() function and include the name of the package you want to load in as the sole argument. For example, to load the {splines} package, use the following syntax:\n\n# Load splines package\nlibrary(splines)\n\nSome packages requires other packages (dependencies) to work. For example, the {lme4} package is dependent on the {Matrix} package. When you load packages that have dependencies, R will also load the dependencies (assuming you have them installed). When it does this, a message will be printed after you execute library(). For example, here is what happens when we load the {lme4} package.\n\nlibrary(lme4)\n\nLoading required package: Matrix\n\n\n\nOnce the package is loaded, all of the functions, data sets, etc. in that package are available to you. Packages will need to be loaded every time you launch a new R session. Because of this it is good practice to load all of your packages at the top of your script file!\n\n\n\n2.6.1.1 Masked Objects\nSometimes you will get a message about objects being masked. This is not a problem. It is just informative and means that the package you just loaded has a function that has the exact same name as a previously loaded package. If you use that particular function, the most recently loaded package‚Äôs version of the function will be used. For example, after loading the {dplyr} library the following message is printed:\nAttaching package: ‚Äòdplyr‚Äô\n\nThe following objects are masked from ‚Äòpackage:stats‚Äô:\n\n    filter, lag\n\nThe following objects are masked from ‚Äòpackage:base‚Äô:\n\n    intersect, setdiff, setequal, union\nThis tells me that the {dplyr} package includes six functions that have the same name as functions included in other packages that have already been loaded into memory (two from the {stats} package and four from the {base} package.) Since {dplyr} was the most recently loaded package, if you were to use the filter() function, R would use {dplyr}‚Äôs filter() function rather than that from the {stats} package2.\n\n\n\n2.6.1.2 Error Loading a Package\nOnce in a while, when loading a package, you may get an error. Don‚Äôt panic. There are two errors that are common. The first error you may get indicates that the package did not get installed. For example, if the {ggplot2} package was not installed, trying to use the library() function to load that package would result in an error.\n\nlibrary(ggplot2)\n\nError in library(ggplot2) : there is no package called ‚Äòggplot2‚Äô\nSimply install the package and then re-try loading it.\nThe second error that you might run across when trying to load a package occurs when the installation did not include the package dependencies. For example,\n\nlibrary(odbc)\n\nError: package or namespace load failed for ‚Äòodbc‚Äô in loadNamespace(j &lt;- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]):\nthere is no package called ‚ÄòRcpp‚Äô\nAgain, don‚Äôt panic! Here the error message is saying that the {Rcpp} package is a dependency and it is not installed. To fix this, install the {Rcpp} package and then try again. (You may need to open a new R session first.) You may need to install more than one dependency, so just keep installing what is missing until it works.\n\n\n\n\n2.6.2 Adding Functionality: Installing Packages\nYou can also install other packages onto your R system. R, in fact, has a repository called CRAN3, that includes 16,000 different packages (as of July 2020). The easiest way to install a package from CRAN onto your computer is to use the Install button in the `Packages tab of RStudio.\nThis will open a pop-up window where you can type the CRAN package you want to install in a text box. Ensure that the ‚ÄúInstall dependencies‚Äù box is checked (this will also install any package dependencies), and then click ‚ÄúInstall‚Äù.\n\n\n\n\n\nPop-up window to install packages. Here we are installing the dplyr package. Note that the ‚ÄòInstall dependencies‚Äô box is checked.\n\n\n\n\nYou may be prompted to choose a nearest mirror. If so, choose a mirror location. If you are successful in installing the package, you will get a message like the following:\nInstalling package into ‚Äò/Users/zief0002/Library/R/4.0/library‚Äô\n(as ‚Äòlib‚Äô is unspecified)\ntrying URL 'https://cran.rstudio.com/bin/macosx/contrib/4.0/dplyr_1.0.0.tgz'\nContent type 'application/x-gzip' length 1209135 bytes (1.2 MB)\n==================================================\ndownloaded 1.2 MB\n\n\nThe downloaded binary packages are in\n    /var/folders/s3/sqlc9xw92w54166w86dgkd000000gr/T//Rtmps80Uf8/downloaded_packages\nThe message you get on Windows may be slightly different, but the key is that there is not an error. Furthermore, you should immediately be able to load the package using the library() function.\nAn equivalent manner of installing a package via syntax is to use the install.packages() function. For example, to install the {dplyr} package we could have used the following syntax:\n\ninstall.packages(\"dplyr\", dependencies = TRUE)\n\nNote that the name of the package is included in quotation marks (it is a character string). The argument dependencies=TRUE installs all package dependencies, similar to checking the ‚ÄúInstall dependencies‚Äù box in the pop-up menu.\n\n\n2.6.2.1 Installing Packages from GitHub\nCRAN is not the only place to get R packages. Many developers add packages to a website called GitHub. Packages hosted on GitHub can be installed using the install_github() function from the {remotes} package.\nFirst, you will need to install the {remotes} package from CRAN and then load it using the library() function. Then, you can use the install_github() function to actually install the package. This function is provided a character string that specifies the user name and GitHub repository for the package, separated by a slash. You can find this in the part of the URL that follows ‚Äúhttps://github.com/‚Äù in your web browser. For example, the URL for the {educate} package is: ‚Äúhttps://github.com/zief0002/educate‚Äù, so to install this we would use:\n\n# Load remotes package\nlibrary(remotes)\n\n# Install dplyr from GitHub\ninstall_github(\"zief0002/educate\")\n\nThe message I get when installing this is\nInstalling package into ‚Äò/Users/zief0002/Library/R/4.0/library‚Äô\n(as ‚Äòlib‚Äô is unspecified)\n* installing *source* package ‚Äòeducate‚Äô ...\n** using staged installation\n** R\n** inst\n** byte-compile and prepare package for lazy loading\n** help\n*** installing help indices\n*** copying figures\n** building package indices\n** installing vignettes\n** testing if installed package can be loaded from temporary location\n** testing if installed package can be loaded from final location\n** testing if installed package keeps a record of temporary installation path\n* DONE (educate)\nThe ‚ÄúDONE‚Äù message typically signified successful installation. Note that you may be prompted to update some packages. If you get this message, choose the option to update ‚ÄúALL‚Äù packages. As with packages installed from CRAN, if things worked you should be able to load the package you just installed using the library() function without any errors.\n\n\n\n\n2.6.3 Install Rtools/Command Line Tools\nYou may need to install some additional functionality to your system in order to get certain packages to install or load properly. On a Windows machine, you might need to install Rtools. Mac users might need to add the Command Line Tools. These tools also allow you to write and compile your own R packages. RStudio has well written instructions for adding these tools at: https://support.rstudio.com/hc/en-us/articles/200486498-Package-Development-Prerequisites.",
    "crumbs": [
      "Statistical Computation",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Getting Started with R</span>"
    ]
  },
  {
    "objectID": "01-02-getting-started-with-r.html#footnotes",
    "href": "01-02-getting-started-with-r.html#footnotes",
    "title": "2¬† Getting Started with R",
    "section": "",
    "text": "The difference between the two classes is technical and related to how R internally stores the information in the vector.‚Ü©Ô∏é\nIf you really wanted to use the filter() function from the {stats} package you could specify this in the syntax using the :: operator, stats::filter(). This operator also allows you to use a function without loading the package with the library() function.‚Ü©Ô∏é\n‚ÄúCRAN is a network of ftp and web servers around the world that store identical, up-to-date, versions of code and documentation for R.‚Äù‚Ü©Ô∏é",
    "crumbs": [
      "Statistical Computation",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Getting Started with R</span>"
    ]
  },
  {
    "objectID": "01-03-data-structures-in-r.html",
    "href": "01-03-data-structures-in-r.html",
    "title": "3¬† Data Structures in R",
    "section": "",
    "text": "3.1 Vectors\nVectors (the single-column bookcases in our metaphor) are perhaps the most common data structure you will encounter in R. In fact, even the data frame is composed of vectors; each column is a vector. There are many ways to create a vector in R, in fact you have already been introduced to a couple of them: seq() and rep(). These are useful to create sequences of values and vectors with repeated values, respectively. But what if you wanted to create the vector of the Spice Girls‚Äô ages when the band was formed in 1994 (the values in the second column in the picture above)?\nTo create a vector of these ages, we can use the c() function to input each of the five ages. Within this function, each age is separated by a comma‚Äîeach input is a separate argument to the c() function. We will also assign this to an object called age.\n# Create age vector\nage = c(19, 20, 18, 22, 20)\n\n# View vector\nage\n\n[1] 19 20 18 22 20\nNote that once we assign create age it shows up in our global environment. In the technical language of R, each age is an element of the vector. All of the elements in the age vector are numeric values. This is the vector‚Äôs type.3 Lastly, there are five elements in the vector.\nOnce you have created a numeric vector, you can compute on it. For example in the syntax below we compute the mean age, the standard deviation of the ages, and count the elements in the vector.\n# Compute mean\nmean(age)\n\n[1] 19.8\n\n# Compute standard deviation\nsd(age)\n\n[1] 1.48324\n\n# Count elements\nlength(age)\n\n[1] 5",
    "crumbs": [
      "Statistical Computation",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Data Structures in R</span>"
    ]
  },
  {
    "objectID": "01-03-data-structures-in-r.html#vectors",
    "href": "01-03-data-structures-in-r.html#vectors",
    "title": "3¬† Data Structures in R",
    "section": "",
    "text": "3.1.1 Logical Vectors\nAnother common vector type you will encounter is the logical vector. Each element in a logical vector is either TRUE or FALSE (all uppercase letters). You could use the c() function to create a logical vector. For example, to create the original_member vector we could use the following syntax:\n\n# Create logical vector\noriginal_member = c(TRUE, TRUE, FALSE, TRUE, FALSE)\n\n# View vector\noriginal_member\n\n[1]  TRUE  TRUE FALSE  TRUE FALSE\n\n\nIt is more common to create logical vectors through computation using logical operators. For example we might ask which elements of the age object are greater than 20.\n\n# Which elements of age &gt; 20\nage &gt; 20\n\n[1] FALSE FALSE FALSE  TRUE FALSE\n\n\nThe result of using the logical operator &gt; is a logical vector. There are several logical operators in addition to &gt;:\n\n# greater than or equal to 20\nage &gt;= 20\n\n[1] FALSE  TRUE FALSE  TRUE  TRUE\n\n# less than 20\nage &lt; 20\n\n[1]  TRUE FALSE  TRUE FALSE FALSE\n\n# less than or equal to 20\nage &lt;= 20\n\n[1]  TRUE  TRUE  TRUE FALSE  TRUE\n\n# equal to 20\nage == 20\n\n[1] FALSE  TRUE FALSE FALSE  TRUE\n\n# not equal to 20\nage != 20\n\n[1]  TRUE FALSE  TRUE  TRUE FALSE\n\n\nNote that the logical operator for ‚Äúequal to‚Äù is two equals signs. This is because = (one equal sign) is what we use for assignment . If you wrote age=20 you would be assigning the value 20 to age, not asking whether the elements in age are equal to 20!\nLogical elements have numeric values associated with them, namely,\n\nFALSE = 0; and\nTRUE = 1.\n\nThis means we can apply computations to a logical vector. For example, we could count the number of Spice Girls that were original members by summing the logical values in the original_members object. (Since all FALSE values are 0, this amounts to counting the number of TRUE values.)\n\n# Count original members\nsum(original_member)\n\n[1] 3\n\n\nWe could also count the number of Spice Girls who are under the age of 20.\n\n# Count members with age &lt; 20\nsum(age &lt; 20)\n\n[1] 2\n\n\n\n\n\n3.1.2 Character Vectors\nA third type of vector you will work with is a character vector. Character vectors (a.k.a., strings, literals) are vectors in which each element is a string of characters delimited by quotation marks. For example, the Spice names column is a character vector. We can again create this vector using the c() function.\n\n# Create character vector\nspice = c(\"Scary\", \"Sporty\", \"Baby\", \"Ginger\", \"Posh\")\n\n# View vector\nspice\n\n[1] \"Scary\"  \"Sporty\" \"Baby\"   \"Ginger\" \"Posh\"  \n\n\nMany computations that worked on numeric vectors do not work on character vectors. These will often return an error or unexpected result. In the syntax below, for example, we are told that the mean() function expects a numeric or logical vector, and since what we used was not either of those, the result returned was NA.\n\n# Find mean name\nmean(spice)\n\nWarning in mean.default(spice): argument is not numeric or logical: returning\nNA\n\n\n[1] NA\n\n\nSome computations work the same way.\n\n# Count the number of elements\nlength(spice)\n\n[1] 5",
    "crumbs": [
      "Statistical Computation",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Data Structures in R</span>"
    ]
  },
  {
    "objectID": "01-03-data-structures-in-r.html#data-frames",
    "href": "01-03-data-structures-in-r.html#data-frames",
    "title": "3¬† Data Structures in R",
    "section": "3.2 Data Frames",
    "text": "3.2 Data Frames\nData frames (the multi-column bookcases in our metaphor) are a more complex data structures than vectors. There are again, multiple ways to create a data frame in R. We will examine two methods for creating a data frame: using the data.frame() function and importing data from a spreadsheet or CSV file.\nTo create a data frame from scratch, using R, we can use the data.frame() function. Each argument to this function is a named vector that will correspond to a column within the data frame, and each argument (vector) is separated by commas. For example, to create the Spice Girls data frame from our example, we could use the following syntax:\n\n# Create data frame\nspice_girls = data.frame(\n  spice = c(\"Scary\", \"Sporty\", \"Baby\", \"Ginger\", \"Posh\"),\n  age = c(19, 20, 18, 22, 20),\n  original_member = c(TRUE, TRUE, FALSE, TRUE, FALSE),\n  solo_nominations = c(4, 26, 14, 13, 12),\n  real_name = c(\"Mel B\", \"Mel C\", \"Emma\", \"Geri\", \"Victoria\")\n)\n\n# View data frame\nspice_girls\n\n\n  \n\n\n\nNote that we also assigned the data frame to an object called spice_girls so we can compute on it. You will learn how to compute on data frames in later chapters.",
    "crumbs": [
      "Statistical Computation",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Data Structures in R</span>"
    ]
  },
  {
    "objectID": "01-03-data-structures-in-r.html#importing-data-from-a-csv-file",
    "href": "01-03-data-structures-in-r.html#importing-data-from-a-csv-file",
    "title": "3¬† Data Structures in R",
    "section": "3.3 Importing Data From a CSV File",
    "text": "3.3 Importing Data From a CSV File\nIn professional practice, you will often enter data into a spreadsheet and rather than typing it into R. When you save this work, many spreadsheet programs use a proprietary format for saving the information (e.g., Excel saves as a XLSX file; Google Sheets saves as a GSHEET file). These often include extraneous information (e.g., formatting) that is irrelevant to the raw data. While R includes libraries and functions that can import data in the XLSX and GSHEETS formats, it is generally easier to save or export your data to a CSV (comma separated value) file from within your spreadsheet program prior to importing it into R.\n\n\n\n\n\n\n\n\n\n\nHere are some tips for entering data into a spreadsheet:\n\nThe first row should be the variable names. Do not use spaces in variable names.\nCharacter strings should be entered without quotation marks in a spreadsheet.\nIf you have missing data, leave the cell blank.\n\nFor more tips on entering data, see Broman & Woo (2018).\n\nOnce your data are saved as a CSV file, it can be easily imported into R. To do so,\n\nClick the Import Dataset button under the Environment tab in RStudio and choose ‚ÄúFrom Text (readr)‚Äù.\nIf the CSV file is a file stored on your computer, click the Browse button and navigate to where you saved your CSV file, select the file, and click ‚ÄúOpen‚Äù. If the CSV file is hosted on the web, type the URL into the ‚ÄúFile/URL‚Äù text box and click ‚ÄúUpdate‚Äù.\n\n\n\n3.3.1 Importing the Spice Girls Data\nThe file spice-girls.csv is accessible at https://raw.githubusercontent.com/zief0002/modeling/main/data/spice-girls.csv.\n\nCopy and paste that URL into the ‚ÄúFile/URL‚Äù text box.\nClick the ‚ÄúUpdate‚Äù button.\n\nClicking ‚ÄúUpdate‚Äù will open a preview of your data. Check to be sure the variable names are correct and that the data looks like what you entered into your spreadsheet.\n\nChange the text in the name box to correspond to the object name you want to use in R.\nFinally, click the Import button to import your data.\n\nAfter importing the data you should see the object in your global environment.\n\n\n\n\n\n\n\n\n\n\n\n\n3.3.2 Importing Data Using a Script File\nEven though you used the Import button‚Äîa point-and-click feature in RStudio‚Äîto import the data, behind the scenes, syntax was generated that was actually used to import the data into R. When we selected ‚ÄúFrom Text (readr)‚Äù, the read_csv() function from the {readr} package was used to import the data. You can see the syntax generated in the Code Preview window after you selected your CSV file.\n\n\n\n\n\n\n\n\n\nIn the first line of syntax, the {readr} package is loaded using the library() function. The data is imported in the second line of syntax and assigned to an object, in this case spice_girls. The read_csv() function includes an unnamed argument providing the URL for the CSV file.4 The View() function in the third line of syntax simply opens the spice_girls object in a view tab in RStudio.\nIt is a good idea to copy the first two lines of syntax from the Code Preview window into your script file. It will be faster to import the data in the future by running it from a script file rather than trying to reproduce all the steps to import your data. The third line of syntax, using View(), is not essential to importing your data..\n\nSince there are better ways to actually ‚Äúsee‚Äù the contents of the data object (e.g., print()), you should not include the View() syntax line in your script file.\n\nBelow are the two lines I would include in the script file. I would also comment them.\n\n# Load readr library\nlibrary(readr)\n\n# Import data\nspice_girls &lt;- read_csv(\"https://raw.githubusercontent.com/zief0002/modeling/main/data/spice-girls.csv\")",
    "crumbs": [
      "Statistical Computation",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Data Structures in R</span>"
    ]
  },
  {
    "objectID": "01-03-data-structures-in-r.html#validity-check-on-imported-data",
    "href": "01-03-data-structures-in-r.html#validity-check-on-imported-data",
    "title": "3¬† Data Structures in R",
    "section": "3.4 Validity Check on Imported Data",
    "text": "3.4 Validity Check on Imported Data\nOnce you import data, you should always perform a validity check to ensure that the entire dataset was imported and that things look OK. There are several functions that are useful for this examination. Three that I use regularly are print(), glimpse() and summary().\nThe print() function gives us a quick look at the data.\n\n# View data\nprint(spice_girls)\n\n# A tibble: 5 √ó 5\n  spice_name   age original_member solo_nominations real_name\n  &lt;chr&gt;      &lt;dbl&gt; &lt;lgl&gt;                      &lt;dbl&gt; &lt;chr&gt;    \n1 Scary         19 TRUE                           4 Mel B    \n2 Sporty        20 TRUE                          26 Mel C    \n3 Baby          18 FALSE                         14 Emma     \n4 Ginger        22 TRUE                          13 Geri     \n5 Posh          20 FALSE                         12 Victoria \n\n\nNote that from this output we can see that the read_csv() function actually imports the data as a tibble. Tibbles are essentially the same data structure as data frames. The only difference is that when you use print() (and some other functions) to examine the data object, what is printed to the screen is slightly different.5 For tibbles,\n\nThe number of rows and columns is displayed;\nThe first 10 rows are shown;\nOnly the columns that fit on screen are printed; and\nEach column type is reported\n\nHere the size of the data object is 5 x 5, which indicates that there are five rows (first value) and five columns (second value). We are also informed which columns are numeric, which are logical, and which are character.6\nThe summary() function computes summary statistics for each column in the data object. Different measures are computed depending on the column type. For character columns, only the length of the column is computed. The count of TRUE and FALSE values are computed for logical columns, and several measures are computed for numeric columns.\n\n# Compute summary measures for each column\nsummary(spice_girls)\n\n  spice_name             age       original_member solo_nominations\n Length:5           Min.   :18.0   Mode :logical   Min.   : 4.0    \n Class :character   1st Qu.:19.0   FALSE:2         1st Qu.:12.0    \n Mode  :character   Median :20.0   TRUE :3         Median :13.0    \n                    Mean   :19.8                   Mean   :13.8    \n                    3rd Qu.:20.0                   3rd Qu.:14.0    \n                    Max.   :22.0                   Max.   :26.0    \n  real_name        \n Length:5          \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n\n\nThis is another good validity check to ensure that numeric columns have appropriate minimum and maximum values, etc. Here we see that the the age and solo_nominations columns have reasonable values. In practice you would undertake many more validity checks, but for now this is a good start.",
    "crumbs": [
      "Statistical Computation",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Data Structures in R</span>"
    ]
  },
  {
    "objectID": "01-03-data-structures-in-r.html#references",
    "href": "01-03-data-structures-in-r.html#references",
    "title": "3¬† Data Structures in R",
    "section": "References",
    "text": "References\n\n\n\n\nBroman, K. W., & Woo, K. H. (2018). Data organization in spreadsheets. The American Statistician, 72(1), 2‚Äì10. https://doi.org/10.1080/00031305.2017.1375989",
    "crumbs": [
      "Statistical Computation",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Data Structures in R</span>"
    ]
  },
  {
    "objectID": "01-03-data-structures-in-r.html#footnotes",
    "href": "01-03-data-structures-in-r.html#footnotes",
    "title": "3¬† Data Structures in R",
    "section": "",
    "text": "Technically, a data frame can have a single column, but in practice most data frames you encounter will have many columns.‚Ü©Ô∏é\nIn this case, everything in the column would be turned into a character string.‚Ü©Ô∏é\nThe technical type is ‚Äúdouble‚Äù, which is commonly referred to as numeric.‚Ü©Ô∏é\nThis argument for the read_csv() function can also be a pathname to the location of the CSV file on your computer. If you are computing on a Mac, you may need to add ~/ to the beginning of this path name.‚Ü©Ô∏é\nFor data frames only the first six rows are displayed, all the columns are printed regardless of size, and column type is not reported.‚Ü©Ô∏é\nNote that just typing the name of the data frame also allows you to view the data. However, using print allows us more flexibility when the data set is larger.‚Ü©Ô∏é",
    "crumbs": [
      "Statistical Computation",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Data Structures in R</span>"
    ]
  },
  {
    "objectID": "02-00-data.html",
    "href": "02-00-data.html",
    "title": "Data",
    "section": "",
    "text": "The American Statistical Association defines statistics as, ‚Äúthe science of learning from data, and of measuring, controlling and communicating uncertainty‚Äù (American Statistical Association, 2023). The methods you learn throughout this textbook, and the EPSY 5261 course, will help you to learn from data and to measure, control, and communicate about uncertainty.\nAn important learning goal of statistics is therefore to understand the vocabulary and ideas related to data. To this end, in 4¬† Data Structure and Attribute Classification you will learn about the structure of data and attribute classification. You will also learn how to judge the quality of data including questions you should ask about the data.\n\n\n\n\n\nAmerican Statistical Association. (2023). ASA newsroom. Website. https://www.amstat.org/asa-newsroom",
    "crumbs": [
      "Data"
    ]
  },
  {
    "objectID": "02-01-data-structure-and-attributes.html",
    "href": "02-01-data-structure-and-attributes.html",
    "title": "4¬† Data Structure and Attribute Classification",
    "section": "",
    "text": "4.1 Classifying Attributes\nOur ultimate goal is often to analyze the data we have to learn from it. For example, in our NYT Best Seller data, we may be interested in the proportion of authors that identify as female. Or, we may want to. know how many weeks a book stays on the Best Sellers list. The type of analyses we can do, however, depend on the type of attributes we have.\nWe typically classify attributes as either categorical attributes or quantitative attributes. These classifications are based on the type of information (data) in the attribute. A categorical attribute has values that represent categorical (or qualitative) differences between the cases, whereas a quantitative attribute represents numerical (or quantitative) differences between cases. For example, in the NYT Best Seller data, title and author are categorical variables, whereas year, and total number of weeks the book was on the NYT Best Sellers list are quantitative attributes.\nTypically attributes that have numerical values are quantitative, but not always. In our data, consider the attribute that indicates whether the author identifies as a female. Although the values in the data are numeric, these numbers actually represent different categories: 0 = no (not female) and 1 = yes (female). Therefore, this attribute is actually a categorical attribute, not a quantitative attribute.\nOne check of whether anattribute is actually quantitative is whether numeric computations, such as finding an average of the attribute, can be carried out and the result makes conceptual sense. For example, we cannot compute the mean author value (it is thus a categorical attribute). If we compute the mean of the female attribute we get a result, but it does not indicate anything about the gender identity of a NYT best selling author. The mean does not make conceptual sense and thus we classify female as a categorical attribute.",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Data Structure and Attribute Classification</span>"
    ]
  },
  {
    "objectID": "02-01-data-structure-and-attributes.html#classifying-attributes",
    "href": "02-01-data-structure-and-attributes.html#classifying-attributes",
    "title": "4¬† Data Structure and Attribute Classification",
    "section": "",
    "text": "Your Turn\nClassify the best_rank attribute (the book‚Äôs highest rank while it was on the NYT Best Sellers list) as either categorical or quantitative. Explain.\n\nShow/Hide Solution\n\n\nThe attribute best_rank is a quantitative attribute. The data in this attribute are numeric values, and it makes conceptual sense to compute summaries such as the mean for this attribute.\n\n\n\n\n4.1.1 Further Classifications of Attributes\nWhile categorizing each attribute as categorical or quantitative is a good first step, statisticians and data analysts often go a step further and classify attributes based on their scale of measurement. This classification is based on how attributes were measured (i.e., how we assign numerals to objects of events) and what this implies about the empirical statements we can make about the constructs measured on that particular scale. The most common taxonomy for this was described by Stevens (1946) who classified four scales of measurement: nominal, ordinal, interval, or ratio (NOIR). Below we describe each of these scales of measurement:\nNominal Scale of Measurement: In nominal scales of measurement, any numerals assigned to different values would only be useful as labels, for distinguishing or organizing values. Most categorical attributes have this scale of measurement. For example, in the NYT bests sellers data, the numerical values in the gender identity attribute (female) are only useful as labels and for distinguishing authors who identify as female and authors who don‚Äôt. Because of this, only the following type of statement would be meaningful:\n\nIn the NYT bestseller data, more authors identify as female (15) than do not identify as female (10).\n\nThe only type of empirical statements we can make are comparisons of the number of cases between different labels (e.g., counts, percentages).\nOrdinal Scale of Measurement: Data measured using an ordinal scales of measurement, is still categorical. It has all the features of nominal measured data (e.g., labeling, distinguishing, organizing), but we can also rank order the values in a meaningful way. A classic example of the ordinal scale of measurement is in the 5-star review rating used on sites like Amazon. All of these statements would be meaningful:\n\nThere are more 4-star reviews than 5-star reviews (comparison of counts).\nA review of 3 stars is better than a review of 2 stars (rank ordering).\n\nWith this scale of measurement, it is reasonable to not only provide counts of the different values (e.g., the number of 5-star reviews), but now because there is a rank ordering, we can also make empirical statements related to the rank ordering of the measured construct based on the numeral values. In nominal level data, these latter types of statements are not appropriate since the values for the labels are arbitrary. For example, authors with a gender identity of female were assigned a 1 and others were assigned a 0. This is arbitrary in that authors identifying as female could just as easily have been assigned a value of 0 and those that didn‚Äôt identify as female a value of 1. This implies that even though the numeral 1 is greater than the numeral 0, the attribute values associated with these numerals (identifying as female or not) do not have any meaningful rank order. Because of this, saying something about one identity being greater than or less than another is inappropriate.\nInterval Scale of Measurement: In interval level data, the rank order of the numbers assigned to attribute values is meaningful, similar to ordinal data. Moreover, the difference between consecutive values represents the same amount of difference on the underlying attribute. For example, consider the Fahrenheit temperature scale. All of these statements would be meaningful:\n\nThere are more 30 degrees F days than 0 degrees F days (comparison of counts).\nA day that is 10 degrees F is warmer than a day that is 9 degrees F (rank ordering).\nThe difference in temperature when you are comparing days that are 9 and 10 degrees F is the same as when you are comparing days that are 0 and 1 degrees F. (interval comparison).\n\nThe critical component is that on an interval scale, the difference in consecutive numerals has the same level of difference in the construct being measured, regardless of scale location. Again consider our 5-star rating system. The difference between a 1- and 2-star review is not the same as the difference between a 4- and 5-star review. While the numbers themselves have a constant difference, the difference in the amount of the underlying construct (satisfaction, happiness with the product, etc.) does not. With interval level scales we can compute summaries like means, standard deviations, and correlations.\nRatio Scale of Measurement: With attributes that have the ratio scale of measurement, the rank ordering of the numbers assigned to attribute values is meaningful, the differences between consecutive numerals indicates the same amount of difference in the underlying construct being measured, and ratio type statements about these differences are also meaningful. For example, the amount of snowfall is an attribute on the ratio scale of measurement. All of these statements would be meaningful:\n\nThere are more days with 0 inches of snowfall than days with 10 inches of snowfall (comparison of counts).\nA day with 8 inches of snowfall got more snow than a day with 4 inches of snowfall (rank ordering).\nThe difference in snowfall when you are comparing days with 8 inches of snowfall and 7 inches of snowfall is the same as when you are comparing days with 15 and 16 inches of snow (interval comparison).\nA day with 8 inches of snow got twice the amount of snow as a day with 4 inches of snow (ratio comparison).\n\nGoing back to our temperature scale, we cannot make these ratio type statements. For example, a day that is 60 degrees F is not twice as warm as a day that is 30 degrees F. This is because the Fahrenheit scale does not have a ‚Äútrue‚Äù zero value. (Zero degrees F does not indicate absence of temperature.) Whereas, in our snowfall attribute, a day with 0 inches of snow does indeed indicate no snow fell on that day.\nAside from the type of empirical statements we can make, the level of measurement also puts limits on the type of statistical analyses that are appropriate.\n\n\n\n\nTable¬†4.1: The four measurement scales and the types of empirical statements and statistical summaries that are appropriate for each scale.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScale\nEmpirical Statement\nStatistical Summaries\n\n\n\n\nNominal\nComparison of counts\nCounts, percentages\n\n\nOrdinal\nComparison of counts  Rank ordering\nCounts, percentages  Median, percentiles\n\n\nInterval\nComparison of counts  Rank ordering  Interval comparisons\nCounts, percentages  Median, percentiles  Mean, standard deviation\n\n\nRatio\nComparison of counts  Rank ordering  Interval comparisons  Ratio comparisons\nCounts, percentages  Median, percentiles  Mean, standard deviation  Coefficient of variation",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Data Structure and Attribute Classification</span>"
    ]
  },
  {
    "objectID": "02-01-data-structure-and-attributes.html#how-were-the-data-generated",
    "href": "02-01-data-structure-and-attributes.html#how-were-the-data-generated",
    "title": "4¬† Data Structure and Attribute Classification",
    "section": "4.2 How Were the Data Generated?",
    "text": "4.2 How Were the Data Generated?\nAnother question that has direct implications on the methods used in data analysis is: How were the data generated or collected? Were they collected from a survey? Were they mined from the web? Were they generated as part of an experimental study? Knowing the answer to these questions also is important for the degree to which we can draw conclusions from the analysis.\nUnderstanding how the data were generated allows us to determine whether the data we have constitute a sample of cases or the entire population of cases we are interested in learning about. Importantly, whether you have a sample or the entire population depends on how you define the cases/observations you are interested in drawing conclusions about.\n\nA population includes all cases/observations of interest, whereas a. sample includes a subset of cases from the population.\n\nFor example, consider a child psychologist who wants to draw conclusions about all students at a particular school in Minnesota. To do this, she collects data from every student in that school. Since her data includes every case (student) she is interest in drawing conclusions for, her data would be a population, Now consider a second child psychologist who is interested in drawing conclusions about all students in Minnesota. This psychologist also collects data from every student in the same school as the first psychologist. This second psychologist‚Äôs data would be considered a sample since the cases they included in their data are only a subset of the cases they want to draw conclusions about.\n\nYour Turn\nIs the New York Time best sellers data a population or a sample? Explain.\n\nShow/Hide Solution\n\n\nThe New York Time best sellers data is a sample since it is only a subset of all the New York Times best selling books.\n\n\n\n\n4.2.1 Drawing Conclusions from a Sample\nIn practice, we rarely have data collected from an entire population, but we still want to use the data we have in our sample to draw conclusions about that population. Drawing conclusions about an entire population when you only have data from a subset cases is what statisticians call statistical inference.\n\n\n\n\n\n\n\n\nFigure¬†4.1: A sample of data is drawn from the population. Information from the sample is then analyzed and used to make a statistical inference about the population.\n\n\n\n\n\nThis can be a very tricky thing to do since the sample does not give us complete information about the population. As an example, consider if you wanted to figure out the average monthly living expenses for all graduate students at the University of Minnesota. To do this you collect data on the monthly living expenses for the students in your EPSY 5261 class and compute the average monthly living expense based on the data you collected and use that value as a guess for the average monthly living expenses for all graduate students at the University of Minnesota. (Note that the cases in your data (students in your EPSY 5261 class) are a subset of the population you want to draw conclusions about (all graduate students at the University of Minnesota) and thus are a sample.)\n\nSummaries computed from the population are referred to as parameters and summaries computed from a sample are referred to as statistics.\n\nIn statistical inference the statistics we compute from a sample are estimates for the population parameters that we are interested in. The word ‚Äúestimate‚Äù may have clued you in that the value of a statistic is generally not equal to the value of the parameter. In our example, the average monthly living expenses we computed based on your sample of cases is probably not the same as the average monthly living expenses for all graduate students at the University of Minnesota. This is because our sample only includes data for some (not all) of the cases.\nWe don‚Äôt expect the value of the statistic to be the same as that for the parameter we are trying to estimate, but a key question is: Is the value of the statistic a reasonable estimate of the parameter? The answer to this question can sometimes be difficult to answer. What do we mean by reasonable? In statistical analysis, there are a few ways that we consider reasonableness of an estimate. We will explore these below.\n\n\n4.2.1.1 Sampling Error: Quantifying the Amount of Uncertainty in our Sample Estimate\nOne way we consider whether an answer is reasonable is how much uncertainty we have in the estimate from our sample. Imagine if you repeated the study, but this time, you collected data on the monthly living expenses in a different section of EPSY 5261. The average computed from these data would likely be different from the average you computed from your section of EPSY 5261, and therefore your guess for the average monthly living expenses for all graduate students at the University of Minnesota would be different. This is because you would have different cases in your sample.\n\nWhen using a sample to infer about a population, our guesses or estimates vary depending on the cases in our sample. This means that when we make inferences there is always some degree of uncertainty in our estimates.\n\nThe idea that estimates from samples vary depending on the cases in your sample is well known and is referred to as sampling error. In carrying out statistical inference, we not only acknowledge that we have uncertainty in our guess from the sample data, but we also try and quantify how much uncertainty there is in that estimate. For example, do we think that the average monthly living expenses for all graduate students at the University of Minnesota is within a few dollars of our sample estimate? Or do we think that it is within a few hundred dollars of our sample estimate? By providing this estimate of the uncertainty, it lets other people know ‚Äúhow reasonable‚Äù our guess might be.\n\n\n\n\n\n\n\n\nFigure¬†4.2: Estimates for the mean living expense for all graduate students at the University of Minnesota will vary from sample to sample because of sampling error. In statistical inference this is expected and quantifying the amount of sampling error gives us an indication of how much uncertainty we have in our estimate.\n\n\n\n\n\n\n\n\n4.2.1.2 Sampling Bias: Does the Sample Represent the Population?\nA second way we consider whether an answer is reasonable is to consider whether our sample of cases is representative of the population as a whole. In our example, we are asking the question of whether the students in your section of EPSY 5261 are representative of all graduate students at the University of Minnesota when it comes to living expenses. This is a really difficult question to answer, but generally (unless you have selected your sample randomly from the population), your sample is not representative. The key here is that the sampling method (how you chose your cases) matters!\n\nWhen a sample is not randomly selected from the population we say that the sampling method is biased.\n\nA biased sampling method leads to systematically wrong answers. For example, again say you were interested in determining the average monthly living expenses for all graduate students at the University of Minnesota. This time, your sampling method is to collect data about the monthly living expenses from all the graduate students who live in a particular apartment building in Downtown Minneapolis. Would these students‚Äô living expenses be representative of all graduate students at the University of Minnesota?\nAgain, probably not. The living expenses in Downtown Minneapolis are different (generally higher) than the living expenses of students who live in Dinkytown or one of the suburbs. Because the cases in your sample all come from the same apartment building in Downtown Minneapolis, their average monthly living expense will be systematically higher than the average monthly living expenses for all graduate students at the University of Minnesota.\nWhat about our original sampling method of collecting data from each of the graduate students in your EPSY 5261 section? While these students might live in different areas, and seem more representative, this sampling method is likely still biased. Even if we have a hard time identifying how, the estimate for the average monthly living expenses based on students in EPSY 5261 is likely systematically different than the average monthly living expenses for all graduate students at the University of Minnesota. (It may be systematically too low, or too high.)\n\nThe only sampling method that is guaranteed to be unbiased (and therefore representative) is to select your sample randomly from the population.\n\n\n\n\n\n4.2.2 Random Sampling\nThere are many methods for randomly selecting a sample from the population. The simplest method that incorporates randomness into the sampling process is Simple Random Sampling. In simple random sampling each case in the population has an equal probability of being selected into the sample.1\n\nIn the discipline of statistics, there are words that we use that have very different meanings from their use in colloquial English. ‚ÄúRandom‚Äù is one of those words. In our everyday language ‚Äúrandom‚Äù might mean happenstance or unexpected. For example: It was so random that I saw Ferris Bueller at the 31 Flavors last night. In statistics, ‚Äúrandom‚Äù does not mean happenstance at all. Random sampling is quite formal in ensuring that cases have a specified probability of being selected into the sample.\n\nOne of the most compelling and useful results in statistics is that a simple random sample is representative of the population, and moreover that even small samples that are selected with this method can be representative of very large populations. This is powerful!\nBut, it can sometimes be very difficult to draw a simple random sample in practice. For one thing, it requires that you have a list of all the cases in the population (called a sampling frame). This allows you to make sure that everyone in the population has the same probability of being selected. While it might be possible to obtain a list of all graduate students enrolled at the University of Minnesota, it is another thing to obtain a list of all people living in Minnesota. Or even a list of people living in Dinkytown. Depending on your population of interest you may not be able to get a simple random sample.2\n\nYour Turn\nWhat is the sampling method for the New York Time best sellers data. Based on this method, are the estimates of the population parameters we compute from these data going to be biased or unbiased?\n\nShow/Hide Solution\n\n\nThe New York Time best sellers data was sampled using simple random sampling. Because the sampling method employed randomness, the estimates we compute from the data are unbiased estimates of the population parameters.",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Data Structure and Attribute Classification</span>"
    ]
  },
  {
    "objectID": "02-01-data-structure-and-attributes.html#summary",
    "href": "02-01-data-structure-and-attributes.html#summary",
    "title": "4¬† Data Structure and Attribute Classification",
    "section": "4.3 Summary",
    "text": "4.3 Summary\nEvery time you encounter data, you should identify the cases and attributes in the data. Understanding the cases, especially in relation to the cases you want to draw conclusions about, helps you identify whether you have a sample, or the entire population. Classifying the attributes helps you think about the type of analysis you can undertake. If your data are a sample (rather than a population), you also need to ask how they were collected. Were they collected using randomness in the sampling method? Or is the sampling method used to collect the data biased?",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Data Structure and Attribute Classification</span>"
    ]
  },
  {
    "objectID": "02-01-data-structure-and-attributes.html#references",
    "href": "02-01-data-structure-and-attributes.html#references",
    "title": "4¬† Data Structure and Attribute Classification",
    "section": "4.4 References",
    "text": "4.4 References\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGould, R., & Ryan, C. (2013). Introductory statistics: Exploring the world through data. Pearson.\n\n\nPruett, J. (2021). NYT hardcover fiction bestsellers. Post45 Data Collective, V1. https://doi.org/https://doi.org/10.18737/CNJV1733p4520220211\n\n\nStevens, S. S. (1946). On the theory of scales of measurement. Science, 103(2684), 677‚Äì680.",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Data Structure and Attribute Classification</span>"
    ]
  },
  {
    "objectID": "02-01-data-structure-and-attributes.html#footnotes",
    "href": "02-01-data-structure-and-attributes.html#footnotes",
    "title": "4¬† Data Structure and Attribute Classification",
    "section": "",
    "text": "Technically the definition of a simple random sample is all potential samples of size n have the same probability of being selected, which implies that each case in the population has an equal probability of being selected into the sample. Conceptually, however, it is easier to think about the probability of each case rather than of the probability of groups of size n.‚Ü©Ô∏é\nIn this case there are other more complex methods of random sampling that you could use (e.g., stratified random sampling, cluster random sampling.‚Ü©Ô∏é",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Data Structure and Attribute Classification</span>"
    ]
  },
  {
    "objectID": "03-00-exploring-and-describing-data.html",
    "href": "03-00-exploring-and-describing-data.html",
    "title": "Summarizing and Visualizing Data",
    "section": "",
    "text": "Goals for Summarization and Visualization\nData scientists and statisticians visualize data and compute numerical summaries to explore and understand data. In addition to visualizing distributions of data, it is common to also summarize certain feature of the data using numbers. (For example, the mean is one summarization of a distribution of quantitative data.) Together visualizing and summarizing data can help analysts identify features in the data such as typical or extreme observations, and also describe and explore the variation in the data. Data exploration is an important first step in any statistical analysis.",
    "crumbs": [
      "Summarizing and Visualizing Data"
    ]
  },
  {
    "objectID": "03-00-exploring-and-describing-data.html#college-scorecard-data",
    "href": "03-00-exploring-and-describing-data.html#college-scorecard-data",
    "title": "Summarizing and Visualizing Data",
    "section": "College Scorecard Data",
    "text": "College Scorecard Data\nThroughout the chapters in this section we will use the College Scorecard data to illustrate the methods of data exploration. These data were collected and made available by the U.S. Department of Education (DOE). The DOE publishes data on institutions of higher education in their College Scorecard to facilitate transparency and provide information for interested stakeholders (e.g., parents, students, educators). A subset of this data is provided in the file college-scorecard.csv.\n\nCSV File\nData Codebook",
    "crumbs": [
      "Summarizing and Visualizing Data"
    ]
  },
  {
    "objectID": "03-01-categorical-attributes.html",
    "href": "03-01-categorical-attributes.html",
    "title": "5¬† Summarizing and Visualizing Categorical Attributes",
    "section": "",
    "text": "5.1 Hypothetical Example: Pet Ownership\nImagine you have surveyed 10 pet owners about the type of pet they own.1 The data you collected is shown in Figure¬†5.1.\nFigure¬†5.1: Data collected from 10 pet owners about the type of pet the own.\nOur goal in exploratory analysis is to describe the data. One way of describing the data is to list all of the values. For example here we could say the sample included a turtle, a fish, a cat, a dog, another dog, another fish, another cat, another cat, another cat, and another dog. While this is an accurate description, it isn‚Äôt very generalizable. (Imagine trying to describe the data from 1000 pet owners or 10,000 pet owners!)",
    "crumbs": [
      "Summarizing and Visualizing Data",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Summarizing and Visualizing Categorical Attributes</span>"
    ]
  },
  {
    "objectID": "03-01-categorical-attributes.html#hypothetical-example-pet-ownership",
    "href": "03-01-categorical-attributes.html#hypothetical-example-pet-ownership",
    "title": "5¬† Summarizing and Visualizing Categorical Attributes",
    "section": "",
    "text": "5.1.1 Numerically Summarizing Categorical Attributes\nA more natural way to describe these data is to summarize them by providing counts of each pet type. For example, describing our sample data using counts:\n\n1 of the pet owners sampled owned a turtle,\n2 of the pet pet owners sampled owned a fish,\n3 of the pet pet owners sampled owned a dog, and\n4 of the pet pet owners sampled owned a cat.\n\nSummarizing each type of pet owned by reporting counts of them is a much more natural way of describing the data. (This is also useful when the sample size is much larger.)\nAnother summary that could be used to describe this sample is to give the proportion of each type of pet owned. To compute the proportion, we take the count of each type of pet owned, and divide it by the total sample size.\n\\[\n\\mathrm{Proportion} = \\frac{\\mathrm{Count~of~Pet~Type}}{\\mathrm{Total~Sample~Size}}\n\\]\nFor example, to compute the proportion of pet owners in our sample that owned a dog, we use:\n\\[\n\\mathrm{Proportion~of~Dogs} = \\frac{3}{10} = 0.30\n\\]\n\nProportions will always be between 0 and 1. If you add all of the proportions of each category together you will get 1, so long as values can only belong to one category.\n\nDescribing our sample data using proportions:\n\n0.10 of the pet owners sampled owned a turtle,\n0.20 of the pet pet owners sampled owned a fish,\n0.30 of the pet pet owners sampled owned a dog, and\n0.40 of the pet pet owners sampled owned a cat.\n\nThe count and proportion values are often reported in a table, especially if there are more than a couple values in the categorical attribute. Table¬†5.1 is an example table indicating the counts and proportions of values in our hypothetical pet example.\n\n\n\n\nTable¬†5.1: Counts and proportions of pet owners who own each type of pet.\n\n\n\n\n\n  \n  \n\n\n\nPet\nCount\nProportion\n\n\n\n\n\n3\n0.30\n\n\n\n4\n0.40\n\n\n\n2\n0.20\n\n\n\n1\n0.10\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.1.2 Visualizing Categorical Attributes\nTo visualize categorical attributes we typically use a bar chart. Figure¬†5.2 shows a bar chart of the pet data.\n\n\n\n\n\n\n\n\nFigure¬†5.2: Bar chart indicating the counts of each type of pet owned.\n\n\n\n\n\nA bar chart (also known as a bar graph) shows a bar for each category of the categorical attribute. In our example, we have four bars, one for each pet type. The height of the bar indicates the count of each category. For example, the bar for cats has a height of four on the y-axis.\nSometimes the axes in the bar chart are transposed; categories are placed on the y-axis and counts on the x axis. Also, you might see a bar chart indicating proportions rather than counts. Figure¬†5.3 shows a transposed bar chart indicating the proportion of each pet type.\n\n\n\n\n\n\n\n\nFigure¬†5.3: Bar chart indicating the counts of each type of pet owned. In this plot the categories are placed on the y-axis and the scale on the the x axis indicates proportions rather than counts.\n\n\n\n\n\n\nWhen proportions are used in a bar chart, it is coventional to extend that axis from 0 to 1 (the range of potential proportions).\n\n\n\n5.1.2.1 Bar Chart Variations\nThere are several variations on the bar chart that you may see in practice. For example, the segmented bar chart is a variation of the bar chart. This variation of the plot, which always uses proportions rather than counts, has a single bar that is split into segments‚Äîone for each category. A segmented bar chart summarizing the pet data is shown in Figure¬†5.4.\n\n\n\n\n\n\n\n\nFigure¬†5.4: Segmented bar chart indicating the proportion of each type of pet owned.\n\n\n\n\n\nAnother variation of the bar chart is the donut chart. A donut chart is simply a segmented bar chart that is presented in a circular layout. Figure¬†5.5 presents a donut chart summarizing the pet data. Because there is no axis to indicate the proportion of each category in a donut chart, it is conventional to indicate the percentages of each category in the plot. Here percentages are used rather than proportions.\n\n\n\n\n\n\n\n\nFigure¬†5.5: Donut chart indicating the percentage of each type of pet owned. A donut chart is simply a segmented bar chart presented in a circular layout.\n\n\n\n\n\n\n\n\n5.1.2.2 Pie Charts\nOne last plot used to visualize summaries of categorical dat is the pie chart. Figure¬†5.6 shows a pie chart summarizing the pet data. Unlike any of the bar charts that we have looked at, a pie chart uses the proportional area of a circle to indicate the proportion or percentage of each pet type rather than the length of a bar.\n\n\n\n\n\n\n\n\nFigure¬†5.6: Pie chart indicating the percentage of each type of pet owned. A pie chart uses the proportional area of a circle to indicate the proportion or percentage of each pet type.\n\n\n\n\n\n\nIn a pie chart, each section of the pie is determined by proportionally dividing the 360¬∞ of the circle based on the data, and then making each section have the computed angle. For example the proportion of pet owners who have a cat is 0.4, and 0.4 of 360¬∞ is 144¬∞‚Äîso the cats section has an angle of 144¬∞. While these computations and the drawing of the pie chart would be done by the computer, it has implications for interpretations. Namely, research has suggested that humans may not be as adept at making accurate comparisons involving angles and the areas of sections based on those angles. Because of this, the recommendation from the data visualization community is to use bar charts rather than pie charts when displaying summaries of categorical data.",
    "crumbs": [
      "Summarizing and Visualizing Data",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Summarizing and Visualizing Categorical Attributes</span>"
    ]
  },
  {
    "objectID": "03-01-categorical-attributes.html#using-r-to-numerically-summarize-categorical-attributes",
    "href": "03-01-categorical-attributes.html#using-r-to-numerically-summarize-categorical-attributes",
    "title": "5¬† Summarizing and Visualizing Categorical Attributes",
    "section": "5.2 Using R to Numerically Summarize Categorical Attributes",
    "text": "5.2 Using R to Numerically Summarize Categorical Attributes\nTo illustrate how we can summarize and visualize categorical attributes using R, we will use the college-scorecard.csv data. As a reminder, we will start by loading three libraries: {tidyverse}, {ggformula}, and {mosaicCore}. Then we will import the college scorecard data using the read_csv() function and assign the data into an object called colleges. Finally, we view the data to make sure it read in properly.\n\nlibrary(tidyverse)\nlibrary(ggformula)\nlibrary(mosaicCore)\n\n# Import data\ncolleges &lt;- read_csv(\"https://raw.githubusercontent.com/zief0002/epsy-5261/main/data/college-scorecard.csv\")\n\n# View data\ncolleges\n\n\n  \n\n\n\nRecall that in these data each case in these data is an institution of higher education and there are 234 institutions in our sample. This dataset has several categorical attributes, including: state, region, type of institution, and control.\nThe first attribute we will summarize and visualize is the control variable. Looking at the data codebook we find that this attribute can take on three different values: Public, Private nonprofit, and Private for-profit. Our first task is to get institution counts for each category of control. To do this, we will use the df_stats() function. The general syntax to obtain these counts is shown below.\n\n# General syntax to counts the categories in a categorical attribute\ndf_stats( ~ attribute_name, data = data_name, counts)\n\nWe first need to identify the name of the categorical attribute. To tell df_stats() that this is an attribute, we place a tilde (~) in front of the attribute name. Then we use the data= argument to identify the data object that includes our categorical attribute. Finally, we use counts to indicate that we want to compute the category counts.\n\nIt is a good idea to learn how to read R syntax. The tilde operator indicates a special kind of expression called a formula, and can be read as ‚Äúmodel‚Äù. So the general syntax above is read as, ‚Äúmodel the attribute_name found in the data_name data by counting the categories in the attribute‚Äù.\n\nPutting this into practice to count the categories in the control attribute which is in our colleges data:\n\n# Syntax to count the categories in the control attribute\ndf_stats(~control, data = colleges, counts)\n\n\n  \n\n\n\nIf we were to read this syntax, ‚Äúmodel the control attribute found in the colleges data by counting the categories in the attribute‚Äù.\nBased on the counts, we find that most of the institutions of higher learning in our sample are private nonprofit institutions (n = 146). There are also several public institutions of higher learning in our sample (n = 71). Lastly, there are also a few private for-profit institutions of higher learning in our sample (n = 13).\n\nIt is common to use n or N to denote sample size. Some textbooks and authors will use N to indicate the overall sample size (e.g., in the college scorecard data, N = 234) and n to indicate the sample size of subgroups within the sample (e.g., n = 71 for public institutions). Other authors might use n to define the overall sample size (e.g., n = 234) and then use subscripts on n to denote the sample size of different groups (e.g., \\(n_{\\mathrm{Public}}=71\\)). There is not a single unified agreed upon way to denote these things.\n\nWe also might want to compute the proportions for each category of control. To do this, we can again use the function df_stats(), but instead of providing counts we will provide props.\n\n# Syntax to compute the proportion for each category in the control attribute\ndf_stats(~control, data = colleges, props)\n\n\n  \n\n\n\nThese proportions (which can also be turned into percentages2) tell a similar story to what the counts did. Most of the institutions in our sample are private nonprofit (63.5%) and public (30.9%) institutions. There is a smaller percentage of institutions that are private for-profit (5.7%).3 As we did with the numerical summaries of the pet data, we can include these values in a table.\n\n\n\n\nTable¬†5.2: Counts and proportions of institutions of higher learning by control.\n\n\n\n\n\n  \n  \n\n\n\nControl\nCount\nProportion\n\n\n\n\nPublic\n71\n0.309\n\n\nPrivate Nonprofit\n146\n0.635\n\n\nPrivate For-Profit\n13\n0.057\n\n\n\n\n\n\n\n\n\n\n\n\n\nYour Turn\nWrite the syntax to compute the counts of the region attribute.\n\nShow/Hide Solution\n\n\n\ndf_stats(~ region, data = colleges, counts)\n\n\n  \n\n\n\n\nWrite the syntax to compute the proportions of the region attribute.\n\nShow/Hide Solution\n\n\n\ndf_stats(~ region, data = colleges, props)",
    "crumbs": [
      "Summarizing and Visualizing Data",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Summarizing and Visualizing Categorical Attributes</span>"
    ]
  },
  {
    "objectID": "03-01-categorical-attributes.html#creating-a-bar-chart-to-summarize-counts-using-r",
    "href": "03-01-categorical-attributes.html#creating-a-bar-chart-to-summarize-counts-using-r",
    "title": "5¬† Summarizing and Visualizing Categorical Attributes",
    "section": "5.3 Creating a Bar Chart to Summarize Counts using R",
    "text": "5.3 Creating a Bar Chart to Summarize Counts using R\nTo create a bar chart, we will use the gf_counts() function. This general syntax for gf_counts() is\n\n# General syntax to create a bar chart\ngf_counts(~ attribute_name, data = data_name)\n\nIn this function we indicate the name of the attribute we want to create a bar chart for with a tilde (~) precedeing the attribute name. We also give the name of the data object in the data= argument. For example, the syntax to create a bar chart summarizing the counts of the control attribute is:\n\n# Syntax to create a bar chart for the control attribute\ngf_counts(~ control, data = colleges)\n\n\n\n\n\n\n\nFigure¬†5.7: Bar chart summarizing the counts of the control attribute.\n\n\n\n\n\n\nReading the syntax: Create a bar chart by modeling the counts of the control attribute in the colleges data object.\n\nWe can make this plot nicer by changing the axes labels. For example, we might change the y-axis label to ‚ÄúCount‚Äù and the x-axis label to ‚ÄúType of Institution‚Äù. To do this we include the xlab= and ylab= arguments in the gf_counts() function. The labels we want depicted are given as text inside of quotation marks. Remember that each argument needs to be separated by a comma!\n\nAs you include additional arguments in the function, it can be useful to include each argument on different lines. This will help you troubleshoot syntax that doesn‚Äôt work.\n\n\n# Syntax to create a bar chart for the control attribute\ngf_counts( \n  ~ control, data = colleges,\n  xlab = \"Type of Institution\",\n  ylab = \"Count\"\n  )\n\n\n\n\n\n\n\nFigure¬†5.8: Bar chart summarizing the counts of institutions of higher learning by type.\n\n\n\n\n\n\nYour Turn\nWrite the syntax to create a bar chart that summarizes the counts of the region attribute.\n\nShow/Hide Solution\n\n\n\ngf_counts(~ region, data = colleges)\n\n\n\n\n\n\n\n\n\nAdd better labels to the x- and y-axis of the bar chart you just created.\n\nShow/Hide Solution\n\n\n\ngf_counts(\n  ~ region, data = colleges,\n  xlab = \"Region of the United States\",\n  ylab = \"Count\"\n  )",
    "crumbs": [
      "Summarizing and Visualizing Data",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Summarizing and Visualizing Categorical Attributes</span>"
    ]
  },
  {
    "objectID": "03-01-categorical-attributes.html#creating-a-bar-chart-to-summarize-proportions-using-r",
    "href": "03-01-categorical-attributes.html#creating-a-bar-chart-to-summarize-proportions-using-r",
    "title": "5¬† Summarizing and Visualizing Categorical Attributes",
    "section": "5.4 Creating a Bar Chart to Summarize Proportions using R",
    "text": "5.4 Creating a Bar Chart to Summarize Proportions using R\nTo create a bar chart that summarizes the proportion of each category (rather than counts) we can use the gf_props() function. The syntax for this function is identical to that of gf_counts(). The syntax to create a bar chart summarizing the proportion of the control attribute is:\n\n# Syntax to create a bar chart for the control attribute\ngf_props(\n  ~control, data = colleges,\n  xlab = \"Type of Institution\",\n  ylab = \"Count\"\n  )\n\n\n\n\n\n\n\nFigure¬†5.9: Bar chart summarizing the proportions of institutions of higher learning by type.\n\n\n\n\n\nYou can also create a bar chart that summarizes the percentage of each category using the gf_percents() function.\n\n# Syntax to create a bar chart for the control attribute\ngf_percents(\n  ~control, data = colleges,\n  xlab = \"Type of Institution\",\n  ylab = \"Percent\"\n  )\n\n\n\n\n\n\n\nFigure¬†5.10: Bar chart summarizing the percentage of institutions of higher learning by type.\n\n\n\n\n\n\nYour Turn\nWrite the syntax to create a bar chart that summarizes the proportions of the region attribute. Also change the axis labels on both the x- and y-axes.\n\nShow/Hide Solution\n\n\n\ngf_props(\n  ~ region, data = colleges,\n  xlab = \"Region of the United States\",\n  ylab = \"Proportion\"\n  )",
    "crumbs": [
      "Summarizing and Visualizing Data",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Summarizing and Visualizing Categorical Attributes</span>"
    ]
  },
  {
    "objectID": "03-01-categorical-attributes.html#creating-horizontal-bar-charts-using-r",
    "href": "03-01-categorical-attributes.html#creating-horizontal-bar-charts-using-r",
    "title": "5¬† Summarizing and Visualizing Categorical Attributes",
    "section": "5.5 Creating Horizontal Bar Charts Using R",
    "text": "5.5 Creating Horizontal Bar Charts Using R\nTo create horizontal bar charts we can use add on (literally) the function coord_flip() , to gf_counts(), gf_props() or gf_percents(). For example, to create a horizontal bar chart summarizing the counts of each type of institution we can use the following syntax:\n\n# Syntax to create a hirizontal bar chart for the control attribute\ngf_counts(\n  ~control, data = colleges,\n  xlab = \"Count\",\n  ylab = \"Type of Institution\"\n  ) +\n  coord_flip()\n\n\n\n\n\n\n\nFigure¬†5.11: Horizontal bar chart summarizing the number of institutions of higher learning by type.\n\n\n\n\n\n\nYour Turn\nWrite the syntax to create a horizontal bar chart that summarizes the percent of the region attribute. Also change the axis labels on both the x- and y-axes.\n\nShow/Hide Solution\n\n\n\ngf_percents(\n  ~ region, data = colleges,\n  xlab = \"Percent\",\n  ylab = \"Region of the United States\"\n  ) +\n  coord_flip()",
    "crumbs": [
      "Summarizing and Visualizing Data",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Summarizing and Visualizing Categorical Attributes</span>"
    ]
  },
  {
    "objectID": "03-01-categorical-attributes.html#summary",
    "href": "03-01-categorical-attributes.html#summary",
    "title": "5¬† Summarizing and Visualizing Categorical Attributes",
    "section": "5.6 Summary",
    "text": "5.6 Summary\nThere are several R functions that are useful for summarizing categorical attributes. Table¬†6.1 shows the functions (and their descriptions) you will use to summarize and visualize categorical attributes. Note that they all have very parallel syntax.\n\n\n\n\nTable¬†5.3: The functions and their descriptions to summarize and visualize categorical attributes.\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\nFunction\nDescription\n\n\n\n\nSummarize\n\n\ndf_stats(~attribute, data = data_object, counts)\nCompute counts of a categorical attribute\n\n\ndf_stats(~attribute, data = data_object, props)\nCompute proportions of a categorical attribute\n\n\ndf_stats(~attribute, data = data_object, percs)\nCompute percentages of a categorical attribute\n\n\nVisualize\n\n\ngf_counts(~attribute, data = data_object)\nCreate bar chart of counts\n\n\ngf_props(~attribute, data = data_object)\nCreate bar chart of proportions\n\n\ngf_percents(~attribute, data = data_object)\nCreate bar chart of percentages\n\n\ngf_counts(~attribute, data = data_object) + coord_flip()\nCreate horizontal bar chart of counts\n\n\ngf_props(~attribute, data = data_object) + coord_flip()\nCreate horizontal bar chart of proportions\n\n\ngf_percent(~attribute, data = data_object) + coord_flip()\nCreate horizontal bar chart of percentages\n\n\n\n\n\n\n\n\n\n\n\nLastly, there are several optional arguments you can include in the visualization (gf_) functions to improve the aesthetic quality of your plot. Some of these are listed in Table¬†5.4.\n\n\n\n\nTable¬†5.4: Optional argumnents that can be included in the visualization (gf_) functions.\n\n\n\n\n\n  \n  \n\n\n\n\n\n\nArgument\n\n\n\n\nLabels\n\n\n`xlab =\n\n\n`ylab =\n\n\n`title =\n\n\n`subtitle =\n\n\n`caption =\n\n\nColor\n\n\n`fill =\n\n\n`color =\n\n\n\n\n\n\n\n\n\n\n\nRemember to separate each argument with a comma if you include multiple arguments in the function.",
    "crumbs": [
      "Summarizing and Visualizing Data",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Summarizing and Visualizing Categorical Attributes</span>"
    ]
  },
  {
    "objectID": "03-01-categorical-attributes.html#footnotes",
    "href": "03-01-categorical-attributes.html#footnotes",
    "title": "5¬† Summarizing and Visualizing Categorical Attributes",
    "section": "",
    "text": "To keep it simple, assume each pet owner only has a single pet.‚Ü©Ô∏é\nYou can also use df_stats() to compute percentages by providing percs.‚Ü©Ô∏é\nNote that these percentages do not quite add up to 100%. This is because of the rounding that we did.‚Ü©Ô∏é",
    "crumbs": [
      "Summarizing and Visualizing Data",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Summarizing and Visualizing Categorical Attributes</span>"
    ]
  },
  {
    "objectID": "03-02-quantitative-attributes.html",
    "href": "03-02-quantitative-attributes.html",
    "title": "6¬† Summarizing and Visualizing Quantitative Attributes",
    "section": "",
    "text": "6.1 Importing the Data\nTo illustrate how we can summarize and visualize quantitative attributes using R, we will again use the college-scorecard.csv data. As a reminder, we will start by loading three libraries, {tidyverse}, {ggformula}, and {mosaicCore}. Then we will import the college scorecard data using the read_csv() function and assign the data into an object called colleges. Finally, we view the data to make sure it read in properly.\nlibrary(ggformula)\nlibrary(mosaicCore)\nlibrary(tidyverse)\n\n\n# Import data\ncolleges &lt;- read_csv(\"https://raw.githubusercontent.com/zief0002/epsy-5261/main/data/college-scorecard.csv\")\n\n# View data\ncolleges\nRecall that in these data each case in these data is an institution of higher education and there are 234 institutions in our sample. This dataset has several quantitative attributes, including: admission rate, number of undergraduate students, median debt for all students, median debt for graduates, and median earnings.",
    "crumbs": [
      "Summarizing and Visualizing Data",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Summarizing and Visualizing Quantitative Attributes</span>"
    ]
  },
  {
    "objectID": "03-02-quantitative-attributes.html#histograms",
    "href": "03-02-quantitative-attributes.html#histograms",
    "title": "6¬† Summarizing and Visualizing Quantitative Attributes",
    "section": "6.2 Histograms",
    "text": "6.2 Histograms\nThe first visualization we will examine is a histogram. We can create a histogram of the admission rates using the gf_histogram() function.1 This function takes the same general syntax as the gf_ functions you learned about in Chapter 5:\n\nThe first argument is a formula using the tilde operator (~) that identifies the attribute to be plotted, and\nThe second argument, data =, specifies the data object that was assigned on data import.\n\nThe syntax used to create a histogram of the admission rates is:\n\ngf_histogram(~ adm_rate, data = colleges)\n\n\n\n\n\n\n\nFigure¬†6.1: Histogram of admission rates for the institutions of higher learning in the sample.\n\n\n\n\n\n\n\n6.2.1 Interpretting Histograms\nHistograms are created by collapsing the data into bins and then counting the number of observations that fall into each bin. To show this more clearly in the figure created previously, we can color the bin lines to highlight the different bins. To do this we include an additional argument, color =, in the gf_histogram() function. We can also set the color for the bins themselves using the fill = argument. Here we color the bin lines black and set the bin color to yellow.2\n\ngf_histogram(\n  ~ adm_rate, data = colleges, \n  color = \"black\", \n  fill = \"yellow\",\n  xlab = \"Admission Rate\",\n  ylab = \"Count\"\n  )\n\n\n\n\n\n\n\nFigure¬†6.2: Histogram of college admission rates. Here the color of the bin lines to black and fill in the bars with yellow. Axes labels are also added to the plot.\n\n\n\n\n\nEach bar in a histogram represents indicates the number of cases with a range of values for the plotted variable. For example, the bar that is just to the right of 0.50, shows there are approximately 16 institutions of higher learning with admissions rates between about 0.50 and 0.54. Similar interpretations can be made for all of the other bars as well.\nOne common assumption made with a histogram is that the width of each bar covers the same range over the attribute plotted. In this histogram, there are 25 total bars, which means that the range of each is 0.04 on the admission rate scale (i.e., 25 * .04 = 1.00 which is the rtange of the entire attribute).\n\nYour Turn\nInterpret the bar that is immediately to the left of 1.00.\n\nShow/Hide Solution\n\n\nThere are approximately 12 institutions of higher learning with admissions rates between about 0.96 and 1.00.\n\n\n\n\n6.2.2 Describing the Distribution\nRather than focusing on any one bin, we typically want to describe the distribution of the attribute plotted as a whole. For example, it appears as though most institutions admit a high proportion of applicants since the bins to the right of 0.50 have higher counts than the bins that are below 0.50. (In fact, the highest bins seem to be above 0.75.) There are a few institutions, however, that are quite selective, admitting fewer than 25% of the students who apply.\nStatistically we would say that the distribution of admission rates is left-skewed. A left skewed distribution has the majority of cases on the right side of the distribution (i.e., at higher values of the attribute). In contrast, a distribution that has the majority of cases on the left side of the distribution (i.e., at lower values of the attribute) is called right-skewed. Figure¬†6.3 shows examples of both a left-skewed and right-skewed distribution.\n\n\n\n\n\n\n\n\n\n\n\n(a) Left-Skewed Distribution\n\n\n\n\n\n\n\n\n\n\n\n(b) Right-Skewed Distribution\n\n\n\n\n\n\n\nFigure¬†6.3: Examples of a left-skewed and right-skewed distribution.\n\n\n\nThe skewness of a distribution describes a characteristic that we refer to as the shape of the distribution. Some distributions are not skewed, these distributions have a symmetric shape. Figure¬†6.4 shows an example of a symmetric distribution.\n\n\n\n\n\n\n\n\nFigure¬†6.4: Example of a symmetric distribution.",
    "crumbs": [
      "Summarizing and Visualizing Data",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Summarizing and Visualizing Quantitative Attributes</span>"
    ]
  },
  {
    "objectID": "03-02-quantitative-attributes.html#density-plots",
    "href": "03-02-quantitative-attributes.html#density-plots",
    "title": "6¬† Summarizing and Visualizing Quantitative Attributes",
    "section": "6.3 Density plots",
    "text": "6.3 Density plots\nAnother plot that is sometimes more useful for determining the shape of the distribution for a quantitative attribute is the density plot. This plot is a smoothed out version of a histogram.\nDensity plots can be created with the gf_density() function which takes the same arguments as the other gf_ functions. Similar to these function, you can include optional arguments to color the plot and add axis labels.\nFigure¬†6.5 shows the density plot for the density plot for the admissions rate attribute plotted earlier in a histogram.\n\ngf_density(\n  ~ adm_rate, data = colleges,\n  color = \"black\", \n  fill = \"yellow\",\n  xlab = \"Admission Rate\",\n  ylab = \"Density\"\n  )\n\n\n\n\n\n\n\nFigure¬†6.5: Density plot of college admission rates.\n\n\n\n\n\nBased on the density plot, we can see that the shape of the distribution of admission rates is left-skewed.\n\nThe metric on the y-axis in a density plot is no longer counts, it is ‚Äúprobability density‚Äù, or just ‚Äúdensity‚Äù. We don‚Äôt interpret those values, but rather focus on the relative height of the curve. That is, areas of the density curve that are higher indicate more data in those areas of the attribute of interest. Places where the density curve is lower indicates areas where data occur infrequently.\n\nOur interpretation of the distribution of admission rates remains that most institutions of higher learning admit a high proportion of applicants. In fact, colleges that admit around 75% of their applicants have the highest probability density, indicating this is where most of the institutions are found in the distribution. Additionally, there are just a few institutions that are have an admission rate 25% or less.\n\n\n6.3.1 More about Shape\nIn addition to the overall symmetry or direction of skewness, another aspect of shape that we should describe is the number of modes in the distribution. The distributions we have looked as so far have been unimodal, that is, they have a single mode or ‚Äúhump‚Äù in the distribution.\nOther distributions have multiple modes. For example, the distribution in Figure¬†6.6 is bimodal (it has two modes). If a distribution has more than one mode, it often indicates that there are different groups that have been mixed into the data. For example, in Figure¬†6.6 we see one mode around 180 minutes (3 hours) and another taller mode around 300 minutes (5 hours). This might indicate that there are two different groups of runners that competed in the Legacy Marathon‚Äîone smaller group that was faster (e.g., elite runners) and one larger group that was slower.\n\n\n\n\n\n\n\n\nFigure¬†6.6: Distribution of times for a random sample of runners who competed in the 2022 Legacy Marathon.\n\n\n\n\n\n\n\n\n6.3.2 Center and Variation: Two Additional Characteristics to Describe\nIn addition to the describing the shape of the distribution, there are two other characteristics of a quantitative distribution that we want to describe: the center and the variation.\nThe ‚Äúcenter‚Äù of a distribution is misleading in that it doesn‚Äôt literally mean the center of the distribution. What it really means is ‚Äútypical value‚Äù. In the distribution of admission rates presented in Figure¬†6.5, a typical admission rate might be around 0.75. This value is at the mode in the distribution.\nWe also need to describe the variation in the distribution. When estimating the variation from a density plot we typically describe the overall range of values, as well as, the range of values within which most of the data falls. In the distribution of admission rates presented in Figure¬†6.5, there are admission rates between 0 and 1, but most of the institutions of higher learning have an admission rate between 0.65 and 0.85. This could also be given as a range of values around the typical value‚Äî\\(0.75 \\pm 0.10\\)\n\nA full description of a quantitative distribution includes shape, center, and variation. Here is how we might descirbe the distribution of admission rates presented in Figure¬†6.5:\n\nThe distribution of admission rates is left-skewed. Most institutions admit a high proportion of applicants. A typical institution in the distribution admits around 75% of its applicants (\\(\\pm\\) 10%). There are, however, a few institutions that are quite selective, admitting fewer than 25% of the students who apply.\n\n\nIn a multi-modal distribution, the identification of center and variation is more difficult, since there are multiple typical values. For example, in the distribution of marathon times presented in Figure¬†6.6, there are two typical values, one around 180 minutes and another around 300 minutes. Similarly, in describing the variation we often describe a range of values around each typical value that depicts where most of the data fall. From Figure¬†6.6, most of the faster runners finished the Legacy Marathon between 160 and 190 minutes, whereas most of the slower runners finished with a time between 200 and 400 minutes.\n\nYour Turn\nCreate a density plot for the distribution of median earnings for students. Add appropriate labels to the axes.\n\nShow/Hide Solution\n\n\n\ngf_density(\n  ~ mdn_earn, data = colleges,\n  color = \"black\", \n  fill = \"yellow\",\n  xlab = \"Median Earnings\",\n  ylab = \"Density\"\n  )\n\n\n\n\n\n\n\n\n\nDescribe the shape, center, and variation of this distribution and what it tells you about students‚Äô median earnings 10 years after being enrolled in college.\n\nShow/Hide Solution\n\n\nThe distribution of median earnings is right skewed. The median amount of money earned 10 years after graduation is around $50k (\\(\\pm \\$10k\\)). There are some institutions where the median earnings of students is quite high (~100k).",
    "crumbs": [
      "Summarizing and Visualizing Data",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Summarizing and Visualizing Quantitative Attributes</span>"
    ]
  },
  {
    "objectID": "03-02-quantitative-attributes.html#numerical-summaries",
    "href": "03-02-quantitative-attributes.html#numerical-summaries",
    "title": "6¬† Summarizing and Visualizing Quantitative Attributes",
    "section": "6.4 Numerical Summaries",
    "text": "6.4 Numerical Summaries\nIn the previous examples, we estimated the typical value (center) and variation from a visualization of the distribution. If the distribution is unimodal, we can also obtain more precise values for these characteristics by computing different numerical summaries.3\n\n6.4.1 Learn More\nIn this class we will focus on the computation of these values using R and their interpretations rather than on the mathematical manipulation and formulas. Here are some links to learn more about the underlying calculations of the measures that we will focus on in this class if you are interested: mean, median, and mode, range interquartile range (IQR), standard deviation.\n\nIn describing the center of the distribution, we estimated the typical value based on the value for the ‚Äúmodal hump‚Äù in the density plot. There are two numerical values that are often computed to summarize the center of the distribution: the mean and the median.\nIn a perfectly symmetric distributions, the mean and median are the same value. In practice, they are rarely exactly the same. If the distribution is roughly symmetric, these values should be similar. In skewed distributions, the mean and median will be different. In these distributions, the mean will be further in the tail of the distribution than the median.\n\n\n\n\n\n\n\n\n\n\n\n(a) Left-Skewed Distribution\n\n\n\n\n\n\n\n\n\n\n\n(b) Symmetric Distribution\n\n\n\n\n\n\n\n\n\n\n\n(c) Right-Skewed Distribution\n\n\n\n\n\n\n\nFigure¬†6.7: Mean, median, and modal values in a left-skewed, symmetric, and right-skewed distribution.\n\n\n\nIn a symmetric distribution, any of the three center values (mean, median, or mode) are a good summarization of a typical value since they are all roughly the same. In skewed distributions, because the mean is further in the tail, it is often not a good reflection of a typical value in the distribution. Instead, the median or mode is often a better summary in these distributions.\n\n\n6.4.2 Computing Numerical Summaries in R\nTo compute numerical summary values, including the mean and median, we use the df_stats() function from the {mosaicCore} package. This function takes the exact same arguments as the gf_ functions. The syntax below shows how to compute numerical summaries for the admissions rate attribute.\n\n# Compute numerical summaries\ndf_stats(~adm_rate, data = colleges)\n\n\n  \n\n\n\nThe mean, or average, of the 230 institutions‚Äô admission rates is 0.68 and the median admission rate for these institutions is 0.72. The slightly lower mean value is consistent with how the mean and median compare in a left-skew distribution. Because the distribution is skewed the median of 0.68, or modal value of 0.75, is a better indication of a typical admission rate.\n\nYour Turn\nCompute the mean and median for the distribution of students‚Äô median earnings 10 years after being enrolled in college\n\nShow/Hide Solution\n\n\n\ndf_stats(~mdn_earn, data = colleges)\n\n\n  \n\n\n\nThe mean earnings is $51,134 and the median earnings is $49,316.\n\nBased on the distribution of students‚Äô median earnings 10 years after being enrolled in college is the mean or median a better summary of a typical value in the distribution? Explain.\n\nShow/Hide Solution\n\n\nBecause the distribution of earnings is right-skewed, the median is a better summary of a typical value in the distribution.\n\n\n\n\n\n6.4.3 Numerically Summarizing Variation\nThere are several summary measures that statisticians use to summarize the variation in a quantitative distribution. In this class we will focus on three of these measures: the range, the standard deviation, and the interquartile range (IQR).\n\nThe range is the difference between the maximum and minimum values in the distribution.\nThe standard deviation is measure of how far, on average, values in the distribution are from the mean.\nThe interquartile ranger (IQR) is the range of the middle 50% of the distribution.\n\nTo illustrate how to compute these values, we will again use df_stats() to compute the summaries for the admission rate attribute.\n\n# Compute numerical summaries\ndf_stats(~adm_rate, data = colleges)\n\n\n  \n\n\n\nThe range of the distribution is \\(1 - 0.0519 = 0.9481\\). Note that the range is a single value. Alternatively, we can say the admission rates range from 0.0519 to 1. This summary indicates the overall variation in the attribute.\nThe standard deviation is computed and returned in the sd column of the df_stats() output. The standard deviation of the admission rates is 0.217. Interpreting this, we would say that on average, most admission rates are within .216 of the mean. That is, most admission rates are between 0.47 and 0.90. To compute this range:\n\\[\n\\begin{split}\n&\\mathrm{Mean} \\pm \\mathrm{SD}\\\\[2ex]\n&0.683 - 0.217 = 0.47 \\\\[2ex]\n&0.683 + 0.217 = 0.90\n\\end{split}\n\\] The last summary measure of variation we will compute is the IQR. The IQR is the difference between the 75th-percentile value (Q3) and the 25th-percentile value (Q1). In the admission rates attribute this is:\n\\[\n\\begin{split}\n\\mathrm{IQR} &= 0.840975 - 0.5597 \\\\[2ex]\n&= 0.281\n\\end{split}\n\\]\nThat is the middle 50% of the admission rates have a range of 0.281‚Äîthey range from 0.56 to 0.84.\n\nYour Turn\nCompute the range, IQR, and standard deviation for the distribution of students‚Äô median earnings 10 years after being enrolled in college.\n\nShow/Hide Solution\n\n\n\ndf_stats(~mdn_earn, data = colleges)\n\n\n  \n\n\n# Range = 132969 - 19513 = 113456\n# IQR = 56535.75 - 43031 = 13504.75\n# SD = 14.601k\n\n\nBased on the distribution of students‚Äô median earnings 10 years after being enrolled in college which summary measure(s) of variation would you report? Explain.\n\nShow/Hide Solution\n\n\nBecause the distribution of earnings is right-skewed, we might report the IQR in addition to the range.\n\n\nSimilar to the numerical summaries for the center of a distribution, some measures of variation are better suited toward summarizing symmetric distributions and others for skewed distributions. For all distributions, the range is typically provided to summarize the overall variation. In addition, for symmetric distributions, the standard deviation is also conventionally used to summarize the variation for most cases. In skewed distributions, the IQR is a better numerical summary of the variation than the standard deviation.\n\nAdding the numerical summaries to our previous description of the distribution of admission rates presented in Figure¬†6.5:\n\nThe distribution of admission rates is left-skewed. There is a great deal of variation in addmission rates, with institutions of higher learning admitting as few as .5% of their applicants, and some as many as 100%. A typical institution in the distribution admits around 72% (median) of its applicants with half admitting between 56% (Q1) and 84% (Q3) of their applicants. This suggests that most institutions admit a high proportion of applicants. There are, however, a few institutions that are quite selective, admitting fewer than 25% of the students who apply.\n\n\nThere is no one correct way to summarize and report the characteristics of a quantitative distribution. You will want to describe the shape, center, and variation, but how you do that may be different from how another person chooses to do that. For example, in the description of the distribution of admission rates I chose to report the characteristics using text/prose. Another researcher might have instead chosen to report this information in a table rather than writing about it. As an applied scientist or researcher you need to be able to do both.\n\nIn practice you might try multiple reporting strategies within a paper before you settle on one that is ‚Äúbest‚Äù for that paper. Think of it like you do in drafting writing‚Äîoften your first attempt isn‚Äôt the same as the final product, and it may take several iterations to get to that final draft.",
    "crumbs": [
      "Summarizing and Visualizing Data",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Summarizing and Visualizing Quantitative Attributes</span>"
    ]
  },
  {
    "objectID": "03-02-quantitative-attributes.html#summary",
    "href": "03-02-quantitative-attributes.html#summary",
    "title": "6¬† Summarizing and Visualizing Quantitative Attributes",
    "section": "6.5 Summary",
    "text": "6.5 Summary\nThere are several R functions that are useful for summarizing categorical attributes. Table¬†6.1 shows the functions (and their descriptions) you will use to summarize and visualize quantitative attributes. Note that they all have very parallel syntax.\n\n\n\n\nTable¬†6.1: The functions and their descriptions to summarize and visualize quantitative attributes.\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\nFunction\nDescription\n\n\n\n\nSummarize\n\n\ndf_stats(~attribute, data = data_object)\nCompute common summaries of a quantitative attribute\n\n\nVisualize\n\n\ngf_histogram(~attribute, data = data_object)\nCreate histogram\n\n\ngf_density(~attribute, data = data_object)\nCreate density plot\n\n\n\n\n\n\n\n\n\n\n\nWhen describing a quantitative distribution, there are three characteristics to attend to: shape, center, and variation. These can be estimated from a plot of the distribution, and the center and variation can also be summarized numerically. Often the shape of the distribution dictates which measures are provided in the description of the attribute. Table¬†6.2 presents a guide for thinking about what should be reported based on the shape of the distribution.\n\n\n\n\nTable¬†6.2: Characteristics (shape, center, and variation) of different quantitative distributions that might get reported to summarize them.\n\n\n\n\n\n  \n  \n\n\n\nExample\nShape\nCenter\nVariation\n\n\n\n\n\nLeft-skewed\nMedian, Mode\nRange (overall) and IQR (typical)\n\n\n\nSymmetric\nMean\nRange (overall) and SD (typical)\n\n\n\nRight-skewed\nMedian or Mode\nRange (overall) and IQR (typical)",
    "crumbs": [
      "Summarizing and Visualizing Data",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Summarizing and Visualizing Quantitative Attributes</span>"
    ]
  },
  {
    "objectID": "03-02-quantitative-attributes.html#footnotes",
    "href": "03-02-quantitative-attributes.html#footnotes",
    "title": "6¬† Summarizing and Visualizing Quantitative Attributes",
    "section": "",
    "text": "This function is part of the {ggformula} package which needs to be loaded prior to using the gf_histogram() function.‚Ü©Ô∏é\nR knows the names of 657 colors. To see these names type colors() at the command prompt.‚Ü©Ô∏é\nIf the distribution is multi-modal many of these summaries cannot be computed, and even if they can be computed they are meaningless as summaries of a typical value or variation.‚Ü©Ô∏é",
    "crumbs": [
      "Summarizing and Visualizing Data",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Summarizing and Visualizing Quantitative Attributes</span>"
    ]
  },
  {
    "objectID": "04-00-comparing-to-a-standard.html",
    "href": "04-00-comparing-to-a-standard.html",
    "title": "Comparing Data to a Standard",
    "section": "",
    "text": "One task that is commonly performed in research is to compare the data you have to a specified standard or value. For example, is the average income for a community higher than the poverty level? Or, is the mean admission rate for institutions of higher learning in the United States higher than 0.50?\nIn previous chapters you learned how to compute characteristics of the distribution (e.g., the mean) that would allow us to answer these questions about the sample. For example, in 6¬† Summarizing and Visualizing Quantitative Attributes, we found that the average admission rate for our 230 sample institutions of higher learning was 0.68. Based on this, we could say that the average admission rate for our sample of 230 schools was higher than 0.50. But, is this true when we grow our sample to ALL institutions of higher learning? Is the mean admission rate for ALL institutions of higher learning in the United States higher than 0.50?\nDrawing conclusions beyond the data we have is called inference, and the associated methods that allow researchers to allows us to learn from incomplete or imperfect data are referred to as statistical inference (Gelman & Hill, 2007). In this part of the textbook, you will learn about a set of statistical inferential methods that allow you to compare a sample of data to some standard in order to draw inferences about how the population compares to that standard (e.g., is the average income for a community higher than the poverty level?). To answer this type of inferential question, you will learn about how we quantify the amount of uncertainty associated with our sample numerical estimate when we have incomplete data (i.e., only a sample of data from the population we want to infer to). You will also learn how we then use that quantification in a one-sample hypothesis test to draw an inference about how a population parameter compares to that standard. Finally, you will learn about potential errors that can be made when conducting hypothesis tests and also assumptions underlying the methods we use to carry out these tests.\n\n\n\n\nGelman, A., & Hill, J. (2007). Data analysis using regression and multilevel/hierarchical models. Cambridge University Press.",
    "crumbs": [
      "Comparing Data to a Standard"
    ]
  },
  {
    "objectID": "04-01-case-study-teen-sleep.html",
    "href": "04-01-case-study-teen-sleep.html",
    "title": "7¬† Case Study: Teen Sleep",
    "section": "",
    "text": "7.1 Descriptive Analysis\nAfter importing the data, we will start by exploring the data. Because we are interested in the hours of sleep teens are getting, we will visualize and numerically describe the hrs_sleep attribute.\n# Create density plot\ngf_density(\n  ~ hrs_sleep, data = teen_sleep,\n  color = \"black\", \n  fill = \"skyblue\",\n  xlab = \"Hours of Sleep\",\n  ylab = \"Density\"\n  )\n\n# Compute numerical summaries\ndf_stats(~hrs_sleep, data = teen_sleep)\n\n\n\n\n\n\n\n\nFigure¬†7.1: Density plot of the hours of sleep for 75 teenagers.\n\n\n\n\n\n\n\n\n\n\nFigure¬†7.2: Density plot of the hours of sleep for 75 teenagers.\nDescribing the amount of sleep teens get we might say:\nBased on the visual and numerical evidence, we might conclude that, on average, teens are not getting the recommended 9 hours of sleep a night. The key words here in the conclusion are: ‚Äúon average‚Äù. Statistically, we are saying that a typical teen in the distribution (around 7.5 hours of sleep a night) is not getting the recommended 9 hours of sleep a night. It is important to note that we are not talking about individual teens here (some of the teens in the sample are getting 9 or more hours of sleep a night), but rather are asking the question: on average, are teens getting the recommended 9 hours of sleep a night.\nUsing this interpretation, we can definitively say that the 75 teens in our sample are, on average, not getting 9 or more hours of sleep a night‚Äîthey are averaging 7.4 hours of sleep a night (based on the sample mean). Our research question, however is not whether these 75 teens are getting the recommended amount of sleep, but whether teens more generally are getting the recommended 9 hours of sleep a night. To answer this requires that we infer beyond our sample of 75 teens to the broader population of teens from which they were sampled from.",
    "crumbs": [
      "Comparing Data to a Standard",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Case Study: Teen Sleep</span>"
    ]
  },
  {
    "objectID": "04-01-case-study-teen-sleep.html#descriptive-analysis",
    "href": "04-01-case-study-teen-sleep.html#descriptive-analysis",
    "title": "7¬† Case Study: Teen Sleep",
    "section": "",
    "text": "There is a great deal of variation in the hours of sleep that teens get, with some teenagers getting as much as 11 hours of sleep a night, and others getting as little as 4 hours. A typical teen in the sample gets around 7.5 hours of sleep a night. The SD of 1.5 further indicates most teens get between 6 and 9 hours of sleep a night. There is some evidence in the density plot that suggests the distribution of teen sleep may be bimodal, with a much smaller group of teens averaging around 5 hours of sleep a night.\n\n\n\n\nThe data a researcher has is sometimes referred to as the observed data, it is after all what is observed. Consequently, the summary measures from the data are sometimes referred to as observed results. As an example, the mean in our teen sleep data of 7.5 might be referred to as the observed mean. Statisticians might also refer to the observed mean as the sample mean, since it is the mean of the sample data!",
    "crumbs": [
      "Comparing Data to a Standard",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Case Study: Teen Sleep</span>"
    ]
  },
  {
    "objectID": "04-01-case-study-teen-sleep.html#statistical-inference-using-sample-data-to-draw-conclusions-about-the-population",
    "href": "04-01-case-study-teen-sleep.html#statistical-inference-using-sample-data-to-draw-conclusions-about-the-population",
    "title": "7¬† Case Study: Teen Sleep",
    "section": "7.2 Statistical Inference: Using Sample Data to Draw Conclusions about the Population",
    "text": "7.2 Statistical Inference: Using Sample Data to Draw Conclusions about the Population\nIn many studies, the primary interest is to learn about one or more characteristics about a population. Although these characteristics must be estimated from sample data, the sample (and thus the estimate computed from the sample) form an incomplete picture of the population. As an example, consider the pictures of Goldy Figure¬†7.3. In the left-hand panel every pixel of the picture is shown. In the right-hand panel, we have only shown a random sample of the pixels. While the picture on the right is incomplete, we can still infer what the original picture looks like. This idea is similar to how we can make inferences about a population from a subset of cases (i.e., a sample).\n\n\n\n\n\n\n\n\n\n\n\n(a) Population\n\n\n\n\n\n\n\n\n\n\n\n(b) Sample\n\n\n\n\n\n\n\nFigure¬†7.3: Goldy.\n\n\n\nThe issue with using the sample data to draw a conclusion about the larger population is that the sample is an incomplete picture of the larger population. This means that any estimate we obtain from the sample needs to account for this incompleteness or uncertainty. For example, in the right-hand panel of Figure¬†7.3 the incomplete data leads to uncertainty about the actual picture. The information there allows us to make some inferences (e.g., it is a photo of Goldy), but there is still uncertainty because some of the pixels are not shown.\nIn our example of determining whether teenagers are sleeping 9 or more hours, we used sample data to obtain an estimate of the average amount of sleep teens are getting in a night, namely 7.4 hours of sleep a night. Because we based this estimate on incomplete data (i.e., from a sample) there is uncertainty associated with this estimate‚Äî7.4 hours is probably not the average number of hours ALL teens sleep a night. Quantifying the uncertainty gives us a better estimate. For example, this quantification might suggest that teens sleep, on average, between 6.0 and 8.8 hours a night.\n\n\n7.2.1 Sources of Uncertainty\nWhy does incomplete data lead to uncertainty? It turns out, there are several sources of uncertainty, the most common of which are:\n\nSampling variation (a.k.a, sampling error); and\nMeasurement variation (a.k.a., measurement error)\n\nSampling variation is the idea that different samples that can be drawn from the same population produce different estimates.\nFor example, what if if we had used a different sample of 75 teenagers. The amount of sleep these teens got would likely be different than our original 75 teens, which means that their average amount of sleep (the sample mean) would also be different than the original average of 7.4. This tells us that the uncertainty in the estimate is a function of the random nature of the sampling.\nAnother source of uncertainty in estimates is imperfect measurement, or measurement error. This arises most often when the constructs we are measuring can not be directly observed (i.e., they are latent) and we have to use proxies of these construct in our analysis. For example, the way the researchers in the original study measured the amount of sleep was via a self-report survey; they asked teens and their parents to indicate the teen‚Äôs typical bedtime and wake-up time using a drop down menu that gave times in 5 minute increments. Self-reporting, even with the parent responses as a check, are likely imperfect measures of the amount of sleep a teen gets. Further, if we compute a numerical summary, say the mean, from scores that are imperfect measures, then that mean will also be an uncertain estimate. The uncertainty in the sample estimate is now not only due to sampling error, but also because of the measurement error inherent in its computation.\nIn practice, despite these being very different sources of variation, measurement error and sampling error are often combined and treated as if all of the uncertainty was due to sampling error.\n\nEPsy 5261, we will focus on quantifying uncertainty via estimating the sampling variation/sampling error. You can learn more about how to compute and account for measurement error in courses like EPsy 5221: Priciples of Educational and Psychological Measurment.",
    "crumbs": [
      "Comparing Data to a Standard",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Case Study: Teen Sleep</span>"
    ]
  },
  {
    "objectID": "04-01-case-study-teen-sleep.html#uncertainty-due-to-sampling-error",
    "href": "04-01-case-study-teen-sleep.html#uncertainty-due-to-sampling-error",
    "title": "7¬† Case Study: Teen Sleep",
    "section": "7.3 Uncertainty Due to Sampling Error",
    "text": "7.3 Uncertainty Due to Sampling Error\nTo give you a better sense of the uncertainty in an estimate that is due to sampling error and the methods we use to quantify sampling error, consider the following thought experiment: Imagine the population of amount of sleep per night taken for every teenager (past, present, and future). There would be an infinite number of these values, but theoretically, we could plot all of these values, and compute numerical summaries such as the mean and standard deviation of these values. (The mean of this distribution is what we are trying to estimate using our sample data.) The conceptual idea of estimating sampling variation is that we are going to draw a sample of 75 students and compute the mean amount of sleep for that sample. Then we are going to repeat this process again, and again, each time drawing 75 observations and computing the mean amount of sleep. Figure¬†8.1 shows a visual depiction of this thought experiment that was carried out 1000 times.\n\n\n\n\n\n\n\n\nFigure¬†7.4: Thought experiment for drawing random samples of size 75 from the population to obtain different samples. The average amount of sleep per night is computed for each sample drawn.\n\n\n\n\n\nThe 1000 sample means can then be plotted, and we can compute a numeric summary of the variability in the distribution of sample means.\n\n\n\n\n\n\n\n\nFigure¬†7.5: Distribution of 1000 sample means. Each observation in the distribution is a mean indicating the average amount of sleep per night for one sample. The red dots show the means computed from Figure¬†8.1.\n\n\n\n\n\nIn Figure¬†7.5 each observation plotted in the distribution is one of the means from a sample drawn in our thought experiment. For example, the red dots indicate the five sample means reported in Figure¬†8.1, namely 7.48 (mean of Sample 1), 6.90 (mean of Sample 2), 7.78 (mean of Sample 3), 7.32 (mean of Sample 4), and 7.24 (mean of Sample 1000). When the cases in a distribution are numerical summaries, we call that distribution a sampling distribution. The distribution in Figure¬†7.5 is a sampling distribution of the mean, indicating that the numerical summaries being plotted are means.\nRemember that our purpose for producing this distribution is to summarize the variation in the mean values, that is, we want to produce a numerical summary of the variation in the sampling distribution of the means shown in Figure¬†7.5. This distribution is approximately normal (unimodal and symmetric), so the standard deviation will be a good summary of the variation in this distribution.\n\nIf you have a distribution that is unimodal and symmetric, you can estimate the standard deviation by determining the halfway point of the height of the middle of the distribution. You can then follow that out to either side of the distribution and that width is a good guess for the standard deviation.\n\n\n\n\n\n\n\n\nFigure¬†7.6: Visual depiction of how to estimate the standard deviation in a unimodal symmetric distribution.\n\n\n\n\n\n\nIn the sampling distribution, in Figure¬†7.5, we estimate the standard deviation to be approximately 0.2. Because this standard deviation is quantifying the variability in a distribution of summary statistics, we refer to it as a standard error (SE).\nRecall that each of the samples were randomly sampled from the same population and that the sample mean is a guess for the value of the population mean‚Äîthe average amount of nightly sleep for ALL teens. Since the only source of variation in the sampling distribution is sampling error (that is, the only reason the sample means are different is that different teens were chosen to be a part of each sample), the SE is a quantification of the uncertainty due to sampling error we expect in our estimate. Based on a typical value in the distribution of about 7.4, and using our SE of 0.20, we can say:\n\nWe think that the mean amount of sleep each night for ALL teens is between 7.2 and 7.6. This range of values captures the uncertainty in the estimate (the sample mean) that is due to sampling error.",
    "crumbs": [
      "Comparing Data to a Standard",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Case Study: Teen Sleep</span>"
    ]
  },
  {
    "objectID": "04-01-case-study-teen-sleep.html#looking-ahead",
    "href": "04-01-case-study-teen-sleep.html#looking-ahead",
    "title": "7¬† Case Study: Teen Sleep",
    "section": "7.4 Looking Ahead",
    "text": "7.4 Looking Ahead\nIn practice, you do not draw 1000 samples; you have one sample of data that you have collected. So one of the things we will need to learn is how to produce a standard error based on only one sample of data. You will also learn about how to use the standard error in hypothesis tests evaluate how well data conforms to particular quantitative hypotheses we may have about the population. Finally, you will learn about a theoretical result in statistics known as the Empirical Rule, which will help us put probabilistic statements around the quantification of uncertainty to produce confidence intervals.",
    "crumbs": [
      "Comparing Data to a Standard",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Case Study: Teen Sleep</span>"
    ]
  },
  {
    "objectID": "04-01-case-study-teen-sleep.html#references",
    "href": "04-01-case-study-teen-sleep.html#references",
    "title": "7¬† Case Study: Teen Sleep",
    "section": "7.5 References",
    "text": "7.5 References\n\n\n\n\nJohns Hopkins University. (2023). Teenagers and sleep: How much sleep is enough? https://www.hopkinsmedicine.org/health/wellness-and-prevention/teenagers-and-sleep-how-much-sleep-is-enough\n\n\nNational Institutes of Health. (2021). Good sleep for good health: Get the rest you need. In NIH News in Health. https://newsinhealth.nih.gov/2021/04/good-sleep-good-health",
    "crumbs": [
      "Comparing Data to a Standard",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Case Study: Teen Sleep</span>"
    ]
  },
  {
    "objectID": "04-02-simulation.html",
    "href": "04-02-simulation.html",
    "title": "8¬† Bootstrapping: Using Simulation to Estimate the Uncertainty",
    "section": "",
    "text": "8.1 Bootstrapping\nThe key question addressed by using any statistical method of inference is ‚Äúhow much variation is expected in a particular test statistic if one repeatedly draws random samples from the same population?‚Äù In the thought experiment we introduced in Chapter 7, the method for quantifying the uncertainty was to repeatedly sample from the population and measure the variation in the sample means. Recall that the quantification of the uncertainty (i.e., variation in the sample means) is referred to as the standard error.\nFigure¬†8.1: Thought experiment for drawing random samples of size 75 from the population to obtain different samples. The average amount of sleep per night is computed for each sample drawn.\nBradley Efron introduced the methodology of bootstrapping in the late 1970s as an alternative method to compute the standard error.1\nEfron‚Äôs big discovery was that in the thought experiment, we could replace the population with a sample, and then randomly sample from that initial sample. He proved that using this methodology, you can obtain a good estimate of the sampling variation.\nFigure¬†8.2: Thought experiment for bootstrapping random samples of size 75 from the original sample of 75 students‚Äô sleep times to obtain different samples. The average amount of sleep per night is computed for each re-sample drawn.\nBecause we need to randomly sample 75 observations out of the original sample (which itself only includes 75 observations), we need to sample WITH REPLACEMENT when we draw our re-samples. In this way, we mimic drawing random samples from a larger population without actually needing the larger population.",
    "crumbs": [
      "Comparing Data to a Standard",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Bootstrapping: Using Simulation to Estimate the Uncertainty</span>"
    ]
  },
  {
    "objectID": "04-02-simulation.html#importing-the-teen-sleep-data",
    "href": "04-02-simulation.html#importing-the-teen-sleep-data",
    "title": "8¬† Bootstrapping: Using Simulation to Estimate the Uncertainty",
    "section": "8.2 Importing the Teen Sleep Data",
    "text": "8.2 Importing the Teen Sleep Data\nWe will use the data in teen-sleep.csv to bootstrap a standard error of the mean. These data include the bedtime, wake-up time, and hours slept for a sample of \\(n=75\\) American teens in Grades 9‚Äì12.\n\nteen-sleep.csv\nData Codebook\n\nWe will prepare for the analysis by loading in the {tidyverse}, {ggformula}, and {mosaicCore} libraries and importing the teen sleep data. We will also load the {mosiaic} package.\n\nlibrary(ggformula)\nlibrary(mosaicCore)\nlibrary(mosaic)\nlibrary(tidyverse)\n\n\n# Import data\nteen_sleep &lt;- read_csv(\"https://raw.githubusercontent.com/zief0002/epsy-5261/main/data/teen-sleep.csv\")\n\n# View data\nteen_sleep",
    "crumbs": [
      "Comparing Data to a Standard",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Bootstrapping: Using Simulation to Estimate the Uncertainty</span>"
    ]
  },
  {
    "objectID": "04-02-simulation.html#bootstrapping-from-the-teen-sleep-data",
    "href": "04-02-simulation.html#bootstrapping-from-the-teen-sleep-data",
    "title": "8¬† Bootstrapping: Using Simulation to Estimate the Uncertainty",
    "section": "8.3 Bootstrapping from the Teen Sleep Data",
    "text": "8.3 Bootstrapping from the Teen Sleep Data\nThe process for computing the standard error via bootstrapping is:\n\nSTEP 1: Randomly sample n observations from the observed sample of size n (with replacement) This is called a bootstrap sample or a re-sample.\nSTEP 2: Compute the mean of the bootstrap sample.\nSTEP 3: Repeat the first two steps in the process many times (say 1000 times), each time recording the mean.\nSTEP 4: Find the standard deviation of these means (i.e., the standard error of the mean).\n\nThe computations we do will parallel each step of this process. As you learn how to do this, it is easy to get lost in the computing and forget why you are doing this. Remember, the end goal is to mimic the thought experiment so we can quantify the variation in the sample means.\n\n\n8.3.1 STEP 1: Randomly sample 75 observations from the observed sample of size 75 teen sleep amounts (with replacement)\nTo randomly sample from a set of values we use the sample() function. We will need to specify the values we are sampling from (i.e., the original sample) as an input to the function. The data we want to randomly sample from is in a column called hrs_sleep inside the data object called teen_sleep. To specify a particular column in a data object we use the following notation: teen_sleep$hrs_sleep. We also need to set the number of observations to randomly sample, and tell this function that we are sampling with replacement.\nThus to draw a random sample of values from our data we use:\n\n# Randomly sample from the hrs_sleep column located in the teen_sleep data object\n# Draw 75 observations\n# Sample with replacement\nsample(teen_sleep$hrs_sleep, size = 75, replace = TRUE)\n\n [1]  8.333333  7.500000  8.583333  7.916667  4.916667  7.500000  5.916667\n [8]  9.166667  9.166667  8.250000  6.750000  7.500000  7.500000  7.500000\n[15]  7.083333  7.666667  7.666667  8.083333  6.750000  8.583333  6.083333\n[22]  4.666667  7.416667  7.916667  8.083333  7.583333  8.500000  8.916667\n[29]  4.416667  7.583333 10.083333  7.583333  4.583333  7.083333 10.083333\n[36]  7.166667  7.750000  8.333333 11.083333  6.416667  7.666667  5.166667\n[43]  6.416667  7.333333  8.333333  7.000000  7.666667  6.083333  6.916667\n[50]  7.750000  7.333333  5.166667  7.916667  7.666667  5.416667  4.166667\n[57]  4.500000  7.916667  7.500000 10.083333  6.333333  4.666667  5.833333\n[64]  5.916667  5.416667  4.666667  9.083333  9.916667  6.583333  8.333333\n[71]  7.333333  5.166667  8.333333  9.750000  6.500000\n\n\nThis is akin to drawing a bootstrap sample from the original sample. Note that because we are drawing randomly, if you are trying this on your computer, you might get a different bootstrap sample than the one shown here. If you re-run this syntax, you will get a different bootstrap sample.\n\n# Draw a second bootstrap sample of 75 observations\nsample(teen_sleep$hrs_sleep, size = 75, replace = TRUE)\n\n [1]  7.833333  9.166667  7.500000  6.750000  4.500000  5.916667  6.416667\n [8]  6.083333  7.583333  7.583333  6.916667  8.333333  7.666667  4.166667\n[15]  5.916667  6.083333  9.750000  4.500000 11.083333  9.166667  7.166667\n[22]  4.833333  6.500000  5.416667  6.916667  5.416667  8.750000  4.166667\n[29] 10.333333  7.916667  7.333333  8.500000  7.583333  6.083333  6.583333\n[36]  7.916667  4.583333  7.166667  7.083333  6.833333  4.500000  4.166667\n[43] 11.083333  5.833333 11.083333  7.500000  7.500000  4.833333  8.083333\n[50]  7.666667  5.833333  5.416667  7.500000  4.666667  6.500000  6.750000\n[57]  8.833333  7.916667  8.750000  4.583333  4.833333  7.166667  7.500000\n[64]  7.500000  8.416667  8.333333  5.916667  8.416667  8.333333  4.666667\n[71]  7.333333  7.333333  8.750000  8.583333  7.916667\n\n\n\n\n\n8.3.2 STEP 2: Compute the mean of the bootstrap sample.\nTo compute the mean of a bootstrap sample, we are just going to embed our sample() syntax inside of the mean() function. For example,\n\n# Draw a bootstrap sample of 75 observations and compute the mean\nmean(sample(teen_sleep$hrs_sleep, size = 75, replace = TRUE))\n\n[1] 7.233333\n\n\nYou could re-run this syntax to draw another bootstrap sample and compute the mean.\n\n\n\n8.3.3 STEP 3: Repeat the first two steps in the process many times (say 1000 times), each time recording the mean.\nTo repeat a set of computations, we are going to use the do() function from the {mosaic} package. As a reminder, you will need the {mosiac} package loaded prior to using this function. The syntax for the do() function takes the following format:\ndo(N times) * {Computations to repeat}\nAs an example, if we wanted to carry out our computations to draw a bootstrap sample and compute the mean 10 times, the synatx is:\n\n# Draw a bootstrap sample of 75 observations and compute the mean\n# Do this 10 times \ndo(10) * {mean(sample(teen_sleep$hrs_sleep, size = 75, replace = TRUE))}\n\n\n  \n\n\n\nThe computations are carried out 10 times and the results are recorded in a column (result) of a data object. Because we will ultimately want to compute on this data object, when we run this, we will want to assign the data into an object. Below, we draw 1000 bootstrap samples, each time computing the mean, and assign them into a data object called bootstrap_means.\n\n# Draw a bootstrap sample of 75 observations and compute the mean\n# Do this 1000 times \n# Assign these into an object called bootstrap_means\nbootstrap_means &lt;- do(1000) * {mean(sample(teen_sleep$hrs_sleep, size = 75, replace = TRUE))}\n\n# View the results\nbootstrap_means\n\n\n  \n\n\n\n\n\n\n8.3.4 STEP 4: Find the standard deviation of these means (i.e., the standard error of the mean).\nRemember our goal was to compute the standard error, which quantifies the uncertainty in the sample mean estimates that is due to sampling variation. Before we do that, we will visualize the distribution of bootstrapped means.\n\n# Create a density plot of the bootstrapped means\ngf_density(\n  ~result, data = bootstrap_means,\n  xlab = \"Mean value\",\n  ylab = \"Density\"\n)\n\n\n\n\n\n\n\nFigure¬†8.3: Distribution of 1000 bootstrapped means.\n\n\n\n\n\nThe distribution of bootstrapped means is unimodal and symmetric. This indicates that the standard deviation is a reasonable numeric summary of the variation. Again, since the cases in the distribution are means (summary measures), the standard deviation is referred to as a standard error. To compute the standard error, we use df_stats():\n\n# Compute SE\ndf_stats(~result, data = bootstrap_means)\n\n\n  \n\n\n\nHere the standard error (found in the sd column) is 0.17.\n\nThe distribution of bootstrapped means should be centered at the value of the original sample mean. In our teen sleep example, the original sample had a mean of 7.4. This value is roughly at the center of the distribution in Figure¬†8.3. This can be a self-check when you create a bootstrap distribution.",
    "crumbs": [
      "Comparing Data to a Standard",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Bootstrapping: Using Simulation to Estimate the Uncertainty</span>"
    ]
  },
  {
    "objectID": "04-02-simulation.html#references",
    "href": "04-02-simulation.html#references",
    "title": "8¬† Bootstrapping: Using Simulation to Estimate the Uncertainty",
    "section": "8.4 References",
    "text": "8.4 References\n\n\n\n\nRaspe, R. E. (1948). Singular travels, campaigns and adventures of Baron Munchausen (J. Carswell, Ed.). Cresset Press.",
    "crumbs": [
      "Comparing Data to a Standard",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Bootstrapping: Using Simulation to Estimate the Uncertainty</span>"
    ]
  },
  {
    "objectID": "04-02-simulation.html#footnotes",
    "href": "04-02-simulation.html#footnotes",
    "title": "8¬† Bootstrapping: Using Simulation to Estimate the Uncertainty",
    "section": "",
    "text": "The nomenclature of bootstrapping comes from the idea that the use of the observed data to generate more data is akin to a method used by Baron Munchausen, a literary character, after falling ‚Äúin a hole nine fathoms under the grass,‚Ä¶observed that I had on a pair of boots with exceptionally sturdy straps. Grasping them firmly, I pulled with all my might. Soon I had hoist myself to the top and stepped out on terra firma without further ado‚Äù (Raspe, 1948, p. 22)‚Ü©Ô∏é",
    "crumbs": [
      "Comparing Data to a Standard",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Bootstrapping: Using Simulation to Estimate the Uncertainty</span>"
    ]
  },
  {
    "objectID": "04-03-one-sample-test.html",
    "href": "04-03-one-sample-test.html",
    "title": "9¬† Hypothesis Testing: One-Sample t-Test",
    "section": "",
    "text": "9.1 Statistical Inference and Hypothesis Testing\nOne common approach to statistical inference‚Äîthe drawing of conclusions about populations based on sample observations‚Äîis to use the sample observations to test a priori hypothesis1 about the population. Hypotheses are mathematical statements about population parameters which are often formed based on prior knowledge and substantive literature in the area of content.\nIn the social sciences, we typically write out two hypotheses about the population parameters: the null hypothesis (\\(H_0\\)), often referred to as a statement of no effect, and the alternative hypothesis (\\(H_A\\)), often termed the research (or alternative) hypothesis. For example, here are a set of potential hypotheses about teen sleep:\n\\[\n\\begin{split}\n&H_0: \\textrm{The mean amount of sleep for all teens is equal to 9 hours.} \\\\[1ex]\n&H_A: \\textrm{The mean amount of sleep for all teens is less than 9 hours.}\n\\end{split}\n\\] There are a few things to notice about these hypotheses:\nStatisticians often use the language of mathematics to express these hypotheses. The same hypotheses expressed via the language of mathematics are:\n\\[\n\\begin{split}\n&H_0: \\mu_{\\textrm{Sleep}}=9 \\\\[1ex]\n&H_A: \\mu_{\\textrm{Sleep}} &lt; 9\n\\end{split}\n\\]\nThe Greek letter mu (\\(\\mu\\)) denotes a population mean. In general Greek letters represent population parameters while Roman letters represent sample statistics. Here are a list of common statistical summaries and the mathematical notation used to denote them.\nTable¬†9.1: Some common statistical summaries and the mathematical notation used to denote them.\n\n\n\n\n\n  \n  \n\n\n\nSummary\nSample\nPopulation\n\n\n\n\nMean\n$$\\bar{x},~\\textit{M}$$\n$$\\mu$$\n\n\nStandard Deviation\n$$\\textit{s},~\\textit{SD}$$\n$$\\sigma$$\n\n\nVariance\n$$s^2,~\\textit{Var}$$\n$$\\sigma^2$$\nThe alternative hypothesis is always an inequality. In this example, the alternative hypothesis is the mean is LESS THAN 9 hours. Another potential alternative hypothesis would be that the mean is GREATER THAN 9 hours, while a third possibility is that the mean is NOT EQUAL TO 9 hours. Mathematically these could be expressed as \\(\\mu_{\\textrm{Sleep}}&lt;9\\), \\(\\mu_{\\textrm{Sleep}}&gt;9\\), and \\(\\mu_{\\textrm{Sleep}}\\neq9\\). The alternative hypothesis you choose is based on your conjecture about the population. For example, if we believed that teens sleep, on average, less than 9 hours a night, then the alternative hypothesis we choose would be \\(\\mu_{\\textrm{Sleep}}&lt;9\\). If we thought they sleep more than 9 hours, on average, we would adopt the alternative hypothesis of \\(\\mu_{\\textrm{Sleep}}&gt;9\\). If we are unsure about whether they sleep less or more than 9 hours, then our alternative hypothesis would be \\(\\mu_{\\textrm{Sleep}}\\neq9\\).",
    "crumbs": [
      "Comparing Data to a Standard",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Hypothesis Testing: One-Sample t-Test</span>"
    ]
  },
  {
    "objectID": "04-03-one-sample-test.html#statistical-inference-and-hypothesis-testing",
    "href": "04-03-one-sample-test.html#statistical-inference-and-hypothesis-testing",
    "title": "9¬† Hypothesis Testing: One-Sample t-Test",
    "section": "",
    "text": "The statements are about the mean amount of sleep (i.e., summary measure).\nThe statements are about the population (all teens), not the sample.\nThe null hypothesis (\\(H_0\\)) is a statement of equality (is equal to).\nThe alternative hypothesis often indicates the researcher‚Äôs belief about the population summary (e.g., we think the average amount of sleep for all teens is less than 9 hours).\n\n\n\n\n\n\n\nIn the parlance of statisticians, hypothesis tests that use an alternative hypothesis of not equal (\\(\\neq\\)) are referred to as two-sided or two-tailed tests. If the alternative hypothesis is less than (&lt;) or greater than (&gt;), it is referred to as a one-sided or one-tailed test.\n\n\n\n9.1.1 The Null Model\nA hypothesis test is predicated on the assumption that the null hypothesis is true. Thus, we want to produce a sampling distribution of potential sample summaries that we could see if \\(H_0: \\mu_{\\textrm{Sleep}}=9\\) is actually true. In other words, we are carrying out a thought experiment assuming that the average amount of sleep for all teens is actually 9 hours.\n\n\n\n\n\n\n\n\nFigure¬†9.1: Visual depiction of the thought experiment underlying a hypothesis test assuming that the mean amount of sleep for all tennagers is 9 hours.\n\n\n\n\n\nIf we were able to carry out this thought experiment, here is what the sampling distribution of the sample means would look like:\n\n\n\n\n\n\n\n\nFigure¬†9.2: Density plot of the sampling distribution of the sample means based on the thought experiment underlying a hypothesis test assuming that the mean amount of sleep for all tennagers is 9 hours.\n\n\n\n\n\nThis distribution is also known as the null distribution since it is the sampling distribution that arises from the thought experiment assuming the null hypothesis is true. Describing the features (shape, center, and variation) of this null distribution we find:\n\nThe distribution is unimodal and symmetric.\nThe mean (center) of the distribution is at 9 hours.\nThe SD of this distribution (the SE) is approximately 0.20.\n\nInterpreting these features, we find that in the thought experiment where we assume the mean amount of sleep is 9 hours, a typical mean is 9 hours! But, sample means will vary from 9 hours. That is, even if the true mean amount of sleep is 9 hours, we could expect a sample mean that differs from 9 hours. How much they will vary depends on the SE, which is approximately 0.20.2 So, it would not be unusual to see a sample mean as low as 8.6 (\\(9 - 2(0.20) = 8.6\\)) or as high as 9.4 (\\(9 + 2(0.20) = 9.4\\)).\n\nThe null distribution will always be centered at the parameter value specified in the null hypothesis! The SE of the null distribution gives us an indication of how much a sample statistic is likely to vary from the parameter specified in the null hypothesis. We expect most values will be within 2 standard errors of the center.\n\n\n\n\n9.1.2 Evaluating the Observed Sample Mean\nThe null distribution gives us an indication of the range of sample mean values that are expected assuming the null hypothesis is true. Using the null distribution as a reference, we can evaluate the mean we obtained from the observed data, which was 7.5 hours (see Chapter 7).\n\n\n\n\n\n\n\n\nFigure¬†9.3: Density plot of the sampling distribution of the sample means based on the thought experiment underlying a hypothesis test assuming that the mean amount of sleep for all tennagers is 9 hours. The blue shaded area represents the sample mean values we expect under the hypothesis that the average amount of sleep for all tennagers is 9 hours. The pink dot represnts the sample mean of 7.5 that we observed in the teen sleep data.\n\n\n\n\n\nWe can see from Figure¬†9.3 that the observed mean of 7.5 is not a value we expect if the population mean amount of sleep teenagers get is truly 9 hours. It is, in fact, far less than we expect. In other words,\n\nThe sample mean of 7.5 hours of sleep we observed in the data is not consistent with the hypothesis that the average amount of sleep teenagers get a night is 9 hours.\n\nBecause the data were not consistent with our initial hypothesis, we would reject the null hypothesis, that is, the empirical evidence (data) does not support the hypothesis.\nWhile the method we used allows us to say whether the empirical data are consistent with the null hypothesis that teenagers get, on average, 9 hours of sleep, it does not tell us the level of consistency. Is it slightly inconsistent? Or really inconsistent? Because of this, applied researchers will often quantify this via two measures: (1) the t-value, and the p-value.",
    "crumbs": [
      "Comparing Data to a Standard",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Hypothesis Testing: One-Sample t-Test</span>"
    ]
  },
  {
    "objectID": "04-03-one-sample-test.html#quantifying-the-level-of-consistency-with-the-null-hypothesis-the-t-value",
    "href": "04-03-one-sample-test.html#quantifying-the-level-of-consistency-with-the-null-hypothesis-the-t-value",
    "title": "9¬† Hypothesis Testing: One-Sample t-Test",
    "section": "9.2 Quantifying the Level of Consistency with the Null Hypothesis: The t-Value",
    "text": "9.2 Quantifying the Level of Consistency with the Null Hypothesis: The t-Value\nThe t-value quantifies how far away the observed mean is from the hypothesized mean value in standard error units. To compute the t-value we use the following:\n\\[\nt = \\frac{\\mathrm{Obs.~Mean} - \\mathrm{Hyp.~Mean}}{SE}\n\\]\nwhere, Obs. Mean is the observed sample mean from the data, Hyp. Mean is the hypothesized value in the null hypothesis, and SE is the standard error in the null distribution (which we compute via bootstrapping). Computing this for our example,\n\\[\n\\begin{split}\nt &= \\frac{7.5 - 9}{0.17} \\\\[2ex]\n&= -8.82\n\\end{split}\n\\] The t-value indicates that our observed sample mean of 7.5 is 8.82 standard errors below the hypothesized population mean value of 9. Changing the distance metric to standard error units helps standardize the distance for other scholars so they can better interpret how discrepant the observed mean is from the hypothesized value.\nFor example, if we hadn‚Äôt divided by the SE, we would have said our observed mean of 7.5 hours of sleep is 1.5 hours less than the hypothesized mean of 9 hours of sleep. Is this a lot less? Or a little less? The answer to that depends on how much we expect sample means to vary from the population mean under random sampling. This is what the SE quantifies. So dividing by the SE accounts for this expected variation and also changes the units from ‚Äúhours of sleep‚Äù to ‚Äústandard errors‚Äù.\nNow that we have a t-value, how do we judge its magnitude? To do this, we can again look back to the null distribution in Figure¬†9.3. Based on the null distribution, we said we expected sample means to fall in between 8.6 and 9.4. What are the t-values associated with 8.6 and 9.4?\n\\[\n\\begin{split}\nt &= \\frac{8.6 - 9}{0.17} \\\\[2ex]\n&= -2.35 \\\\[4em]\nt &= \\frac{9.4 - 9}{0.17} \\\\[2ex]\n&= 2.35\n\\end{split}\n\\]\nExpecting a sample mean between 8.6 and 9.4 is essentially the same as expecting a t-value between \\(-2.35\\) and 2.35.\n\nRule-of-Thumb: An observed mean that has a t-value with an absolute value less than 2 is fairly consistent with the null hypothesis being true. An observed mean that has a t-value with an absolute value greater than 2 is less consistent with the null hypothesis being true, and the further away from 2, the more evidence against the null hypothesis.\n\n\n\n9.2.1 The t-Distribution\nRecall that the null distribution is simply a distribution of sample means we expect if the null hypothesis is true. Because each case in this distribution is a sample mean, we could transform each case into a t-value. If we do that, the resulting distribution is a t-distribution.\n\n\n\n\n\n\n\n\nFigure¬†9.4: Density plot of the t-distribution of the sample means based on the thought experiment underlying a hypothesis test assuming that the mean amount of sleep for all tennagers is 9 hours (t value of 0). The blue shaded area represents the t-values we expect if the null hypothesis is true. The pink dot represents the observed t-value of -8.82.\n\n\n\n\n\nThe t-distribution is is the sampling distribution that arises from converting the null distribution from the thought experiment assuming the null hypothesis is true to t-values. Describing the features (shape, center, and variation) of this t-distribution we find:\n\nThe distribution is unimodal and symmetric.\nThe mean (center) of the t-distribution is 0.\nThe SD of this t-distribution (the SE) is approximately 1.\n\nNote that the descriptions referred to ‚Äúthis t-distribution‚Äù. That is because there are many different t-distributions; in fact there are an infinite number of them. Each t-distribution is based on a parameter called the degrees-of-freedom (df), which is in turn based on the sample size for the observed data. The df for the t-distribution is computed as:\n\\[\n\\mathit{df} = n - 1\n\\]\nwhere n is the sample size.\nThe degrees-of-freedom parameter impacts the shape and SE (variation) in the t-distribution. Figure¬†9.5 shows the t-distribution based on a few different degrees-of-freedom values. From this figure we can see:\n\nEvery t-distribution is unimodal and symmetric, although t-distributions with smaller degrees-of-freedom parameters are shorter and have thicker tails than t-distributions with higher degrees-of-freedom parameters.\nThe mean (center) of every t-distribution is 0.\nThe SD of this t-distribution (the SE) depends on the degrees-of-freedom, and t-distributions with smaller degrees-of-freedom parameters have a higher SE than t-distributions with higher degrees-of-freedom parameters.\n\n\n\n\n\n\n\n\n\nFigure¬†9.5: Density plot of three different t-distributions. The t-distributions shown have 3 degree-of-freedom (SE = 1.73), 5 degree-of-freedom (SE = 1.29), and 99 degree-of-freedom (SE = 1.01), respectively. Note that the degrees-of-freedom value impacts the shape and variation in the distribution.\n\n\n\n\n\nThe SE of a t-distribution depends directly on the degrees-of-freedom. Specifically,\n\\[\n\\mathit{SE} = \\begin{cases}\n\\mathrm{Undefined}, & \\text{if } &\\mathit{df}\\leq1\\\\[2ex]\n\\infty, & \\text{if } &1&lt;\\mathit{df}\\leq2\\\\[2ex]\n\\sqrt{\\frac{\\mathit{df}}{\\mathit{df}-2}}, & \\text{if } &\\mathit{df}&gt;2\n\\end{cases}\n\\]\nIn empirical data analyses, the df will almost always be higher than 2 since the sample size for most analyses will be \\(n\\geq3\\). Memorizing these formulas is not important (you an always look them up on Wikipedia), the important thing to see is that when df gets bigger the SE becomes approximately 1.\n\nWhen you report t-values or give information about a t-distribution, you should always report the degrees-of-freedom.\n\n\n\n\n9.2.2 The t-Distribution for the Teen Sleep Example\nNow that we understand a bit more about the properties of the t-distribution, we can sketch the t-distribution for the teen sleep example. Recall that the sample size for the observed data was \\(n=75\\). The df for the resulting t-distribution is:\n\\[\n\\begin{split}\n\\mathit{df} &= 75 - 1 \\\\[1ex]\n&= 74\n\\end{split}\n\\]\nThis helps us think about the properties for this t-distribution:\n\nThe distribution is unimodal and symmetric.\nThe mean (center) of the t-distribution is 0.\nThe SD of this t-distribution (the SE) is \\(\\sqrt{\\frac{74}{74-2}}=1.014\\).\n\nUsing these properties, we can sketch this t-distribution. We can also add the observed t-value of \\(-8.82\\) into the distribution. (Note: We will have to go out about 9 SEs from the center value of 0 to place the observed t-value onto the distribution!)\n\n\n\n\n\n\n\n\nFigure¬†9.6: Sketch of the t-distribution with 74 degrees-of-freedom. The observed value (purple dot) of -8.82 is also shown. The shaded blue area indicates the magnitude of t-values that would be expected if the null hypothesis is true.\n\n\n\n\n\nBeing able to create this sketch helps us understand how the observed data fit with or don‚Äôt fit with the null hypothesis. It also helps us understand the mechanics of what the computations for the t-test actually mean. In practice, you would not create this distribution for a manuscript, but rather report the pertinent information from these computations, namely the t-value, and the df for the t-distribution. In our example, we might report this as:\n\n\\(t(74)=-8.82\\)\n\nThis small amount of information allows another researcher to re-create the sketch of the t-distribution that we made in Figure¬†9.6. We can also see that the observed data is not very consistent with the null hypothesis. If the true mean amount of sleep for all teenagers is 9 hours, we would expect that the magnitude of an observed t-value would be between \\(-2.028\\) and \\(+2.2028\\). (The t-value of zero corresponds to an average of 9 hrs of sleep, but we expect deviation from this in a sample mean because of sampling variation.) In the data, we found a t-value of \\(-8.82\\)! This indicates that the sample mean for the observed data was 8.82 standard errors below the expected t-value of 0. Moreover, a t-value of \\(-8.82\\) is quite a bit lower than we would expect if teenagers actually average 9 hours of sleep a night.",
    "crumbs": [
      "Comparing Data to a Standard",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Hypothesis Testing: One-Sample t-Test</span>"
    ]
  },
  {
    "objectID": "04-03-one-sample-test.html#quantifying-the-level-of-consistency-with-the-null-hypothesis-the-p-value",
    "href": "04-03-one-sample-test.html#quantifying-the-level-of-consistency-with-the-null-hypothesis-the-p-value",
    "title": "9¬† Hypothesis Testing: One-Sample t-Test",
    "section": "9.3 Quantifying the Level of Consistency with the Null Hypothesis: The p-Value",
    "text": "9.3 Quantifying the Level of Consistency with the Null Hypothesis: The p-Value\nComputing the observed t-value gives us a method for determining how far (in SE units) the sample mean for the observed data are from a mean value specified in the null hypothesis. By placing the observed t-value in the appropriate t-distribution, we can also say whether the observed data are consistent with the claim made in the null hypothesis. Applied researchers also augment this information with one more piece of evidence called the p-value.\nThe p-value provides a quantification of the probability of observing data at least as extreme as what we observed if the null hypothesis is true. In other words, with the t-value and t-distribution we can say that it is unlikely that we would observe a sample mean as small as 7.5 if teenagers really do average 9 hours of sleep a night. The p-value will take this one step further and quantify exactly how unlikely that would be.\nThe computation of the p-value is based around the alternative (research) hypothesis. Recall that the alternative hypothesis was a statement of inequality about the population mean value. In our sleep example the alternative hypothesis was:\n\\[\nH_A: \\mu &lt; 9\n\\]\nBut it could also have been one of these other inequalities depending on the researcher‚Äôs hypothesis about how the population mean compared to 9 hours.\n\\[\n\\begin{split}\nH_A: \\mu &gt; 9 \\\\[1ex]\nH_A: \\mu \\neq 9\n\\end{split}\n\\] In computing p-value, we have to identify values that are at least as extreme as the observed data. Extremeness varies depending on the direction of the inequality. For example in the example alternative hypothesis that we had: \\(H_A: \\mu &lt; 9\\), a value more extreme than our observed sample mean of 7.5 would be less than 7.5. So to compute the p-value for this alternative hypothesis, w need to find:\n\\[\nP(\\bar{y} \\leq 7.5) ~~~ \\text{if the null hypothesis is true}\n\\]\nNote that \\(P(\\cdot)\\) is the notation to indicate the probability of whatever is in the parentheses. In our case we are finding the probability of a sample mean (\\(\\bar{y}\\)) that is at least as extreme as the one we saw in our observed data (7.5) where extreme is defined in the alternative hypothesis (\\(\\leq\\)).\nTo find this probability we have to go back to the null distribution‚Äîwhich is based on the null hypothesis being true. (The probability defined above assumed the null hypothesis to be true.) We then need to identify all values that are less than or equal to the observed value and find their probability within that distribution. Typically, we do this in the t-distribution, so rather than finding the probability of values less than or equal to 7.5, we need to find:\n\\[\nP(t \\leq -8.82)\n\\]\nAs an example, consider the dotplot in Figure¬†9.7.\n\n\n\n\n\n\n\n\nFigure¬†9.7: Dot plot of an example t-distribution. The vertical blue dashed line indicates the observed value of -8.82. The yellow dots (to the left of -8.82) are the t-values that are at least as extreme as -8.82 based the alternative hypothesis (mu &lt; -8.82).\n\n\n\n\n\nThis plot shows 300 t-values that are part of a t-distribution created by assuming the null hypothesis was true. Of these 300 t-values, only 2 of them are less than or equal to the observed value of \\(-8.82\\). Thus we can compute the probability of observing data at least as extreme as what we observed as:\n\\[\n\\begin{split}\nP(t \\leq -8.82) &= \\frac{2}{300} \\\\[1ex]\n&= .007\n\\end{split}\n\\]\nThat is, if the null hypothesis is true, the probability we would observe a sample mean at least as extreme as we did is .007. (We report p-values as: p = .007) This is a very unlikely event if the null hypothesis is true. So because we did actually observe a mean this extreme, it causes us to reject the null hypothesis in favor of the alternative hypothesis. The empirical evidence does not seem consistent with teenagers getting 9 hours of sleep a night. It is more consistent with teenagers getting less than 9 hours of sleep a night, on average.\n\nRule-of-Thumb: A p-value that is less than .05 usually is evidence against the null hypothesis in favor of the alternative hypothesis. In contrast, a p-value that is .05 or higher means that the evidence is consistent with the null hypothesis.\nBeing consistent with the null hypothesis does not mean that the null hypothesis is necessarily true, but rather that it could be true. Because of this, if \\(p \\geq .05\\) we never ‚Äúaccept the null hypothesis‚Äù, but instead we ‚Äúfail to reject the null hypothesis‚Äù.\n\n\n\n9.3.1 Computing the p-Value for Other Alternative Hypotheses\nIn the example, we computed the p-value based on the alternative hypothesis, \\(H_A:\\mu&lt;9\\). To do this we counted the cases in the t-distribution that were more extreme than our observed t-value of \\(-8.82\\), which in this alternative hypothesis corresponded to the t-values that were less than or equal to \\(-8.82\\) and computed a probability (proportion) by dividing by the total number of values in the distribution. To compute this for other null hypotheses, we do the same thing, but we have to re-define extreme.\nFor example if we had the alternative hypothesis \\(H_A:\\mu&gt;9\\), values at least as extreme as \\(-8.82\\) correspond to all the values that are greater than or equal to \\(-8.82\\). These are shown a the yellow cases in the distribution below.\n\n\n\n\n\n\n\n\nFigure¬†9.8: Dot plot of an example t-distribution. The vertical blue dashed line indicates the observed value of -8.82. The yellow dots (to the right of -8.82) are the t-values that are at least as extreme as -8.82 based the alternative hypothesis (mu &gt; -8.82).\n\n\n\n\n\nBased on this alternative hypothesis, we would have counted 298 cases that have a t-value greater than or equal to \\(-8.82\\). Based on this alternative hypothesis, the p-value would be computed as:\n\\[\n\\begin{split}\np &= \\frac{298}{300} \\\\[1ex]\n&= .993\n\\end{split}\n\\]\nThis level of evidence does not support the alternative hypothesis since the p-value is not less than .05. Because of this, we do not think the average amount of sleep teenagers get a night is greater than 9 hours. The empirical evidence doesn‚Äôt support this. However, it isn‚Äôt clear from this test that the empirical evidence supports that students get 9 hours of sleep (i.e., \\(\\mu=9\\)); it may be they are getting less than 9 hours of sleep (\\(\\mu&lt;9\\)). That is why we cannot accept the null hypothesis that \\(\\mu=9\\). The test has only ruled out values for \\(\\mu\\) that are greater than 9 hours; the mean actually being 9 hours is only one possibility of many that remain after we eliminate those values greater than 9!\nAnother potential alternative hypothesis that a researcher might have is \\(H_A:\\mu\\neq9\\). In this research hypothesis the researcher is not positing a direction‚Äîthey are just saying we think it differs from 9 hours; it might be higher, it might be lower. What this means for identifying cases in the t-distribution that are at least as extreme as \\(-8.82\\) is that we have to identify all values less than or equal to \\(-8.82\\) AND all values greater than or equal to \\(+8.82\\). These are shown a the yellow cases in the distribution below.\n\n\n\n\n\n\n\n\nFigure¬†9.9: Dot plot of an example t-distribution. The vertical blue dashed lines indicates the observed value of -8.82 and its counterpart at +8.82. The yellow dots (to the left of -8.82 and to the right of +8.82) are the t-values that are at least as extreme as -8.82 based the alternative hypothesis (mu ‚â† -8.82).\n\n\n\n\n\nBased on this alternative hypothesis, we would have counted 4 cases that have a t-value at least as extreme as \\(-8.82\\). Based on this alternative hypothesis, the p-value would be computed as:\n\\[\n\\begin{split}\np &= \\frac{4}{300} \\\\[1ex]\n&= .013\n\\end{split}\n\\]\nBased on this p-value, which is less than .05, we would reject the null hypothesis in favor of the alternative hypothesis. This implies that the empirical evidence does not support the claim that teenagers get, on average, 9 hours of sleep, but rather that they get a different amount of sleep on average. Based on the results of this test, we cannot tell whether they get, on average, more or less sleep than 9 hours‚Äîonly that it is likely a different amount.\n\n\n\n9.3.2 p-Values in Density Plots\nIn the previous example we have looked at to compute the p-value, the t-distribution was presented as a dotplot. This makes it easy to count the observations at least as extreme as the observed value. In most cases, the t-distribution is presented as a density plot. Because individual cases are not shown in a density plot, we need to have another method of computing the p-value that is not based on counting.\nThe method we use with density plots is to compute the area under the density curve that corresponds to at least as extreme as the observed value. Figure¬†9.10 shows both the dotplot and superimposed density curve for an example t-distribution. If the alternative hypothesis was \\(H_A:\\mu&lt;9\\), rather than counting the cases to that are less than the observed value of \\(-8.82\\), we would find the area under the curve that is less than \\(-8.82\\). This area is shaded in the figure.\n\n\n\n\n\n\n\n\nFigure¬†9.10: Dot plot of an example t-distribution with superimposed density. The vertical blue dashed line indicates the observed value of -8.82. The yellow dots (to the left of -8.82) are the t-values that are at least as extreme as -8.82 based the alternative hypothesis (mu &lt; -8.82). The area under the density curve that is less than -8.82 is also shaded.\n\n\n\n\n\nFinding the area under the density curve requires calculus, or software. We will show you how to use R to find this area in Chapter 10. We can, however estimate this area for a quick approximation. Since the area under the entire density curve is 1, the shaded area (p-value) is found by determining the proportion that the shaded area is of the whole curve. (Remember that a proportion is a value between 0 and 1; it is not a percent.) In this example, the shaded area is roughly .01 of the whole curve, so we would say the p-value was .01.\n\nIt is very difficult to get an accurate p-value from estimating it from the density curve, especially when the p-value is small. In practice, we always use software to obtain the p-value. However, understanding that the software is calculating the area under the density curve is useful for ‚Äúgut-checking‚Äù the size of the p-value that the software gives us. For example, based on the shaded area in Figure¬†9.10, we would not expect a p-value of 0.5 since the shaded are is not half of the whole curve.",
    "crumbs": [
      "Comparing Data to a Standard",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Hypothesis Testing: One-Sample t-Test</span>"
    ]
  },
  {
    "objectID": "04-03-one-sample-test.html#putting-it-all-together",
    "href": "04-03-one-sample-test.html#putting-it-all-together",
    "title": "9¬† Hypothesis Testing: One-Sample t-Test",
    "section": "9.4 Putting It All Together",
    "text": "9.4 Putting It All Together\nIt is important to not lose the forest in the trees when you are conducting a hypothesis test. We set out to answer a substantive question about whether or not teens are getting the recommended amount of sleep. All of the steps we carried out in the hypothesis test were a means to an end of actually answering this question based on the data we collected. So when we report results from the t-test, we need to not only report the pertinent statistical evidence (t-value, df, p-value), but we also need to answer the substantive/research question that drove this test in the first place. Below is an example write-up that an applied researcher might use:\n\nTo determine whether or not teens are getting the recommended amount of sleep, a one-sample t-test was used to compare the sample mean amount of sleep for 75 teens to a hypothesized population mean of 9 hours (the amount of sleep recommended by medical experts). The sample mean of 7.40 hours of sleep (SD = 1.52) was found to be inconsistent with the hypothesis that teens are getting 9 (or more) hours of sleep a night, on average; \\(t(74) = ‚àí8.82\\), \\(p = .007\\). This suggest that teens might not be getting the recommended amount of sleep every night.",
    "crumbs": [
      "Comparing Data to a Standard",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Hypothesis Testing: One-Sample t-Test</span>"
    ]
  },
  {
    "objectID": "04-03-one-sample-test.html#looking-forward",
    "href": "04-03-one-sample-test.html#looking-forward",
    "title": "9¬† Hypothesis Testing: One-Sample t-Test",
    "section": "9.5 Looking Forward",
    "text": "9.5 Looking Forward\nIn the next chapter, we will introduce how to use R to carry out the one-sample t-test. Then in chapter Chapter 11, you will learn about the assumptions that we need to make in order for the results of a one-sample t-test to be statistically valid.\nAs you work through these chapters, you will become more comfortable with the vocabulary and ideas that underlie hypothesis tests. This same set of vocabulary and ideas will come up again when we use hypothesis tests when we compare a sample proportion to a standard and to compare two samples. Because of this it may be useful to put together a summary of the ideas and vocabulary from this chapter that you can refer to (e.g., on a notecard). Here are some of the ideas and vocabulary that are important in hypothesis testing to get you started:\n\nStatistical inference\nNull hypothesis\nNull model\nAlternative hypothesis\nStandard error\nt-value\nt-distribution\np-value",
    "crumbs": [
      "Comparing Data to a Standard",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Hypothesis Testing: One-Sample t-Test</span>"
    ]
  },
  {
    "objectID": "04-03-one-sample-test.html#footnotes",
    "href": "04-03-one-sample-test.html#footnotes",
    "title": "9¬† Hypothesis Testing: One-Sample t-Test",
    "section": "",
    "text": "a priori means the hypothesis is made prior to collecting any data‚Ü©Ô∏é\nTechnically, we computed the SE as 0.17 in Chapter 8.‚Ü©Ô∏é",
    "crumbs": [
      "Comparing Data to a Standard",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Hypothesis Testing: One-Sample t-Test</span>"
    ]
  },
  {
    "objectID": "04-04-one-sample-test-computation.html",
    "href": "04-04-one-sample-test-computation.html",
    "title": "10¬† One-Sample t-Test Using R",
    "section": "",
    "text": "10.1 Teen Sleep: A Quick Re-Cap\nIn this case study, researchers collected data on the bedtime, wake-up time, and hours slept for a sample of \\(n=75\\) American teens in Grades 9‚Äì12. These data were used to evaluate the following statistical hypotheses For example, here are a set of potential hypotheses about teen sleep:\n\\[\n\\begin{split}\nH_0: \\mu = 9 \\\\[1ex]\nH_A: \\mu &lt; 9\n\\end{split}\n\\] The analysis started by importing the data and visualizing and numerically describing the amount of sleep for the teens in our sample.\n# Create density plot\ngf_density(\n  ~ hrs_sleep, data = teen_sleep,\n  color = \"black\", \n  fill = \"skyblue\",\n  xlab = \"Hours of Sleep\",\n  ylab = \"Density\"\n  )\n\n# Compute numerical summaries\ndf_stats(~hrs_sleep, data = teen_sleep)\n\n\n\n\n\n\n\n\nFigure¬†10.1: Density plot of the hours of sleep for 75 teenagers.\n\n\n\n\n\n\n\n\n\n\nFigure¬†10.2: Density plot of the hours of sleep for 75 teenagers.\nThese analyses suggest that, on average, the 75 teens in the sample are not getting the recommended 9 hours of sleep a night. They seem to be getting much less sleep on average, with a typical teen in the sample getting around 7.5 hours of sleep a night (SD = 1.5). To evaluate whether this lower amount of sleep we are seeing in the sample data is only a function of sampling uncertainty, we will carry out a one-sample t-test. To do this, we need to convert our sample mean to a t-value and then evaluate it in a t-distribution with \\(n-1\\) df.\n\\[\nt = \\frac{\\mathrm{Obs.~Mean} - \\mathrm{Hyp.~Mean}}{SE}\n\\]\nWe have the observed mean (\\(\\bar{x}=7.39\\)), and the hypothesized mean (\\(\\mu=9\\)) from the data and null hypothesis, respectively. To obtain the SE we bootstrapped from the data.\n# Draw a bootstrap sample of 75 observations and compute the mean\n# Do this 1000 times \n# Assign these into an object called bootstrap_means\nset.seed(42)\nbootstrap_means &lt;- do(1000) * {mean(sample(teen_sleep$hrs_sleep, size = 75, replace = TRUE))}\n\n# Compute numerical summaries to get SE\ndf_stats(~result, data = bootstrap_means)\nBased on the bootstrapping, the SE is 0.170. Putting this together, we compute the t-value as:\n\\[\n\\begin{split}\nt &= \\frac{7.39 - 9}{.170} \\\\[2ex]\n&= -9.47\n\\end{split}\n\\] We can then sketch the t-distribution with 74 df, include the t-value we just computed, and shade the area under the density plot that corresponds to the alternative hypothesis.\nFigure¬†10.3: Density plot of the t-distribution of the sample means based on the thought experiment underlying a hypothesis test assuming that the mean amount of sleep for all tennagers is 9 hours (t value of 0). The blue shaded area represents the t-values we expect if the null hypothesis is true. The pink dot represents the observed t-value of -9.47.\nThe p-value (proportion of the pink shaded area to the whole area under the curve) is quite small. Because it is so small, it is difficult to even estimate its size‚Äî\\(p&lt;.001\\). This small p-value leads us to reject the null hypothesis, indicating that the data suggest that the average amount of sleep teens are getting is likely less than 9 hours and that this result is not only because of sampling uncertainty. That is, the empirical evidence is pointing us to the conclusion that teens are not getting the recommended amount of sleep.",
    "crumbs": [
      "Comparing Data to a Standard",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>One-Sample t-Test Using R</span>"
    ]
  },
  {
    "objectID": "04-04-one-sample-test-computation.html#using-the-t_test-function",
    "href": "04-04-one-sample-test-computation.html#using-the-t_test-function",
    "title": "10¬† One-Sample t-Test Using R",
    "section": "10.2 Using the t_test() Function",
    "text": "10.2 Using the t_test() Function\nRather than bootstrapping the SE, we will use the t_test() function to compute the SE directly. This function is part of the {mosaic} library, and takes the following arguments:\n\nA formula using the tilde (~), similar to the gf_ and df_stats functions, that specifies the attribute to carry out the one-sample t-test on.\ndata= specifying the name of the data object,\nmu= indicating the value of the mean in the null hypothesis,\nalternative= indicating one of three potential alternative hypotheses: \"less\", \"greater\", or \"two.sided\" (not equal). Note that these need to be enclosed in quotation marks.\n\nTo carry out the one-sample t-test in the earlier case study, we will use the following syntax. We assign the results of this t-test to an object (in this case, I called it my_t).\n\n# One-sample t-test\nmy_t &lt;- t_test(~hrs_sleep, data = teen_sleep, mu = 9, alternative = \"less\")\n\nTo see the results of the test, you can just call my_t, or whatever you named the object storing the t-test results. The output, however, is a bit unorganized. Instead, we are going to use two functions from the {educate} package to view the results of the t-test: t_results() and plot_t_dist(). To use these functions, we will need to load the {educate} library. Then, we can use each of these functions by supplying it with the name of the object storing our t-test results. We begin by using the t_results() function.\n\n# Load educate library\nlibrary(educate)\n\n# View t-test results\nt_results(my_t)\n\n\n--------------------------------------------------\nOne Sample t-test\n--------------------------------------------------\n\nH[0]: mu = 9\nH[A]: mu &lt; 9\n\nt(74) = -9.150303\np = 4.328872e-14\n\n--------------------------------------------------\n\n\nThis function outputs the null and alternative hypotheses being tested in the one-sample t-test. It also provide the observed t-value (\\(-9.15\\)) and the df (74) for the t-distribution. Finally, it outputs the p-value for the test. When p-values are really small, R will output the p-value in scientific notation. The e-14 part of the p-value means \\(\\times 10^{-14}\\), which means, move the decimal point 14 places to the left. Thus the p-value is:\n\\[\n\\begin{split}\np &= 4.328872 \\times 10^{-14} \\\\[2ex]\n&= .0000000000000433\n\\end{split}\n\\] Note that the t-value we get from this function was different than the t-value we got earlier. This is because the SE computed by the t_test() function is different than the SE we get when we bootstrap. Because of this, it is very important to indicate the method you used to get the t-value; was it based on bootstrapping a SE? Or did you use the t_test() function, which uses a normal-based method for computing the SE?\nWe can also use the plot_t_dist() to visualize the t-distribution with 74 df, where our observed t-value of \\(-9.15\\), falls in this distribution, and the shaded area under the curve associated with the p-value based on the specified alternative hypothesis. The results form the t-test will also be printed above the plot.\n\n# View t-distribution\nplot_t_dist(my_t)\n\n\n\n\n\n\n\nFigure¬†10.4: Density plot of the t-distribution of the sample means based on the thought experiment underlying a hypothesis test assuming that the mean amount of sleep for all tennagers is 9 hours (t value of 0). The red vertical line represents the observed t-value of -9.15. The shaded area under the curve to the left of -9.15 shows the associated p-value of \\(4.33\\times10^{-14} = .0000000000000433\\) that corresponds to the alternative hypothesis that \\(\\mu&lt;9\\).\n\n\n\n\n\nThe t_test() function uses a different method for computing the standard error than bootstrapping. It computes the standard error using a mathematical formula, namely,\n\\[\nSE = \\frac{SD}{\\sqrt{n}}\n\\]\nwhere, SD is the sample standard deviation, and n is the sample size. This method of computing the standard error approximates the true standard error by employing information about the sample. In some cases this approximation is accurate and in other cases it is not. We will study this more in Chapter 11.",
    "crumbs": [
      "Comparing Data to a Standard",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>One-Sample t-Test Using R</span>"
    ]
  },
  {
    "objectID": "04-04-one-sample-test-computation.html#case-study-2-continuous-assessment",
    "href": "04-04-one-sample-test-computation.html#case-study-2-continuous-assessment",
    "title": "10¬† One-Sample t-Test Using R",
    "section": "10.3 Case Study 2: Continuous Assessment",
    "text": "10.3 Case Study 2: Continuous Assessment\nTo study the practice of continuous assessment in Ethiopian primary schools, Abejehu (2016) collected survey responses from several primary school teachers. One tenet of continuous assessment is that to evaluate learning, teachers need to understand students‚Äô prior knowledge. One item on the survey asked teachers about this: ‚ÄúI always assess students‚Äô prior knowledge before starting new lesson.‚Äù Teachers responded on a Likert scale, with options: Strongly Agree (4), Agree (3), Disagree (2), and Strongly Disagree (1). The responses for 30 teachers is given in the prior_knowledge attribute of the continuous-assessment.csv file (see codebook for additional detail).\n\n# Import data\ncontinuous_assessment &lt;- read_csv(\"https://raw.githubusercontent.com/zief0002/epsy-5261/main/data/continuous-assessment.csv\")\n\nRows: 30 Columns: 3\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\ndbl (3): prior_knowledge, only_achievement, prompt_feedback\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# View data\ncontinuous_assessment\n\n\n  \n\n\n\nTo evaluate whether Ethiopian primary teachers are measuring students‚Äô prior knowledge, we will analyze the data in the prior_knowledge attribute. Because there is not substantive work on whether teachers actually do or do not assess students‚Äô prior knowledge, we don‚Äôt have a priori conjectures about whether they will generally agree (3 or 4) or disagree (1 or 2) with the statement in the survey item. Because of that, we will examine the following set of potential hypotheses:\n\\[\n\\begin{split}\nH_0: \\mu = 2.5 \\\\[1ex]\nH_A: \\mu \\neq 2.5\n\\end{split}\n\\] Before we carry out a hypothesis test, we should always explore the data by creating visualizations and numerical summaries of the attribute. Because the data in the attribute is more discrete (can only be 1‚Äì4 with no values in between), we will create a histogram rather than a density plot of the responses. We will also set the bins= argument to 4 since there are only four possible response options.\n\n# Create histogram\ngf_histogram(\n  ~prior_knowledge, data = continuous_assessment,\n  bins = 4,\n  color = \"black\", \n  fill = \"skyblue\",\n  xlab = \"Level of Agreement\",\n  ylab = \"Count\"\n  )\n\n# Compute numerical summaries\ndf_stats(~prior_knowledge, data = continuous_assessment)\n\n\n\n\n\n\n\n\nFigure¬†10.5: Histogram of teachers responses to the survey item: I always assess students‚Äô prior knowledge before starting new lesson.\n\n\n\n\n\n\n\n\n\n\nFigure¬†10.6: Histogram of teachers responses to the survey item: I always assess students‚Äô prior knowledge before starting new lesson.\n\n\n\n\n\nThe histogram suggests that the distribution of responses is somewhat symmetric, with roughly an equal number of teachers assessing (3 and 4) and not assessing (1 and 2) students‚Äô prior knowledge. Most teachers did not indicate strong agreement nor strong disagreement. The average response is 2.43, which indicates that a typical teacher does not assess students‚Äô prior knowledge. However, the relatively large SD (0.90) suggests that there is a great deal of individual variation in the responses. Next, we carry out a one-sample t-test.\n\n# One-sample t-test\nmy_t &lt;- t_test(~prior_knowledge, data = continuous_assessment, mu = 2.5, alternative = \"two.sided\")\n\n# View t-test results\nt_results(my_t)\n\n\n--------------------------------------------------\nOne Sample t-test\n--------------------------------------------------\n\nH[0]: mu = 2.5\nH[A]: mu ‚â† 2.5\n\nt(29) = -0.4067897\np = 0.6871492\n\n--------------------------------------------------\n\n# View t-distribution\nplot_t_dist(my_t)\n\n\n\n\n\n\n\nFigure¬†10.7: Density plot of the t-distribution of the sample means based on the thought experiment underlying a hypothesis test assuming that the mean response for all Ethiopian primary school teachers is 2.5 (t value of 0). The red vertical line represents the observed t-value of -0.41. The shaded area under the curve to the left of -0.41 and to the right of +0.41 shows the associated p-value of .687 that corresponds to the alternative hypothesis that \\(\\mu\\neq2.5\\).\n\n\n\n\n\nBased on the p-value of .687, we would fail to reject the null hypothesis. We do not have evidence that the average response for all Ethiopian primary school teachers differs from 2.5; that is the empirical data is consistent with the hypothesis that the average response for all Ethiopian primary school teachers is 2.5.\n\nSUPER IMPORTANT NOTE\nJust because data are consistent with a hypothesis does not mean that hypothesis is true. As an example, consider a patient who goes to the doctor with a set of symptoms (e.g., aches, fever, congestion). The symptoms are the data the doctor will use to help make a diagnosis (hypothesis) which is consistent with the symptoms. However, there are likely several diagnoses that are consistent with the same set of symptoms. This is also true of hypotheses: The data can be consistent with several different hypotheses.\nIn our example, the data were consistent with the null hypothesis that the average response for all Ethiopian primary school teachers is 2.5. It turns out, that the data is also consistent with the hypothesis that the average response for all Ethiopian primary school teachers is 2.6. And 2.7, and 2.5. In fact, there are several different hypotheses that the data are consistent with. This is why we cannot say that the average response for all Ethiopian primary school teachers IS 2.5, but can only say that it IS CONSISTENT with the hypothesis that the average is 2.5.",
    "crumbs": [
      "Comparing Data to a Standard",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>One-Sample t-Test Using R</span>"
    ]
  },
  {
    "objectID": "04-04-one-sample-test-computation.html#case-study-house-prices",
    "href": "04-04-one-sample-test-computation.html#case-study-house-prices",
    "title": "10¬† One-Sample t-Test Using R",
    "section": "10.4 Case Study: House Prices",
    "text": "10.4 Case Study: House Prices\nThe average price of a single-family house in Minneapolis is $322.46k (as of May 2023). Is the average price of a house near the University of Minnesota different than that? The data in zillow.csv include the listing price (in thousands of dollars) for 15 houses in neighborhoods adjacent to the UMN campus (e.g., Como, Marcy-Holmes, Cedar-Riverside). We will use these data to evaluate the following hypotheses:\n\\[\n\\begin{split}\nH_0: \\mu = 322.46 \\\\[1ex]\nH_A: \\mu \\neq 322.46\n\\end{split}\n\\]\n\n#| label: fig-house-prices\n#| fig-cap: \"Histogram of the asking price for 15 houses in neighborhoods adjacent to the UMN campus. \"\n#| warning: false\n#| \n# Import data\nzillow &lt;- read_csv(\"https://raw.githubusercontent.com/zief0002/epsy-5261/main/data/zillow.csv\")\n\nRows: 15 Columns: 1\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\ndbl (1): price\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# View data\nzillow\n\n\n  \n\n\n# Create histogram\ngf_histogram(\n  ~price, data = zillow,\n  binwidth = 75,\n  color = \"black\", \n  fill = \"skyblue\",\n  xlab = \"House Price\",\n  ylab = \"Count\"\n  )\n\n\n\n\n\n\n\n# Compute numerical summaries\ndf_stats(~price, data = zillow)\n\n\n  \n\n\n\nThe sample distribution is left-skewed indicating that more of the houses are at the higher end of the price range. A typical single-family house near the UMN campus costs a little over 400 thousand dollars (M = $404.97k). There is a lot of variation in house price, with some as low as $250k and others as high as $550k (SD = $102.43k). The sample evidence supports the hypothesis that the average price of a house near the UMN campus is different than the average house in Minneapolis. Next, we will carry out a one-sample t-test to determine whether this difference is more than we expect because of sampling variation.\n\n# One-sample t-test\nmy_t &lt;- t_test(~price, data = zillow, mu = 322.46, alternative = \"two.sided\")\n\n# View t-test results\nt_results(my_t)\n\n\n--------------------------------------------------\nOne Sample t-test\n--------------------------------------------------\n\nH[0]: mu = 322.46\nH[A]: mu ‚â† 322.46\n\nt(14) = 3.1196\np = 0.007533288\n\n--------------------------------------------------\n\n# View t-distribution\nplot_t_dist(my_t)\n\n\n\n\n\n\n\nFigure¬†10.8: Density plot of the t-distribution of the sample means based on the thought experiment underlying a hypothesis test assuming that the mean cost for all houses near campus is $322.46k (t value of 0). The red vertical line represents the observed t-value of 3.12. The shaded area under the curve to the right of 3.12 shows the associated p-value of .004 that corresponds to the alternative hypothesis that \\(\\mu&gt;\\$322.46k\\).\n\n\n\n\n\nThe results of the t-test, \\(t(14)=3.12\\), \\(p = .008\\), indicate we should reject the null hypothesis. This suggests that the empirical evidence is consistent with the average cost of a house near the UMN campus being different than the average cost of a house in Minneapolis more broadly.",
    "crumbs": [
      "Comparing Data to a Standard",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>One-Sample t-Test Using R</span>"
    ]
  },
  {
    "objectID": "04-04-one-sample-test-computation.html#references",
    "href": "04-04-one-sample-test-computation.html#references",
    "title": "10¬† One-Sample t-Test Using R",
    "section": "10.5 References",
    "text": "10.5 References\n\n\n\n\nAbejehu, S. B. (2016). The Practice of Continuous Assessment in Primary Schools: The Case of Chagni, Ethiopia. Journal of Education and Practice.",
    "crumbs": [
      "Comparing Data to a Standard",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>One-Sample t-Test Using R</span>"
    ]
  },
  {
    "objectID": "04-05-one-sample-test-assumptions.html",
    "href": "04-05-one-sample-test-assumptions.html",
    "title": "11¬† Assumptions of the One-Sample t-Test",
    "section": "",
    "text": "11.1 Assumptions\nWhether or not the results we obtain from the t-test are accurate depends on a set of statistical assumptions about the population. Remember that the t-value we use to compute the p-value is computed as:\n\\[\nt = \\frac{\\mathrm{Obs.~Mean} - \\mathrm{Hyp.~Mean}}{SE}\n\\]\nwhere, \\(SE = \\frac{SD}{\\sqrt{n}}\\), SD is the sample standard deviation, and n is the sample size. A critical part of this is that the formula we use to compute the standard error gives us a good estimation of the standard error. This, it turns out, is only true under a particular set of statistical assumptions.\nIf the assumptions are violated and the formula we used for the SE is wrong, that implies the t-value will be wrong because we used the wrong value in the denominator. And, if the t-value is incorrect, that means the p-value is also incorrect since it is based on the t-value. This would mean further that all of our inferences that we draw about the population mean are dubious, since these inferences are based on the p-value. Because of this, it is critical that we have some sense of whether these statistical assumptions we are making are valid.\nFor the one-sample t-test there are two statistical assumptions we make about the population:\nFor example, in the teen sleep case study we need to know that:\nUnfortunately, we can never know for sure whether these assumptions are met since we do not have data from the entire population. Instead, we have to decide whether these assumptions seem tenable based on the sample of data we have.",
    "crumbs": [
      "Comparing Data to a Standard",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Assumptions of the One-Sample t-Test</span>"
    ]
  },
  {
    "objectID": "04-05-one-sample-test-assumptions.html#assumptions",
    "href": "04-05-one-sample-test-assumptions.html#assumptions",
    "title": "11¬† Assumptions of the One-Sample t-Test",
    "section": "",
    "text": "The distribution of values in the population is normally distributed.\nThe values in the population are independent from each other.\n\n\n\nIf you took the hours of sleep measurements from every teen and plotted them, the distribution would be normally distributed.\nThe hours of sleep measurements from every teen is independent from those of every other teen.\n\n\n\n\n11.1.1 Evaluating the Assumption of Normality\nTo evaluate the first assumption that the distribution of values in the population is normally distributed, we plot the sample data and then ask the question: Is this distribution close to normal? The density plot of the sample teen sleep data is shown in Figure¬†11.1.\n\n\n\n\n\n\n\n\nFigure¬†11.1: Density plot of the hours of sleep for 75 teenagers.\n\n\n\n\n\nThe sample distribution looks symmetric, but perhaps not exactly normal. This is okay since the assumption is about whether the POPULATION distribution is normal, not whether the sample distribution is normal. We are only asking whether we believe that the population distribution is normal based on what we see in the sample distribution. To answer this question, we need some idea of what sample distributions of size 75 look like if they truly do come from a population that is normally distributed. Below are the distributions for five samples of size 75 that were actually drawn from a normal distribution.\n\n\n\n\n\n\n\n\nFigure¬†11.2: Density plots for five samples of size 75 that were actually drawn from a population that was normally distributed.\n\n\n\n\n\nThe density plots in Figure¬†11.2 suggest that the distribution for a sample that was actually drawn from a normal distribution does not necessarily look exactly normal. For example the plots for Sample 1 and Sample 3 look slightly right-skewed, while the plots for Samples 2, 4, and 5 look more symmetric. Some of the plots look more peaked (Samples 1 and 2) while others look thicker in the middle (Samples 4 and 5). All of this suggests that the sample doesn‚Äôt have to look perfectly normal for it to have been drawn from a population that is normal.\nLooking back at the sample distribution of teen sleep measurements in Figure¬†11.1, it seems that this distribution is not so different from the distributions of the five other samples. This suggests that it too might have been drawn from a normally distributed population. In light of this, we would say:\n\nThe assumption of normality seems tenable given the distribution of the sample data.\n\n\n\n11.1.1.1 Sample Size and the Assumption of Normality\nHow different would the sample distribution have to look in order for us to conclude that the assumption of normality was not tenable given the distribution of the sample data? This is a difficult question to answer without other statistical tools.1 One tool that we rely on a great deal is something called the Central Limit Theorem (CLT). This theorem basically says that if the sample size of your data is over 30 that it doesn‚Äôt matter if the normality assumption is met, the p-value will not be impacted if the population is not normal.\nIn our example the sample size is 75. This means that it doesn‚Äôt matter if the population is normal or not‚Äîthe CLT basically says that we can assume that the p-value is not impacted by any deviation in the population distribution from normality. This is good news as it means we don‚Äôt have to guess whether or not our sample distribution of teen sleep measurements actually comes from a population that is normally distributed.\n\n\n\n\n11.1.2 Evaluating the Independence Assumption\nThe definition of independence relies on formal mathematics. Loosely speaking a set of observations is independent if knowing the value for one observation in the distribution conveys no information about the value for any other observation in the same distribution. If observations are not independent, we say they are dependent or correlated.\nTo evaluate the independence assumption we need to know something about the the study design, in particular how the data were collected. Using random chance to select the sample data (random sampling) will guarantee independence of the observations. There are also a few times that we can ascertain that the independence assumption would be violated. These instances are also a function of the data collection process. One such instance common to social science research is when the observations (i.e., cases, subjects) are collected within a physical or spatial proximity to one another. For example, this is typically the case when a researcher gathers a convenience sample based on location, such as sampling students from the same school. Another violation of independence occurs when observations are collected over time (longitudinally), especially when the observations are repeated measures from the same subjects.\nIndependence is often difficult to ascertain, and its tenability is made via a logical argument. In the teen sleep case study, for example, the study design did not employ random sampling‚Äîthe participants volunteered to be a part of the study‚Äîso we can not guarantee independence that way. (If a study uses random sampling in the data collection, it will say this directly in the paper.) On the other hand, all the participants did come from the same school district. This may violate the independence assumption since the teens in the study are all from the area (i.e., there was some degree of spatial proximity that influenced the data collection process).\nThe violation of independence is, however, not clear cut. The big question is does knowing that one teen‚Äôs sleep duration convey any information about any other teen‚Äôs sleep duration? If for example all the teens came from the same family this would likely be the case since teens in a family are often similar sleep schedules. It is less likely that this is a case for teens in the same school district. Because of this, we could argue that the independence assumption seems tenable.\n\nBecause the tenability of the independence assumption is made via a logical argument, outside the use of random sampling to collect the data, different scholars might disagree about whether this assumption is tenable. In this class, and in your own work, you need to lay out the argument for why you think the independence assumption is reasonable or not.\n\n\n\n\n11.1.3 Evaluating Assumptions in the Continuous Assessment Case Study\n\nYour Turn\nIn the continuous assessment case study from Chapter 10, we evaluated whether, on average, Ethiopian primary school teachers agree/disagree with the statement that they assess students‚Äô prior knowledge. The histogram of the 30 teachers‚Äô responses is shown below. Based on this plot and the sample size, do you believe the normality assumption is tenable?\n\n\n\n\n\n\n\n\nFigure¬†11.3: Histogram of teachers responses to the survey item: I always assess students‚Äô prior knowledge before starting new lesson.\n\n\n\n\n\n\nShow/Hide Solution\n\n\nYes, the normality assumption seems tenable. While the distribution of the sample responses is not normally distributed, it is not egregiously skewed. Moreover, since the sample size is 30, the CLT would suggest that we can assume that the p-value is not going to be impacted by any deviation in the population distribution from normality.\n\nBased on the data collection process described in the data codebook, do you believe the independence assumption is tenable?\n\nShow/Hide Solution\n\n\nYes, the independence assumption is tenable. The use of random chance to select the sample data (random sampling) guarantees independence.\n\n\n\n\n\n11.1.4 Evaluating Assumptions in the House Prices Case Study\n\nYour Turn\nIn the house prices case study from Chapter 10, we evaluated whether, on average, houses near the University of Minnesota campus are more expensive than $322.46k (the average price of a single-family house in Minneapolis as of May 2023). The histogram of the 15 sample house prices is shown below. Based on this plot and the sample size, do you believe the normality assumption is tenable?\n\n\n\n\n\n\n\n\nFigure¬†11.4: Histogram of the asking price for 15 houses in neighborhoods adjacent to the UMN campus.\n\n\n\n\n\n\nShow/Hide Solution\n\n\nThe normality assumption may not be tenable. The distribution of the sample responses is not normally distributed, and is clearly left-skewed. Moreover, since the sample size is less than 30, we can not rely on the CLT.\n\nBased on the data collection process described in the data codebook, do you believe the independence assumption is tenable?\n\nShow/Hide Solution\n\n\nIt is unclear that the independence assumption is tenable. The data collection did not use random chance to select the sample data. Moreover, it is likely that knowing the sale price for one house would give us information about the sale price for other houses since houses in the same neighborhood are often sold for similar prices.",
    "crumbs": [
      "Comparing Data to a Standard",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Assumptions of the One-Sample t-Test</span>"
    ]
  },
  {
    "objectID": "04-05-one-sample-test-assumptions.html#references",
    "href": "04-05-one-sample-test-assumptions.html#references",
    "title": "11¬† Assumptions of the One-Sample t-Test",
    "section": "11.2 References",
    "text": "11.2 References",
    "crumbs": [
      "Comparing Data to a Standard",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Assumptions of the One-Sample t-Test</span>"
    ]
  },
  {
    "objectID": "04-05-one-sample-test-assumptions.html#footnotes",
    "href": "04-05-one-sample-test-assumptions.html#footnotes",
    "title": "11¬† Assumptions of the One-Sample t-Test",
    "section": "",
    "text": "If you go on and take EPsy 8251, you will learn about some of these tools.‚Ü©Ô∏é",
    "crumbs": [
      "Comparing Data to a Standard",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Assumptions of the One-Sample t-Test</span>"
    ]
  },
  {
    "objectID": "04-06-one-sample-test-proportions.html",
    "href": "04-06-one-sample-test-proportions.html",
    "title": "12¬† One-Sample z-Test: Evaluating Proportions Against a Standard",
    "section": "",
    "text": "12.1 Case Study: Lead Levels in Minnesota Children\nLead exposure has been shown to have deleterious effects on peoples‚Äô health and well-being, especially children. The Center for Disease Control collects blood lead surveillance data from all 50 states in the United States. In 2012, the proportion of children tested under 6 years of age that had lead levels in their blood above the Minnesota Department of Health (MDH) reference level for high blood lead levels (5¬µg/dL) was .029. The data in mn-lead.csv contains the measured lead levels in the blood for all Minnesota children tested under 6 years of age in 2018. There is also an attribute (ebll) that indicates whether the lead level indicates an elevated blood lead level according to MDH (i.e., is blood lead level above 5 ¬µg/dL).\nlibrary(educate)\nlibrary(ggformula)\nlibrary(mosaic)\nlibrary(mosaicCore)\nlibrary(tidyverse)\n\n\n# Import data\nmn_lead &lt;- read_csv(\"https://raw.githubusercontent.com/zief0002/epsy-5261/main/data/mn-lead.csv\")\n\n# View data\nmn_lead\nOne question health officials might ask is: Is the proportion of all Minnesota children under 6 years of age who are above the MDH reference level in 2018 different than the proportion in 2012? That is, they might wish to examine the following hypotheses:\n\\[\n\\begin{split}\nH_0: \\pi_{\\text{Above MDH}} = .029 \\\\[1ex]\nH_A: \\pi_{\\text{Above MDH}} \\neq .029\n\\end{split}\n\\] where \\(\\pi_{\\text{Above MDH}}\\) (the Greek letter equivalent of ‚Äúp‚Äù) is the proportion of all Minnesota children under 6 years of age who are above the MDH reference level. (Note that it is convention to indicate the group you are hypothesizing the proportion for in the subscript of \\(\\pi\\).) To answer this question, we can compute the proportion of Minnesota children under 6 years of age (who were tested) who have blood lead levels above the MDH reference level in 2018. We can then carry out a one-sample z-test to see if any differences between the 2012 and 2018 proportions are just due to sampling error.",
    "crumbs": [
      "Comparing Data to a Standard",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>One-Sample z-Test: Evaluating Proportions Against a Standard</span>"
    ]
  },
  {
    "objectID": "04-06-one-sample-test-proportions.html#case-study-lead-levels-in-minnesota-children",
    "href": "04-06-one-sample-test-proportions.html#case-study-lead-levels-in-minnesota-children",
    "title": "12¬† One-Sample z-Test: Evaluating Proportions Against a Standard",
    "section": "",
    "text": "12.1.1 Summarizing the Sample Data\nWe will start the analysis by summarizing the ebll attribute to determine the proportion of Minnesota children in 2018 under 6 years of age (who were tested) who have above blood lead levels above the MDH reference level.\n\n# Syntax to compute the proportion for each category in the control attribute\ndf_stats(~ebll, data = mn_lead, props)\n\n\n  \n\n\n\nThese summaries indicates that in 2018, the proportion of Minnesota children under 6 years of age (who were tested) who have above blood lead levels above the MDH reference level was .0139. The notation we use to denote a sample proportion is \\(\\hat{p}\\).\n\\[\n\\hat{p} = .0139\n\\]\nThis is a lower proportion than was found in the 2012 data by .0151. The next question we would want to tackle is whether this difference is more than we expect because of sampling error. To determine this, we need to carry out a hypothesis test.\n\n\n\n12.1.2 Testing Proportions Using the One-Sample z-Test\nThe hypothesis test we use to compare a sample against a known standard is the one-sample z-test. The process we use is very similar to that for the one-sample t-test, which was:\n\nUse the sample proportion to compute a t-value;\nLocate the observed z-value in the t-distribution; and\nDetermine the p-value by computing the area under the curve in the t-distribution that is at least as extreme as the observed t-value based on the alternative hypothesis.\n\nFor the one-sample z-test, the process is:\n\nUse the sample proportion to compute a z-value;\nLocate the observed z-value in the z-distribution; and\nDetermine the p-value by computing the area under the curve in the z-distribution that is at least as extreme as the observed z-value based on the alternative hypothesis.\n\nTo compute the z-value, we use:\n\\[\nz = \\frac{\\hat{p} - \\pi}{SE_{\\hat{p}}}\n\\]\nwhere \\(\\hat{p}\\) is the sample proportion, \\(\\pi\\) is the value hypothesized in the null hypothesis, and \\(SE_{\\hat{p}}\\) is the standard error for the proportion. This SE is computed as:\n\\[\nSE_{\\hat{p}} = \\sqrt{\\frac{\\pi(1 - \\pi)}{n}}\n\\] where again, \\(\\pi\\) is the hypothesized proportion in the null hypothesis and \\(n\\) is the sample size. In our example, the z-value is:\n\\[\n\\begin{split}\nz &= \\frac{.01391403 - .029}{\\sqrt{.029(1 - .029)/91706}} \\\\[1ex]\n&= \\frac{-.0151}{.0006} \\\\[1ex]\n&= -27.22\n\\end{split}\n\\]\nSimilar to a t-value, a z-value indicates how many standard errors the sample mean is from the hypothesized value, In our case, the sample proportion we computed in the data of .0139 is 27.22 standard errors below the hypothesized value of .029. We can evaluate this in the z-distribution.\nUnlike the t-distribution which is different depending on the df, there is only one z-distribution. The z-distribution is a normal distribution that has a mean of 0 and a standard deviation of 1. The z-distribution is shown in Figure¬†15.1.\n\n\n\n\n\n\n\n\nFigure¬†12.1: Density plot of the z-distribution.\n\n\n\n\n\nTo find the p-value associated with the alternative hypothesis that \\(\\pi\\neq.029\\), we will include the observed z-values of \\(-27.22\\) and 27.22 into the z-distribution and shade the area under the curve that is more extreme than these values‚Äîless than the observed z-value of -27.22 and more than the extreme value of 27.22. A sketch of this is shown in Figure¬†12.2.\n\n\n\n\n\n\n\n\nFigure¬†12.2: Sketch of the density plot of the z-distribution with the observed z-value of -27.22 (and 27.22) also included. The shaded area to the left of -27.22 and right of 27.22 constitute the p-value associate with the null hypothesis that the population proportion is different than .029.\n\n\n\n\n\nThe p-value here is going to be quite small since the combined area under the curve to the left of \\(-27.22\\) and right of 27.22 is quite small relative to the area under the whole curve.\nIn practice, we will use the prop_test() function from the {mosaic} package to carry out the one-sample z-test and compute the p-value. This function takes:\n\nA formula using the tilde (~), similar to the gf_ and df_stats functions, that specifies the attribute to carry out the one-sample z-test on. We also need to specify the level of the attribute we want to compute the sample proportion for using == and then giving the exact name for that level inside quotation marks.\ndata= specifying the name of the data object,\np= indicating the value of the proportion in the null hypothesis,\nalternative= indicating one of three potential alternative hypotheses: \"less\", \"greater\", or \"two.sided\" (not equal). Note that these need to be enclosed in quotation marks. Again, in practice, we only use the two-sided alternative hypothesis.\ncorrect=FALSE indicating that we want to do the calculation of the z-value without a correction for continuity which will mimic the formula.\n\nTo carry out the one-sample z-test, we will use the following syntax. Note that in the formula we also indicate that we want to compute the sample proportion for the \"Yes\" values. We assign the results of this z-test to an object (in this case, I called it my_z). Then we can use the z_results() and plot_z_dist() functions (both from the {educate} package) to show the results of the z-test and plot the z-distribution along with the observed z-value and shaded area associated with the p-value.\n\n# One-sample z-test\nmy_z &lt;- prop_test(\n  ~ebll == \"Yes\", \n  data = mn_lead, \n  p = .029, \n  alternative = \"two.sided\",\n  correct = FALSE\n  )\n\n# Plot z-distribution, observed z-value and shaded p-value\nplot_z_dist(my_z)\n\n# Show z-test results\nz_results(my_z)\n\n\n--------------------------------------------------\n1-sample proportions test without continuity correction\n--------------------------------------------------\n\nH[0]: pi = 0.029\nH[A]: pi ‚â† 0.029\nz = -27.22473\np = 3.311047e-163\n\n--------------------------------------------------\n\n\n\n\n\n\n\n\nFigure¬†12.3: Density plot of the z-distribution with the observed z-value of -27.22 (and 27.22) also included. The shaded area to the left of -27.22 and right of 27.22 constitute the p-value associate with the null hypothesis that the population proportion is different than .029.\n\n\n\n\n\nBased on the p-value, and using an \\(\\alpha\\)-value of .05, we would reject the null hypothesis. This suggests it is likely that the proportion of all Minnesota children under 6 years of age who are above the MDH reference level in 2018 is different than the proportion in 2012. In this interpretation we call attention to the words ‚Äúit is likely‚Äù to remind you that it is possible we may have made a Type I error in which case the proportion of all Minnesota children under 6 years of age who are above the MDH reference level in 2018 is NOT lower than the proportion in 2012.",
    "crumbs": [
      "Comparing Data to a Standard",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>One-Sample z-Test: Evaluating Proportions Against a Standard</span>"
    ]
  },
  {
    "objectID": "04-06-one-sample-test-proportions.html#assumptions-for-the-one-sample-z-test",
    "href": "04-06-one-sample-test-proportions.html#assumptions-for-the-one-sample-z-test",
    "title": "12¬† One-Sample z-Test: Evaluating Proportions Against a Standard",
    "section": "12.2 Assumptions for the One-Sample z-Test",
    "text": "12.2 Assumptions for the One-Sample z-Test\nWhether or not the p-value we obtain from the z-test is accurate depends on the following set of statistical assumptions:\n\nThe values in the population follow a binomial distribution. This is true so long as there are only two values the attribute can take on (e.g., ‚ÄúYes‚Äù or ‚ÄúNo‚Äù).\nThe values in the population are independent from each other.\nThe quantities \\(n(\\hat{p})\\) and \\(n(1-\\hat{p})\\) are both greater than 10, where n is the sample size and \\(\\hat{p}\\) is the sample proportion value.\n\nTo evaluate the first assumption that the distribution of values in the population follow a binomial distribution, we only need to confirm that the population only has two values. In our example, this is true; the only two values a case can have is ‚ÄúYes‚Äù (blood lead level is above the MDH reference) or ‚ÄúNo‚Äù (blood lead level is not above the MDH reference).\nWe will evaluate the independence assumption the same way we did for the one-sample t-test, by referring to the study design. In our example, the cases in the data do not constitute a random sample of all Minnesota children. Does knowing that one Minnesota child‚Äôs blood lead level is above (or below) the MDH reference level give us any information about whether any other Minnesota child‚Äôs blood lead level is above (or below) the MDH reference level? Without additional data it is difficult to know, so we could argue that the independence assumption seems tenable.1\nLastly we compute the quantities in the third assumption and check that they are both greater than 10.\n\\[\n\\begin{split}\nn(\\hat{p}) &= 91706(.01391403) \\\\[1ex]\n&= 1276 \\\\[3ex]\nn(1-\\hat{p}) &= 91706(1 - .01391403) \\\\[1ex]\n&= 90430\n\\end{split}\n\\]\n\n\n12.2.1 Case Study: Rotten Tomatoes\nThe Rotten Tomatoes website includes both audiences‚Äô and critics‚Äô ratings for different movies. The ratings are then classified into one of two categories: ‚ÄúFresh‚Äù (which indicates a positive review) or ‚ÄúRotten‚Äù (which indicates a negative review). The data in fastx-reviews.csv includes the critic ratings (as of May 23, 2023) for the film Fast X (the 10th installment of the Fast & the Furious franchise). You will use the data in the fresh_rotten attribute to evaluate whether the proportion of all critics‚Äô ‚ÄúFresh‚Äù reviews is different than .50. Mathematically the hypotheses you will evaluate are:\n\\[\n\\begin{split}\nH_0: \\pi_{\\text{Fresh}} = .50 \\\\[1ex]\nH_A: \\pi_{\\text{Fresh}} \\neq .50\n\\end{split}\n\\]\n\nYour Turn\nImport the fastx-reviews.csv data and compute the sample proportion of ‚ÄúFresh‚Äù reviews.\n\nShow/Hide Solution\n\n\n\n# Import data\nfastx &lt;- read_csv(\"https://raw.githubusercontent.com/zief0002/epsy-5261/main/data/fastx-reviews.csv\")\n\n# Compute sample proportion of Fresh reviews\ndf_stats(~fresh_rotten, data = fastx, props)\n\n\n  \n\n\n\nThe sample proportion of ‚ÄúFresh‚Äù reviews is 0.538.\n\nWhich hypothesis the null or alternative, does the sample evidence support? Explain\n\nShow/Hide Solution\n\n\nThe sample evidence supports the alternative hypothesis since \\(\\hat{p}=.538\\) is different than the hypothesized value of 0.5.\n\nCompute the observed z-value using the formula given earlier in the chapter. Also interpret what this value tells you about how far the sample proportion is from the hypothesized value.\n\nShow/Hide Solution\n\n\n\\[\n\\begin{split}\nz &= \\frac{.5378151 - .50}{\\sqrt{.50(1 - .50)/238}} \\\\[1ex]\n&= \\frac{0.0378151}{0.03241019} \\\\[1ex]\n&= 1.17\n\\end{split}\n\\]\nThe observed z-value tells us that the sample proportion is 1.17 standard errors higher than the hypothesized value of 0.50.\n\nCarry out a one-sample z-test to evaluate whether the sample evidence is only due to sampling error. Report the pertinent results from this test, and use those resultsa to draw a conclusion about the hypotheses assuming an \\(\\alpha\\)-value of 0.05.\n\nShow/Hide Solution\n\n\n\n# One-sample z-test\nmy_z &lt;- prop_test(\n  ~fresh_rotten == \"fresh\", \n  data = fastx, \n  p = .50, \n  alternative = \"two.sided\",\n  correct = FALSE\n  )\n\n# Plot z-distribution, observed z-value and shaded p-value\n#plot_z_dist(my_z)\n\n# Show z-test results\nz_results(my_z)\n\n\n--------------------------------------------------\n1-sample proportions test without continuity correction\n--------------------------------------------------\n\nH[0]: pi = 0.5\nH[A]: pi ‚â† 0.5\nz = 1.166767\np = 0.2433046\n\n--------------------------------------------------\n\n\nThe results of the one-sample z-test, \\(z=1.17\\), \\(p=.243\\), suggest we should fail to reject the null hypothesis. It is likely that the population proportion of ‚ÄúFresh‚Äù reviews is not different than 0.50.\n\nSketch a picture of the z-distribution (try to do this initially without using R). Then add a vertical line at the observed z-value. Finally, shade the area under the z-distribution that is associated with the p-value. Check your sketch by using the plot_z_dist() function.\n\nShow/Hide Solution\n\n\nYour sketch should look like the distribution plotted in Figure¬†12.4.\n\n# Check your work\nplot_z_dist(my_z)\n\n\n\n\n\n\n\nFigure¬†12.4: Density plot of the z-distribution with the observed z-value of +1.17 (and -1.17) also included. The shaded area to the right of 1.17 and left of -1.17 constitute the p-value associated with the null hypothesis that the population proportion is different than .50.\n\n\n\n\n\n\nBased on your decision, what type of error might you have made? Explain.\n\nShow/Hide Solution\n\n\nBecause we failed to reject the null hypothesis, we may have made a Type II error. It may be that the population proportion of ‚ÄúFresh‚Äù reviews actually is different than 0.5 and we erroneously concluded it was not.\n\nCheck and evaluate all of the assumptions for the one-sample z-test.\n\nShow/Hide Solution\n\n\nThe assumptions are:\n\nThe values in the population follow a binomial distribution. This is true so long as there are only two values the attribute can take on (e.g., ‚ÄúYes‚Äù or ‚ÄúNo‚Äù).\nThe values in the population are independent from each other.\nThe quantities \\(n(\\hat{p})\\) and \\(n(1-\\hat{p})\\) are both greater than 10, where n is the sample size and \\(\\hat{p}\\) is the sample proportion value.\n\nThe first assumption is met‚Äîthe only two values for a review are ‚ÄúFresh‚Äù or ‚ÄúRotten‚Äù.\nThe second assumption also seems tenable. Although the sample is not chosen randomly, knowing one reviewer‚Äôs rating does not likely give us information about another reviewer‚Äôs rating. (If you said that the independence assumption is not tenable, you would need to provide an explanation as to why one reviewer‚Äôs rating gives us information about another reviewer‚Äôs rating. For example, reviewers read each others‚Äô reviews so one reviewer‚Äôs rating often influences another reviewer‚Äôs rating.)\nLastly we compute the quantities in the third assumption and check that they are both greater than 10. This is the case, so the third assumption is also met.\n\\[\n\\begin{split}\nn(\\hat{p}) &= 238(.5378151) \\\\[1ex]\n&= 128 \\\\[3ex]\nn(1-\\hat{p}) &= 238(1 - .5378151) \\\\[1ex]\n&= 110\n\\end{split}\n\\]",
    "crumbs": [
      "Comparing Data to a Standard",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>One-Sample z-Test: Evaluating Proportions Against a Standard</span>"
    ]
  },
  {
    "objectID": "04-06-one-sample-test-proportions.html#references",
    "href": "04-06-one-sample-test-proportions.html#references",
    "title": "12¬† One-Sample z-Test: Evaluating Proportions Against a Standard",
    "section": "12.3 References",
    "text": "12.3 References",
    "crumbs": [
      "Comparing Data to a Standard",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>One-Sample z-Test: Evaluating Proportions Against a Standard</span>"
    ]
  },
  {
    "objectID": "04-06-one-sample-test-proportions.html#footnotes",
    "href": "04-06-one-sample-test-proportions.html#footnotes",
    "title": "12¬† One-Sample z-Test: Evaluating Proportions Against a Standard",
    "section": "",
    "text": "Just remember other scholars might argue that the population values are not independent.‚Ü©Ô∏é",
    "crumbs": [
      "Comparing Data to a Standard",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>One-Sample z-Test: Evaluating Proportions Against a Standard</span>"
    ]
  },
  {
    "objectID": "05-00-comparing-two-groups.html",
    "href": "05-00-comparing-two-groups.html",
    "title": "Comparing Two Groups",
    "section": "",
    "text": "Another task that is commonly performed in research is to compare the data you have collected from two different groups with the goal of inferring whether a particular population parameter differs between those groups. For example, is the average cost-of-living higher in Minneapolis than it is in St.¬†Paul? Or, is the proportion of students who own an automobile different for students living at home versus those living in the dorms?\nComparing two groups is one of the most important endeavors in social science and educational research. It is the basis of all experimental work (e.g., does the treatment group perform better, on average, than the control group?). It is also used in non-experimental work and is crucial in calling out societal injustices (e.g., are college-educated women earning less, on average, than college-educated men?).\nThere are many parallels between the one-sample methods you have learned about and the methods used to compare two groups. Similar to the one-sample tests you learned about, the methods you learn in this section will quantify the amount of uncertainty in a sample numerical estimate, but now there is uncertainty that needs to be quantified for estimates from two different samples of data. The assumptions underlying the methods we use to compare groups are also similar, but have to be performed on both groups and also include additional assumptions that the one-sample tests did not have.",
    "crumbs": [
      "Comparing Two Groups"
    ]
  },
  {
    "objectID": "05-01-two-sample-t-test.html",
    "href": "05-01-two-sample-t-test.html",
    "title": "13¬† Two-Sample t-Test",
    "section": "",
    "text": "13.1 Case Study: Cannabis Effects on IQ\nIn recent years, many states have legalized the use of marijuana for medical and recreational purposes. Marijuana use has been shown to have adverse impact on peoples‚Äô health and well-being (Volkow et al., 2014), including long-term effects on IQ. This is especially true for adolescents and young adults since their brain is still developing. As you might expect, marijuana usage among younger people is quite prevalent. Based on data collected from the Center for Disease Control in 2019, 37% of U.S. high school students reported using marijuana at least once, and 22% reported use in the past 30 days.\nTo study the long-term effects of cannabis, Meier et al. (2012) examined data from a cohort of people who were followed for a 20 year time span. They identified participants who became persistent marijuana users during the course of the study and collected data on the change in IQ score between the start of the study (prior to the onset of any cannabis use) and then again 20 years later. Importantly, some of these participants were diagnosed with cannabis dependence prior to the 18 years of age (teen-onset) and others were not diagnosed with cannabis dependence until after 18 years of age (adult-onset).\nWe will use the data in cannabis.csv to evaluate whether the effects on IQ were different for users who started using marijuana as a teen.\n# Load libraries\nlibrary(educate)\nlibrary(ggformula)\nlibrary(mosaic)\nlibrary(tidyverse)\n\n\n# Import data\ncannabis &lt;- read_csv(\"https://raw.githubusercontent.com/zief0002/epsy-5261/main/data/cannabis.csv\")\n\n# View data\ncannabis",
    "crumbs": [
      "Comparing Two Groups",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Two-Sample t-Test</span>"
    ]
  },
  {
    "objectID": "05-01-two-sample-t-test.html#writing-the-set-of-hypotheses",
    "href": "05-01-two-sample-t-test.html#writing-the-set-of-hypotheses",
    "title": "13¬† Two-Sample t-Test",
    "section": "13.2 Writing the Set of Hypotheses",
    "text": "13.2 Writing the Set of Hypotheses\nWhen comparing two groups, the null hypothesis is that the population mean for the two groups is the same. In our example, the null hypothesis would be that the average decline in IQ scores for all persistent marijuana users that became dependent as adults is the same as the average decline in IQ scores for all persistent marijuana users that became dependent as teens. Mathematically:\n\\[\nH_0: \\mu_{\\text{Adult-onset}} = \\mu_{\\text{Teen-onset}}\n\\]\nThe alternative hypothesis is either that the populations means are different, or a specification of how they are different. Since we want to determine if persistent marijuana users that became dependent as teens would have a different change in IQ than those who became dependent as adults, the alternative hypothesis would be:\n\\[\nH_A: \\mu_{\\text{Adult-onset}} \\neq \\mu_{\\text{Teen-onset}}\n\\]\n\nThe order of the two groups in the hypotheses does not matter. For example, we could also have written the hypotheses so that the mean for teen-onset was written before the mean for adult-onset:\n\\[\n\\begin{split}\n&H_0: \\mu_{\\text{Teen-onset}} = \\mu_{\\text{Adult-onset}} \\\\\n&H_A: \\mu_{\\text{Teen-onset}} \\neq \\mu_{\\text{Adult-onset}}\n\\end{split}\n\\]\nHowever, when we go to use the t_test() function, the alternative hypothesis we specify will correspond to an alphabetical ordering of the groups based on their values in the attribute. In the cannabis_dep attribute, the two values are Teen and Adult.\n\nWe can also represent the hypotheses as a difference between the two means. For example, the null hypothesis posits the two means are equal. Mathematically this can be also expressed as the difference between the two means is equal to zero:\n\\[\nH_0: \\mu_{\\text{Adult-onset}} - \\mu_{\\text{Teen-onset}} = 0\n\\] In a similar fashion the alternative hypothesis could be expressed as:\n\\[\nH_A: \\mu_{\\text{Adult-onset}} - \\mu_{\\text{Teen-onset}} \\neq 0\n\\]\n\nThe output from t_result() will present the hypotheses as a difference between means.",
    "crumbs": [
      "Comparing Two Groups",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Two-Sample t-Test</span>"
    ]
  },
  {
    "objectID": "05-01-two-sample-t-test.html#visualizing-and-numerically-describing-sample-differences",
    "href": "05-01-two-sample-t-test.html#visualizing-and-numerically-describing-sample-differences",
    "title": "13¬† Two-Sample t-Test",
    "section": "13.3 Visualizing and Numerically Describing Sample Differences",
    "text": "13.3 Visualizing and Numerically Describing Sample Differences\nAs with every analysis, we begin by visualizing and describing the sample data. Here we will create density plots of the distribution of changes in IQ scores for both groups. To do this, since the IQ change scores are all in a single column, we have to change the formula with the tilde we use in the gf_ and df_stats() functions so that it will plot those for each group separately. The formula will now look like:\n\\[\n\\mathtt{\\sim y ~|~ group}\n\\]\nwhere y is the attribute name that you want to plot, and group is the name of the attribute that has the groups in it. For example, since we want to plot the IQ change scores for the two groups we would use the formula:\n\\[\n\\mathtt{\\sim iq\\_change ~|~ cannabis\\_dep}\n\\]\n\nReading this syntax, we would say: ‚Äúmodel the attribute iq_change but separate this by cannabis_dep‚Äù You can also say: ‚Äúmodel the attribute iq_change but condition this on cannabis_dep‚Äù. In statistics a conditional distribution is a distribution for a particular group.\n\nThe syntax for creating density plots and computing numerical summaries is shown below.\n\n# Create histogram\ngf_density(\n  ~ iq_change | cannabis_dep, data = cannabis,\n  fill = \"skyblue\", \n  xlab = \"Change in IQ Score\",\n  ylab = \"Density\"\n  )\n\n# Compute numerical summaries\ndf_stats(~ iq_change | cannabis_dep, data = cannabis)\n\n\n\n\n\n\n\n\nFigure¬†13.1: Density plots of IQ score changes for participants who became persistent marijuana users as teens and those who became persistent marijuana users as adults.\n\n\n\n\n\n\n\n\n\n\nFigure¬†13.2: Density plots of IQ score changes for participants who became persistent marijuana users as teens and those who became persistent marijuana users as adults.\n\n\n\n\n\nThe density plots suggests that the distribution of change in IQ scores is not symmetric for either group. The distribution for participants who became persistent marijuana users as teens is also potentially bimodal. The average change in IQ score for participants who became persistent marijuana users as adults was \\(-2.07\\) points indicating that the average IQ score decreased by about two points throughout the duration of the study. In contrast, the average change in IQ score for participants who became persistent marijuana users as teens was \\(-8.26\\) points indicating that the average IQ score decreased by about eight points throughout the duration of the study. The was variation in IQ change in both groups, with both groups having a standard deviation near seven.\nNext, we carry out a two-sample t-test. The arguments we include are:\n\nA formula of ~y|group indicating the attribute to compare, and the groups that are being compared;\ndata= indicating the data frame the attributes are in;\nmu= to specify the value of the difference in population means specified in the null hypothesis;\nalternative= is one of two.sided, less, or greater that corresponds to the alternative hypothesis; and\nvar.equal=TRUE which ensures that you use the correct version of the two-sample t-test\n\nWe can assign the output of the t_test() function into an object, and use the t_results() and plot_t_dist() functions to examine the output of the two-sample t-test and view the t-distribution and shaded p-value, respectively.\n\n# Two-sample t-test\nmy_t &lt;- t_test(\n  ~ iq_change | cannabis_dep, \n  data = cannabis, \n  mu = 0, \n  alternative = \"two.sided\", \n  var.equal = TRUE\n  )\n\n# View t-test results\nt_results(my_t)\n\n\n--------------------------------------------------\n Two Sample t-test\n--------------------------------------------------\n\nH[0]: mu_[Adult] = mu_[Teen]\nH[A]: mu_[Adult] ‚â† mu_[Teen]\n\nt(35) = 2.474706\np = 0.01832593\n\n--------------------------------------------------\n\n\n\nWhen you get the results from the t-test, be sure it says ‚ÄúTwo Sample t-test‚Äù. If it says ‚ÄúWelch Two Sample t-test‚Äù you forgot to set the argument var.equal=TRUE.\n\n\n# View t-distribution\nplot_t_dist(my_t)\n\n\n\n\n\n\n\nFigure¬†13.3: Density plot of the t-distribution of the sample means based on the thought experiment underlying a hypothesis test assuming that the difference in mean IQ score change between participants who became persistent marijuana users as adults and those that became persistent marijuana users as teens is 0 (t value of 0). The red vertical lines represents the observed t-value of 2.47 and -2.47. The shaded area under the curve to the right of 2.47 and left of -2.47 represent the associated p-value of .018 that corresponds to the alternative hypothesis that \\(\\mu\\neq0\\).\n\n\n\n\n\nBased on the p-value of .018, we would reject the null hypothesis. The evidence suggests that the difference in average IQ score change is likely different for participants who became persistent marijuana users as adults than those that became persistent marijuana users as teens.",
    "crumbs": [
      "Comparing Two Groups",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Two-Sample t-Test</span>"
    ]
  },
  {
    "objectID": "05-01-two-sample-t-test.html#computing-the-observed-t-value-and-degrees-of-freedom",
    "href": "05-01-two-sample-t-test.html#computing-the-observed-t-value-and-degrees-of-freedom",
    "title": "13¬† Two-Sample t-Test",
    "section": "13.4 Computing the Observed t-Value and Degrees-of-Freedom",
    "text": "13.4 Computing the Observed t-Value and Degrees-of-Freedom\nThe observed t-value is computed as part of using the t_test() function, but examining the mathematical formula may give us insight into what this t-statistic is measuring. In a two-sample t-test the t-value is computed as:\n\\[\nt = \\frac{(\\bar{y}_{1} - \\bar{y}_{2}) - \\mu_{\\text{Diff.}}}{SE_{\\text{Mean Diff.}}}\n\\]\nwhere,\n\\(\\bar{y}_1\\) is the sample mean for Group 1, \\(\\bar{y}_2\\) is the sample mean for Group 2, \\(\\mu_{\\text{Diff.}}\\) is the mean difference specified in the null hypothesis, and \\(SE_{\\text{Mean Diff.}}\\) is the standard error for the sample mean difference, which is computed as:\n\\[\nSE_{\\text{Mean Diff.}} = \\sqrt{\\frac{SD_1^2}{n_1} + \\frac{SD_2^2}{n_2}}\n\\]\nAnd \\(SD_1\\) and \\(SD_1\\) are the sample standard deviations for Groups 1 and 2, respectively, and \\(n_1\\) and \\(n_2\\) are the sample sizes for those groups.\nLooking at the numerator of the t-value, we are measuring how far the sample mean difference is from the hypothesized mean difference. Then, we are dividing by the SE, which changes the scale to standard error units. So our observed t-value is measuring the discrepancy between the sample and hypothesized mean difference in standard error units. In our example,\n\\[\n\\begin{split}\nt &= \\frac{(-2.07 - -8.26) - 0}{\\sqrt{\\frac{7.77^2}{14} + \\frac{7.14^2}{22}}} \\\\[2ex]\n&= \\frac{6.19}{2.55} \\\\[2ex]\n&= 2.47\n\\end{split}\n\\]\nThat is our observed mean difference of 6.19 is 2.47 standard errors from the hypothesized mean difference of 0. We then evaluate this t-value in a t-distribution with \\(n1 + n_2 -2\\) degrees-of-freedom. In our case the t-value of 2.47 is evaluated in a t-distribution with 35 df. This is the same thing we got in the output of t_results().\nSince the alternative hypothesis was \\(\\mu_{\\text{Adult-onset}} - \\mu_{\\text{Teen-onset}} \\neq 0\\), to find the p-value, we would find the area under the t-distribution that is greater than or equal to the observed t-value of 2.47 and less than or equal to \\(-2.47\\). This area is shaded in the output of plot_t_dist() and corresponds to .018 of the entire area under the curve.",
    "crumbs": [
      "Comparing Two Groups",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Two-Sample t-Test</span>"
    ]
  },
  {
    "objectID": "05-01-two-sample-t-test.html#case-study-2-bachelor-and-bachelorette-ages",
    "href": "05-01-two-sample-t-test.html#case-study-2-bachelor-and-bachelorette-ages",
    "title": "13¬† Two-Sample t-Test",
    "section": "13.5 Case Study 2: Bachelor and Bachelorette Ages",
    "text": "13.5 Case Study 2: Bachelor and Bachelorette Ages\nResearch suggests that men emotionally mature years later than women. This is because the human brain develops slower in men than in women, on average. In the reality television series The Bachelor and The Bachelorette, a single person is introduced to a pool of potential romantic interests. Throughout the show, they get to know these people by going on dates with them and eliminating those they are not interested in. At the end of the show, they are supposed to select one person that will become their fianc√©. If there is a maturity gap between men and women, we might expect that the average age for Bachelor and Bachelorette contestants may differ.\nWe will use the data in bachelor.csv to evaluate whether there are age differences between those people selected to be The Bachelor and those selected to be The Bachelorette. In particular we will test the following hypotheses:\n\\[\n\\begin{split}\n&H_0: \\mu_{\\text{Bachelor}} = \\mu_{\\text{Bachelorette}} \\\\\n&H_A: \\mu_{\\text{Bachelor}} \\neq \\mu_{\\text{Bachelorette}}\n\\end{split}\n\\]\n\nYour Turn\nWrite the hypotheses as a difference in the average ages of the Bachelor and Bachelorette contestants.\n\nShow/Hide Solution\n\n\n\\[\n\\begin{split}\n&H_0: \\mu_{\\text{Bachelor}} - \\mu_{\\text{Bachelorette}} = 0 \\\\\n&H_A: \\mu_{\\text{Bachelor}} - \\mu_{\\text{Bachelorette}} \\neq 0\n\\end{split}\n\\]\n\n\n\n# Import data\nbachelor &lt;- read_csv(\"https://raw.githubusercontent.com/zief0002/epsy-5261/main/data/bachelor.csv\")\n\n# View data\nbachelor\n\n\n  \n\n\n\nBelow we create the distribution of ages for the bachelors and bachelorettes. Both distributions are right-skewed and have a range between about 25 and 40. The average age for the bachelor contestants is 30.7 while that for the Bachelorette contestants is slightly younger at 28.2. The SD for these distributions is slightly higher for the Bachelor contestants (3.80) than for the Bachelorette contestants (3.04) indicating a little more variation in the bachelors‚Äô ages.\n\n# Create histogram\ngf_histogram(\n  ~age | show, data = bachelor,\n  binwidth = 2,\n  color = \"black\", \n  fill = \"skyblue\",\n  xlab = \"Age\",\n  ylab = \"Count\"\n  )\n\n# Compute numerical summaries\ndf_stats(~age | show, data = bachelor)\n\n\n\n\n\n\n\n\nFigure¬†13.4: Histograms of ages for the 27 Bachelor and 23 Bachelorette contestants.\n\n\n\n\n\n\n\n\n\n\nFigure¬†13.5: Histograms of ages for the 27 Bachelor and 23 Bachelorette contestants.\n\n\n\n\n\nWhile the sample data suggests that the average age for Bachelor contestants is higher than the average age of Bachelorette contestants, is this difference only due to sampling variation? To answer this, we will carry out a two-sample t-test to evaluate the sample differences in light of the expected sampling variation.\n\n# Two-sample t-test\nmy_t &lt;- t_test(\n  ~age | show, data = bachelor, \n  mu = 0, \n  alternative = \"two.sided\",\n  var.equal = TRUE\n  )\n\n# View t-test results\nt_results(my_t)\n\n\n--------------------------------------------------\n Two Sample t-test\n--------------------------------------------------\n\nH[0]: mu_[Bachelor] = mu_[Bachelorette]\nH[A]: mu_[Bachelor] ‚â† mu_[Bachelorette]\n\nt(48) = 2.567151\np = 0.0134258\n\n--------------------------------------------------\n\n\n\nYour Turn\nUse the results of the two-sample t-test to sketch the t-distribution with 48 df, add vertical lines at the observed t-value (and \\(-\\)t-value), and shade the area under the curve corresponding to the p-value.\n\nShow/Hide Solution\n\n\nYour sketch should look something like the following.\n\n# View t-distribution\nplot_t_dist(my_t)\n\n\n\n\n\n\n\nFigure¬†13.6: Density plot of the t-distribution of the difference in sample means based on the thought experiment underlying a hypothesis test assuming that the difference in mean age between Bachelor and Bachelorette contestants is 0 (t value of 0). The red vertical lines represent the observed t-value of 2.57 and -2.57. The shaded area under the curve to the right of 2.57 and left of -2.57 show the associated p-value of .013 that corresponds to the alternative hypothesis that the average age for the Bachelor contestants is different than the average age of the Bachelorette contestants.\n\n\n\n\n\n\nBased on the results of the t-test, should we reject or fail to reject the null hypothesis? Explain why and also what this implies given the context of the case study.\n\nShow/Hide Solution\n\n\nThe p-value of .013 suggest we should reject the null hypothesis that the average age of Bachelor and Bachelorette contestants are the same (or that the difference between these averages is 0) since it is less than .05. This suggests that the average age for Bachelor contestants is different than the average age for Bachelorette contestants.",
    "crumbs": [
      "Comparing Two Groups",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Two-Sample t-Test</span>"
    ]
  },
  {
    "objectID": "05-01-two-sample-t-test.html#references",
    "href": "05-01-two-sample-t-test.html#references",
    "title": "13¬† Two-Sample t-Test",
    "section": "13.6 References",
    "text": "13.6 References\n\n\n\n\nMeier, M. H., Caspi, A., Ambler, A., Harrington, H., Houts, R., Keefe, R. S. E., McDonald, K., Ward, A., Poulton, R., & Moffitt, T. E. (2012). Persistent cannabis users show neuropsychological decline from childhood to midlife. Proc Natl Acad Sci U S A, 109(40), E2657‚Äì64. https://doi.org/10.1073/pnas.1206820109\n\n\nVolkow, N. D., Baler, R. D., Compton, W. M., & Weiss, S. R. B. (2014). Adverse health effects of marijuana use. N Engl J Med, 370(23), 2219‚Äì2227. https://doi.org/10.1056/NEJMra1402309",
    "crumbs": [
      "Comparing Two Groups",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Two-Sample t-Test</span>"
    ]
  },
  {
    "objectID": "05-02-two-sample-test-assumptions.html",
    "href": "05-02-two-sample-test-assumptions.html",
    "title": "14¬† Two-Sample t-Test: Assumptions",
    "section": "",
    "text": "14.1 Assumptions\nFor the two-sample t-test there are three statistical assumptions we make about the populations:\nFor example, in the cannabis case study we need to know that:\nSimilar to the assumptions from the one-sample t-test, we can never know for sure whether these assumptions are met since we do not have data from the entire population. Instead, we have to decide whether these assumptions seem tenable based on the sample of data we have.",
    "crumbs": [
      "Comparing Two Groups",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Two-Sample t-Test: Assumptions</span>"
    ]
  },
  {
    "objectID": "05-02-two-sample-test-assumptions.html#assumptions",
    "href": "05-02-two-sample-test-assumptions.html#assumptions",
    "title": "14¬† Two-Sample t-Test: Assumptions",
    "section": "",
    "text": "The distribution of values in both populations is normally distributed.\nThe values in both population are independent from each other.\nBoth populations have the same variance.\n\n\n\nIf you took the change in IQ score measurements for all people who became dependent on cannabis as a teen and plotted them, the distribution would be normally distributed. Similarly the change in IQ score measurements for all people who became dependent on cannabis as an adult would also be normally distributed.\nThe change in IQ score measurements for all people who became dependent on cannabis as a teen is independent from those of every other person who became dependent on cannabis as a teen. And, the change in IQ score measurements for all people who became dependent on cannabis as an adult is independent from those of every other person who became dependent on cannabis as an adult.\nIf you took the change in IQ score measurements for all people who became dependent on cannabis as a teen and computed the variance, that value would be the same as the variance computed from the change in IQ score measurements for all people who became dependent on cannabis as an adult.\n\n\n\n\n14.1.1 Evaluating the Assumption of Normality\nTo evaluate the first assumption that the distributions of values in both populations are normally distributed, we plot the sample data for both groups and ask the question: Is this distribution close to normal? The density plot of the sample teen sleep data is shown in Figure¬†11.1.\n\n# Load libraries\nlibrary(educate)\nlibrary(ggformula)\nlibrary(mosaic)\nlibrary(tidyverse)\n\n\n# Import data\ncannabis &lt;- read_csv(\"https://raw.githubusercontent.com/zief0002/epsy-5261/main/data/cannabis.csv\")\n\n# Create histogram\ngf_density(\n  ~ iq_change | cannabis_dep, data = cannabis,\n  fill = \"skyblue\", \n  xlab = \"Change in IQ Score\",\n  ylab = \"Density\"\n  )\n\n\n\n\n\n\n\nFigure¬†14.1: Density plots of IQ score changes for participants who became persistent marijuana users as teens and those who became persistent marijuana users as adults.\n\n\n\n\n\nThe density plots suggests that the SAMPLE distributions of change in IQ scores is not symmetric for either group. The question is whether the POPULATION distributions are normal, not whether the sample distributions are normal. We are only asking whether we believe that the population distributions are normal based on what we see in the sample distributions. To answer this question, we need some idea of what sample distributions of size 14 and 23 look like if they truly do come from a population that is normally distributed. Below are the distributions for five samples of size 14 and 23 that were actually drawn from a normal distribution.\n\n\nBin width defaults to 1/30 of the range of the data. Pick better value with\n`binwidth`.\n\n\n\n\n\n\n\n\nFigure¬†14.2: Five simple random samples of size 14 and 23 drawn from a normal population.\n\n\n\n\n\nWe see that many of these sample distributions have multiple modes or indicate some skew. However, all of these were drawn from a normally distributed population, that is: the assumption of normality would be met. One take away from this is that with small sample sizes it is difficult to tell whether the assumption of normality is met since even sample distributions drawn from a normal population don‚Äôt necessarily look normal.\nIn our example, the sample distributions do not appear normal. Is this because the population they come from is not normal? Or is it that the population is normal, but the small sample size resulted in a non-normal sample? We don‚Äôt know!\nAs in the one-sample situation, even if the samples look non-normal, we can fall back on the Central Limit Theorem (CLT) if our sample size is large enough in both groups (i.e., \\(n\\geq 30\\)). In our example the sample sizes are 14 (adult) and 23 (teen), respectively. These sample sizes are both less than 30. So we cannot rely on the CLT.\nGiven that the sample distributions deviate from normality and the small sample sizes, it may be that the normality assumption is not tenable or it may be tenable‚Ä¶we just can‚Äôt tell. In this situation, it is safest to point out that the normality assumption may not be tenable.\n\n\n\n14.1.2 Evaluating the Independence Assumption\nTo evaluate the independence assumption we need to know whether random chance was used in the study design. With two groups, random chance might be employed in a couple different ways:\n\nRandom chance might have been used to select the observations in the sample data (random sampling).\nRandom chance might have been used to assign the observations to the two different groups (random assignment).\n\nIf random chance was used in either of these aspects of the study design, it will guarantee independence of the observations. In our example, the participants were not chosen randomly from the larger populations of adults or teens that became dependent on cannabis. They were all volunteers who agreed to be a part of the study‚Äîthe study did not employ random sampling. Random chance was also not employed to assign the participants to the two groups being compared. Participants either became dependent on cannabis as teens or adults‚Äîthey were not randomlly assigned to become dependent at a certain age.\nBecause we cannot rely on the study design to ensure independence, we need to make a logical argument about whether knowing that one participant‚Äôs change in IQ score would convey any information about any other participant‚Äôs change in IQ score. It is unlikely that this is the case (at least without more information about the participants). Because of this, we could argue that the independence assumption seems tenable.\n\n\n\n14.1.3 Evaluating the Equal Variances Assumption\nTo evaluate the assumption that the two populations have equal variances1, we will compare the sample variances for both groups.\n\n# Compute numerical summaries\ndf_stats(~ iq_change | cannabis_dep, data = cannabis)\n\n\n  \n\n\n\nWhile the variances aren‚Äôt provided directly in the ouptut of the df_stats() function, they can be computed by squaring the standard deviations:\n\nAdult Variance: \\(\\sigma^2_{\\text{Adult}} = 7.77^2 = 60.38\\)\nTeen Variance: \\(\\sigma^2_{\\text{Teen}} = 7.14^2 = 50.93\\)\n\nSimilar to the normality assumption, we don‚Äôt expect that both groups will have equal SAMPLE variances, but instead ask the question whether we believe that the POPULATION distributions have equal variances based on what we see in the sample variances. One rule-of-thumb that is often employed is that we find the assumption tenable if the larger variance is no more than four times the smaller variance. In our example, we would ask:\n\\[\n60.38 \\overset{?}{&gt;} 50.93 \\times 4\n\\] Because the larger variance (60.38) is not bigger than four times the smaller variance (50.93), we would say the assumption of equal variances is tenable.",
    "crumbs": [
      "Comparing Two Groups",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Two-Sample t-Test: Assumptions</span>"
    ]
  },
  {
    "objectID": "05-02-two-sample-test-assumptions.html#evaluating-assumptions-in-the-bachelor-and-bachelorette-ages-case-study",
    "href": "05-02-two-sample-test-assumptions.html#evaluating-assumptions-in-the-bachelor-and-bachelorette-ages-case-study",
    "title": "14¬† Two-Sample t-Test: Assumptions",
    "section": "14.2 Evaluating Assumptions in the Bachelor and Bachelorette Ages Case Study",
    "text": "14.2 Evaluating Assumptions in the Bachelor and Bachelorette Ages Case Study\n\nYour Turn\nIn the Bachelor and Bachelorette ages case study from Chapter 13, we evaluated whether, on average, there were age differences between those people selected to be The Bachelor and those selected to be The Bachelorette. The histograms for the sample distributions of ages is shown below. Based on this plot and the sample size, do you believe the normality assumption is tenable?\n\n\n\n\n\n\n\n\nFigure¬†14.3: Histograms of ages for the 27 Bachelor and 23 Bachelorette contestants.\n\n\n\n\n\n\nShow/Hide Solution\n\n\nThe normality assumption may not be tenable. Both sample distributions are skewed to the right. Moreover, the sample sizes for the two groups are both less than 30.\n\nBased on the data collection process described in the data codebook, do you believe the independence assumption is tenable?\n\nShow/Hide Solution\n\n\nThere was no random chance used to select the sample data, nor was random chance used to assign the daa into the two groups. Making a logical argument, would knowing one Bachelor‚Äôs or Bachelorette‚Äôs age give us information about another‚Äôs age? Probably not (independence seems tenable), but there might be a case made that it does (independence is not tenable).\n\nBased on the summary statistics provided below, do you believe the equal variances assumption is tenable?\n\n\n\n  \n\n\n\n\nShow/Hide Solution\n\n\nThe variance for the Bachelor ages is \\(3.80^2=14.45\\), and that for the Bachelorette ages is \\(3.04^2=9.24\\). Since 14.45 is less than four times 9.24, the assumption of equal population variances seems tenable.",
    "crumbs": [
      "Comparing Two Groups",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Two-Sample t-Test: Assumptions</span>"
    ]
  },
  {
    "objectID": "05-02-two-sample-test-assumptions.html#footnotes",
    "href": "05-02-two-sample-test-assumptions.html#footnotes",
    "title": "14¬† Two-Sample t-Test: Assumptions",
    "section": "",
    "text": "This assumption is also referred to as the homogeneity of variance assumption.‚Ü©Ô∏é",
    "crumbs": [
      "Comparing Two Groups",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Two-Sample t-Test: Assumptions</span>"
    ]
  },
  {
    "objectID": "05-03-two-sample-test-proportions.html",
    "href": "05-03-two-sample-test-proportions.html",
    "title": "15¬† Two-Sample z-Test: Evaluating Differences in Proportions From Two Samples",
    "section": "",
    "text": "15.1 Case Study: Still Together?\nIn Chapter 13 we examined whether there were differences in the average age of those people selected to be The Bachelor and those selected to be The Bachelorette. Here, we will continue our data analysis of these reality shows by examining whether the Bachelors or Bachelorettes were more successful in their selection of potential mates by determining whether the proportion of couples that are still together is different for the Bachelors and Bachelorettes.\nThe data in bachelor.csv contains the attribute still_together which is a categorical variable indicating whether the Bachelor or Bachelorette is still together with the person they selected (at least as of June, 2023). We will use this attribute, along with the show attribute to evaluate the following set of hypotheses:\n\\[\n\\begin{split}\nH_0: \\pi_{\\text{Bachelor}} = \\pi_{\\text{Bachelorette}} \\\\[1ex]\nH_A: \\pi_{\\text{Bachelor}} \\neq \\pi_{\\text{Bachelorette}}\n\\end{split}\n\\] where \\(\\pi_{\\text{Bacheor}}\\) is the proportion of all Bachelor contestants that are still together with the person they chose, and \\(\\pi_{\\text{Bacheorette}}\\) is the proportion of all Bachelorette contestants that are still together with the person they chose. (Reminder that it is convention to indicate the group you are hypothesizing the proportion for in the subscript of \\(\\pi\\).)\nTo answer this question, we can compare the proportion of Bachelor and Bachelorette contestants in the sample that are still together with the person they chose, and then carry out a two-sample z-test to see if any differences we observed in the sample data are just due to sampling error. To begin, we will load a few libraries and import the data.\nlibrary(educate)\nlibrary(ggformula)\nlibrary(mosaic)\nlibrary(mosaicCore)\nlibrary(tidyverse)\n\n\n# Import data\nbachelor &lt;- read_csv(\"https://raw.githubusercontent.com/zief0002/epsy-5261/main/data/bachelor.csv\")\n\n# View data\nbachelor",
    "crumbs": [
      "Comparing Two Groups",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Two-Sample z-Test: Evaluating Differences in Proportions From Two Samples</span>"
    ]
  },
  {
    "objectID": "05-03-two-sample-test-proportions.html#case-study-still-together",
    "href": "05-03-two-sample-test-proportions.html#case-study-still-together",
    "title": "15¬† Two-Sample z-Test: Evaluating Differences in Proportions From Two Samples",
    "section": "",
    "text": "Your Turn\nSimilar to hypotheses we wrote for the two-sample t-test, hypotheses in which we compare two samples‚Äô proportions can also be written as differences. Re-write the null and alternative hypotheses as differences.\n\nShow/Hide Solution\n\n\n\\[\n\\begin{split}\nH_0: \\pi_{\\text{Bachelor}} - \\pi_{\\text{Bachelorette}} = 0 \\\\[1ex]\nH_A: \\pi_{\\text{Bachelor}} - \\pi_{\\text{Bachelorette}} \\neq 0\n\\end{split}\n\\] As a reminder, we typically write the difference in alphabetical order based on the values in the grouping variable. In this case, we start with the bachelor group and subtract the bachelorette group to be consistent with how we will need to enter the syntax for the test in R.\n\n\n\n\n\n\n15.1.1 Summarizing the Sample Data\nWe will start the analysis by summarizing the still_together attribute to determine the proportion of Bachelor and Bachelorette contestants that are still together with the person they selected on the show. We will use the vertical bar (|) to condition the still_together attribute by show in the tally() function. To get proportions, we also include the extra argument format=\"proportion\".\n\n# Syntax to compute the number of contestants that are still together for each category in the show attribute\ntally(~still_together | show, data = bachelor)\n\n              show\nstill_together Bachelor Bachelorette\n          No         24           17\n          Yes         3            4\n          &lt;NA&gt;        0            2\n\n# Syntax to compute the proportion of contestants that are still together for each category in the show attribute\ntally(~still_together | show, data = bachelor, format = \"proportion\")\n\n              show\nstill_together   Bachelor Bachelorette\n          No   0.88888889   0.73913043\n          Yes  0.11111111   0.17391304\n          &lt;NA&gt; 0.00000000   0.08695652\n\n\nThese summaries indicates that in 2018, the proportion of Bachelor contestants that are still together with their selected suitor is 0.11, while the proportion of Bachelorette contestants that are still together with their selected suitor is 0.17. We would again use the notation \\(\\hat{p}\\) along with a subscript to denote the sample proportions:\n\\[\n\\hat{p}_{\\text{Bachelor}} = .11 ~~~~~~~~~~ \\hat{p}_{\\text{Bachelorette}} = .17\n\\]\n\n\n15.1.1.1 Missing Data\nOne other thing we see is that there are 2 NA values in the counts and proportions. This is telling us that two cases in our data are missing values on the still_together attribute. Looking back at the CSV file, we find that two of the Bachelorette contestants, Britt Nilsson and Charity Lawson are missing values on the still_together attribute. In any analysis involving the still_together attribute, that will mean that these two cases will be dropped.\nThe proportions in the tally() output are based on the complete number of contestants within each show. For example, the proportion of 0.74 indicating the proportion of Bachelorette contestants that are not still together is based on the total number of Bachelorette contestants (\\(n=23\\)). Because our two-sample z-test will only be based on those contestants who have data, it is common to base the sample proportions on only those contestants that have data (e.g., based on the \\(n=21\\) Bachelorettes with data. To compute these proportions, we will include the argument useNA=\"no\" in the tally() function.\n\n# Syntax to compute the proportion of contestants that are still together for each category in the show attribute\n# Compute only for those contestants with data\ntally(~still_together | show, data = bachelor, format = \"proportion\", useNA = \"no\")\n\n              show\nstill_together  Bachelor Bachelorette\n           No  0.8888889    0.8095238\n           Yes 0.1111111    0.1904762\n\n\nNow, the proportion of 0.81 indicating the proportion of Bachelorette contestants that are not still together with their selected suitor is based on the number of Bachelorette contestants with data (\\(n=21\\)).\nWhile the tally() function includes an argument to only use those cases with data, not all R functions have this utility. Some will drop the cases without telling you, and others will not work at all with missing values. The latter is the case with the prop_test() function we will use later. We will look at solutions to this problem later in this chapter when we introduce the syntax for the two-sample z-test\n\n\n\n15.1.1.2 Reporting Sample Results: Contingency Tables\nIn reporting the sample results, we typically only need to report the sample values for one category of the outcome (e.g., the proportion that are still together). However, many manuscripts will also report the inverse of these values as well (e.g., the proportion who are NOT still together). Table¬†15.1 shows an example of a table summarizing the counts and proportions that might by produced in a manuscript.\n\n\n\n\nTable¬†15.1: Counts (and proportions) of Bachelor and Bachelorette contestants that are still together with the person they selected on the show. Proprtions are based on the total number of contestants within each show.\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n\nShow\nNot Together\nStill Together\nTotal\n\n\n\n\nBachelor\n24(0.89)\n3(0.11)\n27\n\n\nBachelorette\n17(0.81)\n4(0.19)\n21\n\n\nTotal\n410.85\n70.15\n48\n\n\n\n\n\n\n\n\n\n\n\nThe table in Table¬†15.1 is called a contingency table. Contingency tables typically report counts, proportions, or both. They also often include total counts (the row and column highlighted in yellow). The first two total values in the column labelled ‚ÄúTotal‚Äù are the total number of contestants on each show‚Äî27 total contestants on the Bachelor and 21 total contestants on the Bachelorette‚Äîthese are called row totals since we are summing across the rows. The first two total counts in the row labelled ‚ÄúTotal‚Äù indicate the total number of contestants across both shows that are no longer together and the total number across both shows that are still together‚Äî41 contestants are no longer together with the suitor they selected, while 7 are still together with their chosen suitor‚Äîthese totals are referred to as column totals as they constitute the sum in different columns. Finally, the count in the last row and last colum (48) indicated the total number of contestants. Sometimes this value is referred to as the grand total or the total sample size.\nWhen you are interpreting the information from the contingency table, especially proportions, it is important to note which total was used in the denominator of the proportion. For example, if we were trying to compute a proportion of the Bachelor contestants that are still together with their selected suitor (\\(n=3\\)), we have three ways we could compute a proportion:\n\n\\(\\frac{3}{27} = .11\\) This proportion uses the row total in the denominator and is the proportion that is reported which indicates the proportion of all Bachelor contestants that are still together with their selected suitors.\n\\(\\frac{3}{7} = .43\\) This proportion uses the column total in the denominator. It indicates the proportion of all contestants that are still together with their selected suitors that are Bachelor contestants.\n\\(\\frac{3}{48} = .06\\) This proportion uses the grand total in the denominator. It indicates the proportion of all contestants that are Bachelor contestants and are still together with their selected suitor.\n\nThe key is, of course, to report the proportions that help you answer your research question. Since we were interested in differences between shows, we want to compute the proportion of contestants still together within each show. That is why we used the row total in the denominator. Because a proportion can be computed in these multipe ways, it is good practice to report how the proportions are being computed in the table caption or a table note.\n\n\n\n15.1.1.3 Reporting Sample Results: Segmented Bar Charts\nSometimes the summary results are reported in a visualization. One common visualization used to report counts or proportions for multiple groups is the segmented bar chart. Here we use the gf_props() function to plot the proportions of contestants still together (and not still together) within each show. To do this we give:\n\nA formula (~) indicating the attribute to compute proportions within. In this case we used ~show because we want to compute the proportion within each show. This will create a separate bar for each show.\ndata= indicates the name of the data frame.\nfill= gives a formula for how to color fill each bar. Since we used fill=~still_together, each bar will be color filled based on the values in the still_together attribute.\nposition=\"fill\" will make the bars comparable by creating a full range within each show\nxlab= and ylab= indicate the labels you wan on the x- and y-axes, respectively\n\n\n# Syntax to create a segmented bar chart for the still_together attribute\n# A seperate bar is show for each show\ngf_props(\n  ~show, data = bachelor,\n  fill = ~still_together,\n  position = \"fill\",\n  xlab = \"Show\",\n  ylab = \"Proportion\"\n  ) \n\n\n\n\n\n\n\n\nThe default colors used to fill in the bars are not aesthetically pleasing. We can change these by adding the scale_fill_manual() function to the end of our plot syntax. Here we change the name of the legend title by including the name= argument in this function. We also need to include the argument values= which sets the colors we want to use within a c() function. Because there are three colors used, we provide the names or codes for three colors within this c() function. Here I used Hex Codes to define the three colors. (You can learn more about and explore Hex Codes for colors here.)\n\n# Syntax to create a segmented bar chart for the still_together attribute\n# A seperate bar is show for each show\ngf_props(\n  ~show, data = bachelor,\n  fill = ~still_together,\n  position = \"fill\",\n  xlab = \"Show\",\n  ylab = \"Proportion\"\n  ) +\n  scale_fill_manual(\n    name = \"Still Together?\",\n    values = c(\"#2dd7f8\", \"#e059b2\", \"#686868\"), \n  )\n\n\n\n\n\n\n\n\n\nRemember different visualizations use color= or fill= to set the color. The gf_props() function uses fill= to set the fill color of the bars; color= would set the color of the bar outline. Because we used fill= in our gf_ function, we use scale_fill_manual() to define the colors and change the legend title. If instead we had used color= in our gf_ function we would have to use scale_color_manual().\n\nLastly, we point out that these visualizations included the Bachelorettes with the missing values in the stiltogether attribute (e.g., the proportions are based on \\(n=23\\) Bachelorette contestants). If you want to omit the missing values we need to add some syntax in the gf_ function everytime we use the still_together attribute. Rather than using fill=~still_together, we want to fill based on only those values that are not missing. To do that we set this argument to: fill=~!is.na(still_together). The is.na() function identifies all the cases that are missing is the still_together attribute and the ! at the beginning tells fill= to only use those values that are NOT missing. Then, since there are no more missing vlaues, we would only need to provide two colors to the scale_fill_manual() functin\n\n# Syntax to create a segmented bar chart for the still_together attribute\n# A seperate bar is show for each show\n# The fill color is only based on non-missing values\ngf_props(\n  ~show, data = bachelor,\n  fill = ~!is.na(still_together),\n  position = \"fill\",\n  xlab = \"Show\",\n  ylab = \"Proportion\"\n  ) +\n  scale_fill_manual(\n    name = \"Still Together?\",\n    values = c(\"#2dd7f8\", \"#e059b2\"), \n  )\n\n\n\n\n\n\n\n\nThe choice of how you report the counts and proportions is up to you. Most manuscripts will either report the contingency table or just include the appropriate proportions in the text itself. For example, a sentence like: ‚ÄúThe proportion of Bachelor contestants who are still together with their selected suitor is 0.11, while the proportion of Bachelorette contestants who are still together with their selected suitor is 0.19.‚Äù (Note that the proportion who are not still together with their selected suitor can be easily determined and hence does not need to be reported.) A visualization like the segmented bar chart is useful if you have many groups you are reporting proportions for. Since we only have two groups we are comparing, a table or text is simpler.\n\n\n\n\n15.1.2 Testing Proportions Using the One-Sample z-Test\nThe sample data suggest that there is is a difference between the two shows in the proportion of contestants that are still together with their selected suitor (\\(0.11 \\neq 0.19\\)). The next question we would want to tackle is whether this difference is more than we expect because of sampling error. To determine this, we need to carry out a hypothesis test.The hypothesis test we use to compare two samples‚Äô proportions is the two-sample z-test. The process we use is very similar to that for the one-sample z-test, which was:\n\nUse the difference in sample proportions to compute a z-value;\nLocate the observed z-value in the z-distribution; and\nDetermine the p-value by computing the area under the curve in the z-distribution that is at least as extreme as the observed t-value based on the alternative hypothesis.\n\nTo compute the z-value, we use:\n\\[\nz = \\frac{\\hat{p}_1 - \\hat{p}_2}{SE_{\\hat{p}_1 - \\hat{p}_2}}\n\\]\nwhere \\(\\hat{p}_1\\) is the sample proportion for group 1, \\(\\hat{p}_2\\) is the the sample proportion for group 2, and \\(SE_{\\hat{p}_1 - \\hat{p}_2}\\) is the standard error for the difference in proportions. This SE is computed as:\n\\[\nSE_{\\hat{p}_1 - \\hat{p}_2} = \\sqrt{\\frac{\\hat{p}_1(1 - \\hat{p}_1)}{n_1} + \\frac{\\hat{p}_2(1 - \\hat{p}_2)}{n_2}}\n\\]\nwhere again, \\(\\hat{p}_1\\) is the sample proportion for group 1, \\(\\hat{p}_2\\) is the the sample proportion for group 2, and \\(n_1\\) and \\(n_2\\) are the sample sizes for group 1 and 2, respectively. In our example, the z-value is:\n\\[\n\\begin{split}\nz &= \\frac{.11 - .19}{\\sqrt{\\frac{.11(1 - .11)}{27}} + \\sqrt{\\frac{.19(1 - .19)}{21}}} \\\\[2ex]\n&= \\frac{-.08}{.105} \\\\[2ex]\n&= -0.762\n\\end{split}\n\\]\nThe z-value indicates how many standard errors the sample difference is from the hypothesized difference of 0, In our case, the difference in sample proportions we observed in the data was \\(-.08\\). (The negative value just tells us that the Bachelorette group has a higher proportion still together with their selected suitor.) This difference is 0.762 standard errors below the hypothesized difference of 0. We can evaluate this in the z-distribution. (Remember the z-distribution is a normal distribution that has a mean of 0 and a standard deviation of 1.)\nThe z-distribution is shown in Figure¬†15.1. A vertical line is shown at the observed z-value of \\(-0.762\\). The area under the curve associated with the pvalue for the alternative hypothesis that the difference is not equal to 0 is also shown.\n\n\n\n\n\n\n\n\nFigure¬†15.1: Density plot of the z-distribution.\n\n\n\n\n\nIn practice, we will use the prop_test() function from the {mosaic} package to carry out the two-sample z-test and compute the p-value. This function takes:\n\nA formula using the tilde (~) , that specifies the attribute to carry out the two-sample z-test on. We also need to specify the level of the attribute we want to compute the sample proportion for using == and then giving the exact name for that level inside quotation marks. Finally, we also use the vertical bar (|) to indicate the attribute we want to compare.\ndata= specifying the name of the data object,\nalternative= indicating one of three potential alternative hypotheses: \"less\", \"greater\", or \"two.sided\" (not equal). Note that these need to be enclosed in quotation marks.\ncorrect=FALSE indicating that we want to do the calculation of the z-value without a correction for continuity which will mimic the formula.\n\nTo carry out the two-sample z-test to compare the proportion of Bachelor and Bachelorette contestants still together with their selected suitor, we will use the following syntax. Note that in the formula we also indicate that we want to compute the sample proportion for the \"Yes\" values of the still_together attribute. We assign the results of this z-test to an object (in this case, I called it my_z).\n\n# Two-sample z-test\nmy_z &lt;- prop_test(\n  ~still_together == \"Yes\" | show,\n  data = bachelor,\n  alternative = \"two.sided\",\n  correct = FALSE\n  )\n\nError: still_together == \"Yes\" has 3 levels (including NA).  Only 2 are allowed.\n\n\nIf we try running this syntax we get an error message: ‚ÄúError: still_together == \"Yes\" has 3 levels (including NA).  Only 2 are allowed.‚Äù As we stated earlier, this function cannot handle missing values in the data. The error message is saying that the NA values are being treated as a separate category and the function can only handle dichotomous attributes. There are a couple of options for dealing with the missing data:\n\nRemove the cases with missing values from the data.\nEnter the counts in the prop_test() function manually.\n\nIf you decide to remove cases from the data, you can open the CSV file using Excel or some other spreadsheet program, delete the two cases that are missing data in the still_together attribute, and save the data file (be sure you save it as a CSV file). Then you would need to import the edited data and use that data to carry out the two-sample z-test.\nThe second option is to enter the information for the two-sampe z-test into the prop_test() function manually. To do this we need the counts of the Bachelor and Bachelorette contestants that are still together with their selected suitors (\\(n=3\\) and \\(n=4\\), respectively) and the total count of Bachelor and Bachelorette contestants (\\(n=27\\) and \\(n=21\\), respectively). Note that these counts are available in the contingency table! We enter these values into the arguments:\n\nx= takes a vector of the counts that are still together in the c() function\nn= takes a vector of the total Bachelor and Bachelorette counts in the c() function\n\nBecause we are enter in the counts manually, we do not include a formula or data= argument. The syntax to enter the counts manually in the prop_test() function is:\n\n# Two-sample z-test with counts entered manually\nmy_z &lt;- prop_test(\n  x = c(3, 4),\n  n = c(27, 21),\n  alternative = \"two.sided\",\n  correct = FALSE\n  )\n\nWarning in stats::prop.test(x = x, n = n, p = p, alternative = alternative, :\nChi-squared approximation may be incorrect\n\n\nThen we can use the z_results() and plot_z_dist() functions (both from the {educate} package) to show the results of the z-test and plot the z-distribution along with the observed z-value and shaded area associated with the p-value.\n\n# Plot z-distribution, observed z-value and shaded p-value\nplot_z_dist(my_z)\n\n# Show z-test results\nz_results(my_z)\n\n\n--------------------------------------------------\n2-sample test for equality of proportions without continuity correction\n--------------------------------------------------\n\nH[0]: pi_1 = pi_2\nH[A]: pi_1 ‚â† p1_2\nz = -0.7728597\np = 0.4396054\n\n--------------------------------------------------\n\n\n\n\n\n\n\n\nFigure¬†15.2: Density plot of the z-distribution of the difference in sample proportions based on the thought experiment underlying a hypothesis test assuming that the difference in proportion of Bachelor and Bachelorette contestants who are still together with their selected suitor is 0. The red vertical line represents the observed z-value of -.772. The shaded area under the curve to the left of -.772 and to the right of +.772 shows the associated p-value of .440 that corresponds to the probability of seeing an observed result of -.772 (or a result more extreme than that) if the null hypothesis that the two population proportions are equal is true.\n\n\n\n\n\nBased on the p-value, and using an \\(\\alpha\\)-value of .05, we would fail to reject the null hypothesis. This suggests it is likely that the proportion of Bachelor contestants who are still together with their selected suitor is NOT different than the proportion of Bachelorette contestants who are still together with their selected suitor.",
    "crumbs": [
      "Comparing Two Groups",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Two-Sample z-Test: Evaluating Differences in Proportions From Two Samples</span>"
    ]
  },
  {
    "objectID": "05-03-two-sample-test-proportions.html#assumptions-for-the-two-sample-z-test",
    "href": "05-03-two-sample-test-proportions.html#assumptions-for-the-two-sample-z-test",
    "title": "15¬† Two-Sample z-Test: Evaluating Differences in Proportions From Two Samples",
    "section": "15.2 Assumptions for the Two-Sample z-Test",
    "text": "15.2 Assumptions for the Two-Sample z-Test\nWhether or not the p-value we obtain from the z-test is accurate depends on the following set of statistical assumptions:\n\nThe values in the two populations both follow a binomial distribution. This is true so long as there are only two values the attribute can take on (e.g., ‚ÄúYes‚Äù or ‚ÄúNo‚Äù) for each group being compared.\nThe values in the population are independent from each other.\nFor both groups, the quantities \\(n(\\hat{p})\\) and \\(n(1-\\hat{p})\\) are both greater than 10, where n is the sample size used in the group and \\(\\hat{p}\\) is the sample proportion value.\n\nTo evaluate the first assumption that the distribution of values in the population follow a binomial distribution, we only need to confirm that the population only has two values. In our example, this is true; the only two values a case can have is ‚ÄúYes‚Äù (they are still together with their selected suitor) or ‚ÄúNo‚Äù (they are not still together with their selected suitor).\nWe will evaluate the independence assumption by referring to the study design. In our example, the cases in the data do not constitute a random sample of all Bachelor and Bachelorettes. We also have not randomly assigned some people to be the Bachelor and others to be a Bachelorette. Because we have not employed randomness in the study design to select cases or assign them to groups, we need to make a logical argument that knowing a Bachelor‚Äôs (or Bachelorette‚Äôs) value on the still_together attribute does not give us any information about any other Bachelor‚Äôs (or Bachelorette‚Äôs) value on the still_together attribute. Without additional data it is difficult to know, so we could argue that the independence assumption seems tenable.1\nLastly we compute the quantities in the third assumption and check that they are all greater than 10.\n\\[\n\\begin{split}\n\\mathbf{Bachelor}\\\\\nn(\\hat{p}) &= 27(.11) \\\\[1ex]\n&= 2.97 \\\\[3ex]\nn(1-\\hat{p}) &= 27(1 - .11) \\\\[1ex]\n&= 24.03 \\\\[7ex]\n\\mathbf{Bachelorette}\\\\\nn(\\hat{p}) &= 21(.19) \\\\[1ex]\n&= 3.99 \\\\[3ex]\nn(1-\\hat{p}) &= 21(1 - .19) \\\\[1ex]\n&= 17.01\n\\end{split}\n\\] This assumption does not seem tenable since two of the four values were less than 10. This violation may indicate that the p-value computed might not be accurate.\n\nThere are methods we can use to get a more accurate p-value when assumptions are violated. These methods can be Googled or you can learn about them in other courses (e.g., EPSY 8251 and 8252).",
    "crumbs": [
      "Comparing Two Groups",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Two-Sample z-Test: Evaluating Differences in Proportions From Two Samples</span>"
    ]
  },
  {
    "objectID": "05-03-two-sample-test-proportions.html#footnotes",
    "href": "05-03-two-sample-test-proportions.html#footnotes",
    "title": "15¬† Two-Sample z-Test: Evaluating Differences in Proportions From Two Samples",
    "section": "",
    "text": "Just remember other scholars might argue that the population values are not independent.‚Ü©Ô∏é",
    "crumbs": [
      "Comparing Two Groups",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Two-Sample z-Test: Evaluating Differences in Proportions From Two Samples</span>"
    ]
  },
  {
    "objectID": "05-04-errors.html",
    "href": "05-04-errors.html",
    "title": "16¬† Errors in Hypothesis Testing",
    "section": "",
    "text": "16.1 Type I and Type II Errors\nThe conclusions we draw about hypotheses are based on a p-value. Remember the p in p-value stands for probability. That means the conclusions are probabilistic in nature. For example, in our teen sleep case study the p-value was .0000000000000433. If we were interpreting this value, we would say:\nFrom this we reasoned that because seeing the sample mean we observed was so unlikely that the null hypothesis was probably not true; we rejected the null hypothesis. In reality, however, this decision to reject might be wrong. It may be that the null hypothesis is true, and we just observed something that was a really, really low probability event. After all, the probability of seeing such an extreme sample mean did not have a zero probability.",
    "crumbs": [
      "Comparing Two Groups",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Errors in Hypothesis Testing</span>"
    ]
  },
  {
    "objectID": "05-04-errors.html#type-i-and-type-ii-errors",
    "href": "05-04-errors.html#type-i-and-type-ii-errors",
    "title": "16¬† Errors in Hypothesis Testing",
    "section": "",
    "text": "If the null hypothesis is true, the probability of seeing a sample mean at least as extreme as 7.5 (the mean we observed in the data), is .0000000000000433.\n\n\n\n\n16.1.1 Type I Errors\nAnytime we reject the null hypothesis in a hypothesis test, we might make what is called a Type I error.1 A Type I error is rejecting the null hypothesis when it is, in fact, true. In our example this would mean concluding that the average amount of sleep for all teens was less than 9 hours, when in fact it really wasn‚Äôt.\nUnfortunately, when we reject the null hypothesis, we can never know if we made a Type I error or not. In order to determine that, you would actually need to know what the population mean was, in which case you wouldn‚Äôt have to test what it was. While we can‚Äôt know if we made a Type I error, we can set the probability of making a Type I error. The probability of making a Type I error is called \\(\\alpha\\) (alpha)2 and is the value we compare our p-value to. In the social sciences, this probability is almost always .05. That is why we compare our p-value to .05 in order to decide whether to reject the null hypothesis.\n\n\n\n16.1.2 Type II Errors\nA Type II error is failing to reject the null hypothesis when it is, in fact, false. For example, if we had found a p-value in the teen sleep case study that was bigger than .05, we would have failed to reject the null hypothesis. In this case, our conclusion would have been that the average amount of sleep for all teens was NOT less than 9 hours. Once again, once you have drawn a conclusion about the null hypothesis, there is some probability that the conclusion you drew was wrong.\nSimilar to our potential for making an error when we reject a null hypothesis, we can never know for sure whether we have made a Type II error or not after we fail to reject a null hypothesis. We can only know the probability of making a Type II error which is conventionally termed \\(\\beta\\) (beta)3. The value of \\(\\beta\\) is somewhat complex, but has an inverse relationship with the value of \\(\\alpha\\), such that as the value of \\(\\alpha\\) gets smaller, the value of \\(\\beta\\) gets larger, and vice versa. This means that if you make \\(\\alpha\\) smaller (to protect against making a Type I error), you will make the probability of making a Type II error larger!\n\nThe type of error you can make is completely dependent on the conclusion you draw about the null hypothesis. For example, if we reject the null hypothesis, the only type of error you can make is a Type I error. You cannot make a Type II error since that requires failing to reject the null hypothesis. That is, when you reject the null hypothesis, the probability of making a Type II error is 0. Similarly, if you fail to reject the null hypothesis, then you cannot make a Type I error; the probability of making a Type I error after you fail to reject the null hypothesis is 0.\n\n\n\n\n16.1.3 Some Practice with Type I and Type II Errors\n\nYour Turn\nIn the continuous assessment case study from Chapter 10, we evaluated the following set of hypotheses about whether, on average, Ethiopian primary school teachers agree/disagree with the statement that they assess students‚Äô prior knowledge:\n\\[\n\\begin{split}\nH_0: \\mu = 2.5 \\\\[1ex]\nH_A: \\mu \\neq 2.5\n\\end{split}\n\\]\nBased on the results of the one-sample t-test, \\(t(29) = -0.41\\), \\(p = 0.687\\), which type of error could we have made if we were using an \\(\\alpha\\)-value of .05? Explain.\n\nShow/Hide Solution\n\n\nUsing an \\(\\alpha\\)-value of .05, we would have failed to reject the null hypothesis since our p-value was bigger than .05. Because we failed to reject the null hypothesis, the only type of error we can make is a Type II error.\n\nUsing the context of the problem (i.e., survey responses of the assessment of prior knowledge) and the hypotheses tested, what does it mean to make this type of error?\n\nShow/Hide Solution\n\n\nA Type II error in this context indicates that we come to the conclusion that Ethiopian primary school teachers neither agree nor disagree with the statement that they assess students‚Äô prior knowledge on average, but in reality they actually do agree or disagree with that statement, on average.\n\nIn the house prices case study from Chapter 10, we evaluated the following set of hypotheses about whether, on average, houses near the University of Minnesota campus more expensive than $322.46k (the average price of a single-family house in Minneapolis as of May 2023).\n\\[\n\\begin{split}\nH_0: \\mu = 322.46 \\\\[1ex]\nH_A: \\mu &gt; 322.46\n\\end{split}\n\\]\nBased on the results of the one-sample t-test, \\(t(14) = 3.12\\), \\(p = 0.004\\), which type of error could we have made if we were using an \\(\\alpha\\)-value of .01? Explain.\n\nShow/Hide Solution\n\n\nUsing an \\(\\alpha\\)-value of .01, we would have rejected the null hypothesis since our p-value was smaller than .05. Because we rejected the null hypothesis, the only type of error we can make is a Type I error.\n\nUsing the context of the problem (i.e., house prices near the UMN campus) and the hypotheses tested, what does it mean to make a this type of error?\n\nShow/Hide Solution\n\n\nA Type I error in this context indicates that we rejected the null hypothesis that the average price of a house near the UMN campus is not more than $322.46k, but in reality it is not.\n\nIn the case study from Chapter 13, we evaluated the following set of hypotheses about whether the average decline in IQ scores for all persistent marijuana users that became dependent as adults is the same as the average decline in IQ scores for all persistent marijuana users that became dependent as teens.\n\\[\n\\begin{split}\nH_0: \\mu_{\\text{Adult-onset}} = \\mu_{\\text{Teen-onset}} \\\\[1ex]\nH_0: \\mu_{\\text{Adult-onset}} &gt; \\mu_{\\text{Teen-onset}}\n\\end{split}\n\\] Based on the results of the two-sample t-test, \\(t(35) = 2.47\\), \\(p = 0.009\\), which type of error could we have made if we were using an \\(\\alpha\\)-value of .05? Explain. Also, using the context of the problem and the hypotheses tested, what does it mean to make a this type of error?\n\nShow/Hide Solution\n\n\nUsing an \\(\\alpha\\)-value of .05, we reject the null hypothesis since our p-value was smaller than .05, which means the only type of error we can make is a Type I error.\nA Type I error in this context indicates that we decided the average decline in IQ scores for all persistent marijuana users that became dependent as adults is greater than the average decline in IQ scores for all persistent marijuana users that became dependent as teens, but in reality it not.\n\nIn the case study from Chapter 15, we evaluated the following set of hypotheses about whether the proportion of Bachelor contestants that are still together with the suitor they chose is different than the proportion of Bachelorette contestants that are still together with the suitor they chose.\n\\[\n\\begin{split}\nH_0: \\pi_{\\text{Bachelor}} = \\pi_{\\text{Bachelorette}} \\\\[1ex]\nH_A: \\pi_{\\text{Bachelor}} \\neq \\pi_{\\text{Bachelorette}}\n\\end{split}\n\\]\nBased on the results of the two-sample z-test, \\(z = -.772\\), \\(p = 0.440\\), which type of error could we have made if we were using an \\(\\alpha\\)-value of .05? Explain. Also, using the context of the problem and the hypotheses tested, what does it mean to make a this type of error?\n\nShow/Hide Solution\n\n\nUsing an \\(\\alpha\\)-value of .05, we failed to reject the null hypothesis since our p-value was larger than .05, which means the only type of error we can make is a Type II error.\nA Type II error in this context indicates that we decided the null hypothesis that the proportion of Bachelor and Bachelorette contestants that are still together with the suitor they chose is NOT different, but in reality it is different.",
    "crumbs": [
      "Comparing Two Groups",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Errors in Hypothesis Testing</span>"
    ]
  },
  {
    "objectID": "05-04-errors.html#references",
    "href": "05-04-errors.html#references",
    "title": "16¬† Errors in Hypothesis Testing",
    "section": "16.2 References",
    "text": "16.2 References",
    "crumbs": [
      "Comparing Two Groups",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Errors in Hypothesis Testing</span>"
    ]
  },
  {
    "objectID": "05-04-errors.html#footnotes",
    "href": "05-04-errors.html#footnotes",
    "title": "16¬† Errors in Hypothesis Testing",
    "section": "",
    "text": "Conventionally, we use Roman numerals to indicate the different types of errors we can make in hypothesis testing.‚Ü©Ô∏é\nFun Fact: \\(\\alpha\\) is the first letter in the Greek alphabet (equivalent to the Roman letter ‚Äúa‚Äù) so that is why it is associated with the first type (i.e., Type I) error.‚Ü©Ô∏é\nFun Fact: \\(\\beta\\) is the second letter in the Greek alphabet (equivalent to the Roman letter ‚Äúb‚Äù) so that is why it is associated with the second type (i.e., Type II) error.‚Ü©Ô∏é",
    "crumbs": [
      "Comparing Two Groups",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Errors in Hypothesis Testing</span>"
    ]
  },
  {
    "objectID": "06-00-study-design.html",
    "href": "06-00-study-design.html",
    "title": "Study Design",
    "section": "",
    "text": "The design of a study plays a large role in the statistical inferences that we can draw. Two really important aspects of a study‚Äôs design relate to how the observations in our sample data were selected from the larger population and how those selected cases are then assigned to groups or conditions. In this unit you will learn about how these aspects of study design impact the validity of the inferences we draw and how statistical bias might distort our inferences.",
    "crumbs": [
      "Study Design"
    ]
  },
  {
    "objectID": "06-01-generalization.html",
    "href": "06-01-generalization.html",
    "title": "17¬† Random Sampling and Generalization",
    "section": "",
    "text": "17.1 Generalization\nIn statistical inference, generalization (a.k.a., external validity) refers to the process of using sample data to draw conclusions about the larger population from which the sample was drawn. The sample data provides statisticians with an estimate of the exact ‚Äòtruth‚Äô about the population. For example, data collected from 1,000 Americans about their voting preferences may be used to infer the voting preferences of Americans more generally. Statisticians are typically concerned with making inferences about some population parameter using information obtained from a sample (i.e., from a sample statistic).\nHow useful is a sample statistic when it comes to estimating a population parameter? Can we draw reasonable inference about a population from sample data? This question is at the heart of weighing evidence about external validity. External validity is the degree to which generalizations to the larger population are accurate and meaningful.\nThere are two statistical aspects we need to consider when we evaluate evidence for generalization: sampling variation and bias. Sampling variation is the idea that statistics from different samples vary. For example, to use the earlier example, different samples of 1,000 Americans would produce different estimates of voting preferences. This variation needs to be accounted for when we test hypotheses about or provide estimates for population parameters. In hypothesis testing, we account for this by quantifying the sampling variation into the standard error and incorporating that into the test statistic (e.g., the z- or t-value).\nThe second statistical characteristic we need to attend to is statistical bias. Statistical bias is when sample statistics differ systematically from the population parameter. The key here is the word ‚Äúsystematically‚Äù. This implies that there is something in the underlying process (aside from random variation) that is affecting the estimation process.",
    "crumbs": [
      "Study Design",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Random Sampling and Generalization</span>"
    ]
  },
  {
    "objectID": "06-01-generalization.html#statistical-bias",
    "href": "06-01-generalization.html#statistical-bias",
    "title": "17¬† Random Sampling and Generalization",
    "section": "17.2 Statistical Bias",
    "text": "17.2 Statistical Bias\nTo help you understand the idea of statistical bias, imagine a person, Arthur Dent, has lost his keys. The actual location of the keys, the Library, is akin to the population parameter. Arthur believes he lost his keys at the Supermarket and searches several places around the Supermarket. The locations where Arthur searches are like sample statistics.\nThe visual in Figure¬†17.1 is a metaphor for the concept of statistical bias. Arthur‚Äôs search locations (sample statistics) are systematically in the wrong place. On average, where Arthur searched (the middle of the yellow circle) is not the actual location of the keys.\n\n\n\n\n\n\n\n\nFigure¬†17.1: This figure is a metaphor for statistical bias.\n\n\n\n\n\nCompare this with Arthur‚Äôs search locations in Figure¬†17.2. In this picture, on average, where Arthur searched is the location of the actual keys. The visual in Figure¬†17.2 is a metaphor for what is referred to as ‚Äúunbiasedness‚Äù.\n\n\n\n\n\n\n\n\nFigure¬†17.2: This figure is a metaphor for unbiasedness.\n\n\n\n\n\nThere are a couple of other concepts that this metaphor can help us think about:\n\nEven in Figure¬†17.2, none of the actual search locations were right at the keys. Some of the locations were too far to the left of the keys, and others were too far to the right of the keys. However, ON AVERAGE, the search locations ‚Äúfound‚Äù the keys. The way we define unbiased is that the AVERAGE of the statistics is equal to the value of the population parameter. Similarly, the way we define bias is that the AVERAGE of the statistics is NOT equal to the value of the population parameter.\nSecondly, bias (or unbiasedness) is a property of the sampling method not of the statistic. The reason the search locations were not in the right place is because the method Arthur used to pick the search locations was biased. He thought he lost his keys in the Supermarket, so that is where he looked.",
    "crumbs": [
      "Study Design",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Random Sampling and Generalization</span>"
    ]
  },
  {
    "objectID": "06-01-generalization.html#sampling-methods-and-bias",
    "href": "06-01-generalization.html#sampling-methods-and-bias",
    "title": "17¬† Random Sampling and Generalization",
    "section": "17.3 Sampling Methods and Bias",
    "text": "17.3 Sampling Methods and Bias\nThe key to statistical generalization is that the sample needs to be selected using an unbiased sampling method. There are several different sampling methods that are unbiased, but they all employ random sampling. Random sampling uses chance to select the sampling units (i.e., cases) from the larger population. When random sampling has been employed in a study, the unbiasedness of the sampling method is strong evidence for generalizations made to the larger population.\nThere are also several biased methods of selecting a sample. Convenience samples, snowball samples, and volunteer or self-selected samples are all examples of samples that use a biased method of sampling. These samples do not typically represent the population on all characteristics. When there is sampling bias in your study, the generalizability of any findings is limited because characteristic in the sample may be systematically different from the population. Unfortunately the way a biased sample differs from the population is often unclear which makes it difficult to know who any findings can be generalized to.",
    "crumbs": [
      "Study Design",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Random Sampling and Generalization</span>"
    ]
  },
  {
    "objectID": "06-01-generalization.html#choosing-a-simple-random-sample",
    "href": "06-01-generalization.html#choosing-a-simple-random-sample",
    "title": "17¬† Random Sampling and Generalization",
    "section": "17.4 Choosing a Simple Random Sample",
    "text": "17.4 Choosing a Simple Random Sample\nTo draw a simple random sample we need a list of EVERY sampling unit (i.e., case) in the population. This list is called the sampling frame. (Obtaining a sampling frame can be very difficult. Try obtaining a list of everyone who lives in the United States!) Then we employ randomness to draw out sampling units, with the caveat that each unit in the sampling frame has an equal chance of being drawn.\nIn R, there are several ways to draw a random sample. One method is to create a vector of the unts in the sampling frame and then use the sample() function to draw the random sample. (We used this function in Chapter 8 when we were bootstrapping the SE for use in the one-sample t-test.) As a reminder, the sample() function takes as arguments:\n\nThe vector of units in the sampling frame (i.e., the population).\nThe argument size= indicates the number of sampling units to be sampled (i.e., the sample size).\nThe argument replace= indicates whether the sampling units should be sampled with replacement (replace=TRUE) or without replacement (replace=FALSE).\n\nBelow is some syntax that could be used to sample 5 random letters from the English alphabet. (Recall that the set.seed() function makes it so that the random selection is repeatable.)\n\n# Create a vector of the sampling frame\nalphabet &lt;- c(\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \n              \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \n              \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\")\n\n# View sampling frame\nalphabet\n\n [1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\" \"G\" \"H\" \"I\" \"J\" \"K\" \"L\" \"M\" \"N\" \"O\" \"P\" \"Q\" \"R\" \"S\"\n[20] \"T\" \"U\" \"V\" \"W\" \"X\" \"Y\" \"Z\"\n\n# Draw n=5 letters without replacement\nset.seed(42)\nmy_sample &lt;- sample(alphabet, size = 5, replace = FALSE) \n\n# View sample\nmy_sample\n\n[1] \"Q\" \"E\" \"A\" \"J\" \"D\"\n\n\nThere are also several other R functions that draw random samples. For example, rnorm() is used to draw a random sample from a normally distributed population with a particular mean and standard deviation. In this class, it isn‚Äôt as important that you know HOW to draw a random sample, but rather that you understand WHY a random sampling is the method of sampling that is the gold standard when it comes to making generalizations from a sample. That being said, it is also important to understand that even if random sampling is employed, there can still be sampling bias. Things like non-response and recall bias can lead to biased findings despite initially choosing the sample randomly.",
    "crumbs": [
      "Study Design",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Random Sampling and Generalization</span>"
    ]
  },
  {
    "objectID": "06-02-cause-and-effect.html",
    "href": "06-02-cause-and-effect.html",
    "title": "18¬† Random Assignment and Causal Inferences",
    "section": "",
    "text": "18.1 Causal Inference\nCausal inference (a.k.a., internal validity) refers to the process of drawing cause-and-effect conclusions. For example, suppose you were studying the effects of a new drug that was thought to reduce cholesterol. You might give this drug to some patients with high cholesterol (the treatment group) and not to others (the control group). Then, the average cholesterol for these two groups might be compared using a two-sample t-test. Imagine that the results of this analysis indicated that the treatment group had a lower average cholesterol level, with a small p-value. Could we attribute the lower cholesterol level, on average, to the effects of the drug? The answer to that question often depends on how the participants in the trial were assigned to the treatment and control groups.",
    "crumbs": [
      "Study Design",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Random Assignment and Causal Inferences</span>"
    ]
  },
  {
    "objectID": "06-02-cause-and-effect.html#making-a-causal-attribution",
    "href": "06-02-cause-and-effect.html#making-a-causal-attribution",
    "title": "18¬† Random Assignment and Causal Inferences",
    "section": "18.2 Making a Causal Attribution",
    "text": "18.2 Making a Causal Attribution\nTo attribute a causal relationship, there are three criteria a researcher needs to establish:\n\nTemporal Precedence: The cause needs to happen BEFORE the effect.\nCovariation of the Cause and Effect: There needs to be a relationship between the cause and effect (i.e., a statistically discernible difference between treatment and control).\nNo Plausible Alternative Explanations: ALL other possible explanations for the effect need to be ruled out.\n\nIn the hypothetical drug study we have temporal precedence. The presumed effect (lowering of cholesterol level) happened AFTER the presumed cause (taking the drug). We also have the second criteria since the two-sample t-test resulted in a statistically discernible difference in the average cholesterol level between the treatment and control groups. The third criteria, however, is very difficult to establish. For example, maybe the members of the treatment group had a different exercise regime or different dietary habits than the control group and it was those factors, not the drug, that resulted in the lower average cholesterol level.\nTo rule out ALL other possible explanations for the effect, the control group and the treatment group need to be ‚Äúidentical‚Äù with respect to every possible characteristic (aside from the treatment) that could explain differences. This way the only characteristic that will be different is that the treatment group gets the treatment and the control group does not. By design, if there are differences in the outcome, then it must be attributable to the treatment, because the other possible explanations are ruled out.\nSo, the key is to make the control and treatment groups ‚Äúidentical‚Äù when you are forming them. One thing that makes this task (slightly) easier is that they do not have to be exactly identical, only probabilistically equivalent. This means, for example, that if you were matching groups on age that you don‚Äôt need the two groups to have identical age distributions; they would only need to have roughly the same AVERAGE age. Here roughly means ‚Äúthe average ages should be the same within what we expect because of sampling error.‚Äù While this makes it ‚Äúeasier‚Äù to create the groups, it is still an almost impossible challenge since participants still need to be assigned so that the groups, on average, are the same‚Ä¶for EVERY POSSIBLE CHARCTERISTIC that could explain differences in the outcome. Zoinks!1\nIt turns out that creating probabilistically equivalent groups is a really difficult problem. One method that works pretty well for doing this is to randomly assign participants to the groups. This works best when you have large sample sizes, but even with small sample sizes random assignment has the advantage of at least removing the systematic bias between the two groups (any differences are due to chance and will probably even out between the groups). As Wikipedia‚Äôs page on random assignment points out,\n\nRandom assignment of participants helps to ensure that any differences between and within the groups are not systematic at the outset of the experiment. Thus, any differences between groups recorded at the end of the experiment can be more confidently attributed to the experimental procedures or treatment. ‚Ä¶ Random assignment does not guarantee that the groups are matched or equivalent. The groups may still differ on some preexisting attribute due to chance. The use of random assignment cannot eliminate this possibility, but it greatly reduces it.\n\nIt is because of this that using random assignment to assign participants to the treatment and control groups is the gold standard when it comes to drawing causal inferences. The random assingment to groups helps meet the third criteria that ALL other possible explanations for the effect, aside from the treatment being tested, can be ruled out since the control and treatment groups are probabilistically equivalent.",
    "crumbs": [
      "Study Design",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Random Assignment and Causal Inferences</span>"
    ]
  },
  {
    "objectID": "06-02-cause-and-effect.html#randomly-assigning-members-of-a-sample",
    "href": "06-02-cause-and-effect.html#randomly-assigning-members-of-a-sample",
    "title": "18¬† Random Assignment and Causal Inferences",
    "section": "18.3 Randomly Assigning Members of a Sample",
    "text": "18.3 Randomly Assigning Members of a Sample\nTo assign members of a sample to different groups, we can again use the sample() function. We will provide this function a vector of the members of the sample. We will also not include the size= argument and use the argument replace=FALSE. This will randomly order all of the members in the given vector. Then the first half of the elements can be assigned to treatment and the last half to control. (There are also other ways to do this.)\nBelow is some syntax that could be used to assign 10 participants to groups. (Again, we will use the set.seed() function to make the results from sample() repeatable.)\n\n# Create a vector of the participants in the sample\nmy_sample &lt;- c(\"Participant 1\", \"Participant 2\", \"Participant 3\", \"Participant 4\", \n              \"Participant 5\", \"Participant 6\", \"Participant 7\", \"Participant 8\", \n              \"Participant 9\", \"Participant 10\")\n\n# View sample\nmy_sample\n\n [1] \"Participant 1\"  \"Participant 2\"  \"Participant 3\"  \"Participant 4\" \n [5] \"Participant 5\"  \"Participant 6\"  \"Participant 7\"  \"Participant 8\" \n [9] \"Participant 9\"  \"Participant 10\"\n\n# Assign participants in a random order\n# First 5 will be treatment\n# Second 5 will be control\nset.seed(100)\nsample(my_sample, replace = FALSE) \n\n [1] \"Participant 10\" \"Participant 7\"  \"Participant 6\"  \"Participant 3\" \n [5] \"Participant 1\"  \"Participant 2\"  \"Participant 5\"  \"Participant 9\" \n [9] \"Participant 4\"  \"Participant 8\" \n\n\nBased on this ordering, Participants 10, 7, 6, 3, and 1 will be assigned to the treatment group, and Participants 2, 5, 9, 4, and 8 will be assigned to the control group.2\nAs with random sampling, in this class, it isn‚Äôt as important that you know HOW to use R functions to randomly assign participants, but rather that you understand WHY random assignment is the method of assigning subjects that is the gold standard when it comes to making causal inferences. That being said, it is also important to understand that even if random assignment is employed, there can still be problems with ensuring probabilistic equivalence. Things like participant dropout can make causal inference problematic despite initially assigning groups randomly.",
    "crumbs": [
      "Study Design",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Random Assignment and Causal Inferences</span>"
    ]
  },
  {
    "objectID": "06-02-cause-and-effect.html#generalizations-and-causal-inference",
    "href": "06-02-cause-and-effect.html#generalizations-and-causal-inference",
    "title": "18¬† Random Assignment and Causal Inferences",
    "section": "18.4 Generalizations and Causal Inference",
    "text": "18.4 Generalizations and Causal Inference\nIt is important to differentiate between the drawing of causal inferences and making generalizations. For example, we might be able to attribute the lower cholesterol in our hypothetical study to the taking of the drug, but not be able to generalize the effects to the larger population. That is because the question of generalization boils down to how the sample was selected from the larger population, while the question of cause boils down to how the sample participants are assigned to treatment and control groups. Table¬†18.1 shows four possible study designs and the scope of inferences that are feasible given those designs.\n\n\n\n\nTable¬†18.1: Four potential study designs researchers could have and the scope of inferences that they could make based on the study design.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRandom Sample\nRandom Assignment\nScope of Inferences\n\n\n\n\n‚úî\n\nGeneralizable to population\n\n\n\n‚úî\nCause-and-effect, but not generalizable to population\n\n\n‚úî\n‚úî\nCause-and-effect and generalizable to population\n\n\n\n\nNo cause-and-effect and not generalizable to population\n\n\n\n\n\n\n\n\n\n\n\nAs you read research articles and consider the evidence presented in those articles, it is important to take into account the design of the study. How was the sample selected? If there are groups being compared, how were participants assigned to groups? These aspects of the study are as important, if not more important, than statistical significance when it comes to the type of inferences one can make. Because they are so important to the conclusions of a study, most research will describe these aspects of the study‚Äôs design. If a study does not describe these aspects, it should be assumed that random sampling and assignment were not employed. And while this doesn‚Äôt necessarily make the study‚Äôs results unimportant, it should give you pause as a researcher and reduce the weight of evidence the study gives to the broader scientific corpus.",
    "crumbs": [
      "Study Design",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Random Assignment and Causal Inferences</span>"
    ]
  },
  {
    "objectID": "06-02-cause-and-effect.html#footnotes",
    "href": "06-02-cause-and-effect.html#footnotes",
    "title": "18¬† Random Assignment and Causal Inferences",
    "section": "",
    "text": "According to Wiktionary the earliest usage of the work ‚Äúzoinks‚Äù was by Norville ‚ÄúShaggy‚Äù Rogers on the show Scooby-Doo.‚Ü©Ô∏é\nYou could also choose other ways of assigning the participants based on the random order. For example every other participant could be assigned to the treatment group. The key is you decide how this will be done before you see the results of the sample() function.‚Ü©Ô∏é",
    "crumbs": [
      "Study Design",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Random Assignment and Causal Inferences</span>"
    ]
  },
  {
    "objectID": "07-00-effect-size.html",
    "href": "07-00-effect-size.html",
    "title": "Effect Size",
    "section": "",
    "text": "References",
    "crumbs": [
      "Effect Size"
    ]
  },
  {
    "objectID": "07-00-effect-size.html#references",
    "href": "07-00-effect-size.html#references",
    "title": "Effect Size",
    "section": "",
    "text": "Cohen, J. (1990). Things I have learned (so far). American Psychologist, 45, 1304‚Äì1312.\n\n\nCohen, J. (1994). The Earth is round (\\(p&lt;.05\\)). American Psychologist, 49, 997‚Äì1003.\n\n\nKirk, R. E. (1995). Experimental design: Procedures for the behavioral sciences (3rd ed.). Brooks/Cole.\n\n\nKirk, R. E. (1996). Practical significance: A concept whose time has come. Educational and Psychological Measurement, 56, 746‚Äì759.\n\n\nKirk, R. E. (2001). Promoting good statistical practices: Some suggestions. Educational and Psychological Measurement, 61(2), 213‚Äì218.\n\n\nThompson, B. (1996). AERA editorial polices regarding statistical significance testing: Three suggested reforms. Educational Researcher, 25(2), 26‚Äì30.\n\n\nThompson, B. (2007). Effect sizes, confidence intervals, and confidence intervals for effect sizes. Psychology in the Schools, 44(5), 423‚Äì432.",
    "crumbs": [
      "Effect Size"
    ]
  },
  {
    "objectID": "07-01-confidence-intervals.html",
    "href": "07-01-confidence-intervals.html",
    "title": "19¬† Confidence Intervals",
    "section": "",
    "text": "19.1 House Prices (Revisited)\nIn the house prices case study from Chapter¬†10, we evaluated whether the average price of a house near the University of Minnesota was different than $322.46k, the price of a typical single-family house in Minneapolis, by testing the following hypotheses:\n\\[\n\\begin{split}\nH_0: \\mu = 322.46 \\\\[1ex]\nH_A: \\mu \\neq 322.46\n\\end{split}\n\\] The results of the one-sample t-test were: \\(t(14)=3.12\\), \\(p = .008\\). This small p-value led us to reject the null hypothesis, indicating that the empirical evidence was consistent with the average cost of a house near the UMN campus being different than the average cost of a house in Minneapolis more broadly.",
    "crumbs": [
      "Effect Size",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Confidence Intervals</span>"
    ]
  },
  {
    "objectID": "07-01-confidence-intervals.html#house-prices-revisited",
    "href": "07-01-confidence-intervals.html#house-prices-revisited",
    "title": "19¬† Confidence Intervals",
    "section": "",
    "text": "19.1.1 Estimating the Average Price for Houses Near the University of Minnesota\nWhile the results of the hypothesis test suggest that the average cost of a house near the UMN campus is different than the average cost of a house in Minneapolis more broadly, the results from a hypothesis tests cannot tell us (1) the direction of that difference, nor (2) how much different the average cost is. Is it more or less than $322.46k? How much more or less? These questions are natural follow-ups after carrying out a hypothesis test.\nUsing the sample evidence (e.g., sample mean), we can begin to answer this question. For example, the mean cost of a single-family house near the UMN campus was $404.97k. The sample evidence suggests that the average price of a house near the UMN campus is $82.51k higher than the average house in Minneapolis.\nThis is informative in answering our follow-up questions, but had we drawn a different sample of houses near the University of Minnesota, our estimate of the average house price would vary because of sampling error. Similar to how we accounted for sampling error in the hypothesis tests we carried out, we also need to account for it in the estimates/effect sizes that we give. To do this, we quantify the uncertainty in the estimate that is due to sampling error, and use that to produce a margin of error, which in turn is used to produce a confidence interval (CI) for the estimate by:\n\\[\n\\text{CI} = \\text{Sample Estimate} \\pm \\text{Margin of Error}\n\\] For example, if the margin of error was $10k, our confidence interval would be computed as:\n\\[\n\\begin{split}\n&404.97 \\pm 10 \\\\[2ex]\n&[394.97,~414.97]\n\\end{split}\n\\]\nThat is, the confidence interval would indicate that the average price of a single-family house near the University of Minnesota is between $394.97k and $414.97k. Adding and subtracting the margin of error to the sample estimate gives a range of values that are reasonable estimates for the average price of a single-family house near the University of Minnesota. Providing this range, rather than only a single value for the estimate, is an acknowledgement that we have uncertainty in our estimate.\nTo obtain the margin of error we quantify the amount of sampling error in the sample estimate (i.e., compute the SE for the estimate) and multiply that by two.1 That is:\n\\[\n\\text{Margin of Error} = 2 \\times \\text{SE}\n\\] Substituting this into our formula for confidence intervals, we find that a confidence interval is computed as:\n\\[\n\\text{CI} = \\text{Sample Estimate} \\pm 2 \\times \\text{SE}\n\\]\nAll confidence intervals are computed using this method. The only thing that changes is how the SE is computed. Remember from our reading in hypothesis tests, the formula for the SE depended on whether we were computing it for a single mean, the difference between two means, a single proportion, or a difference between two proportions. As a reminder, the formulas for SE are presented in Table¬†19.1.2\n\n\n\n\nTable¬†19.1: Formulas to compute the standard error (SE) for the different situations we have studied in EPsy 5261.\n\n\n\n\n\n\n\n\n\n\nSituation\nSE\n\n\n\n\nSingle Mean\n$$\\frac{\\text{SD}}{\\sqrt{n}}$$\n\n\nSingle Proportion\n$$\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}$$\n\n\nDifference in Means\n$$\\sqrt{\\frac{\\text{SD}_1^2}{n_1} + \\frac{\\text{SD}_2^2}{n_2}}$$\n\n\nDifference in Proportions\n$$\\sqrt{\\frac{\\hat{p}_1(1-\\hat{p}_1)}{n_1} + \\frac{\\hat{p}_2(1-\\hat{p}_2)}{n_2}}$$\n\n\n\n\n\n\n\n\n\n\n\nIn the house prices case study we had a single sample that we want to estimate the mean for (i.e., single mean). Thus we can compute the CI as:\n\\[\n\\begin{split}\n\\text{CI} &= \\text{Sample Estimate} \\pm 2 \\times \\text{SE} \\\\[2ex]\n&= \\text{Sample Mean} \\pm 2 \\times \\text{SE for single mean} \\\\[2ex]\n&= \\bar{x} \\pm 2 \\times \\frac{\\text{SD}}{\\sqrt{n}} \\\\[2ex]\n\\end{split}\n\\]\nSo we need to use the sample data to get the sample mean (\\(\\bar{x}\\)), the sample standard deviation (SD), and the sample size (n). Remember we can get these values by using the df_stats() function.\n\nlibrary(ggformula)\nlibrary(mosaic)\nlibrary(tidyverse)\n\n\n# Import data\nzillow &lt;- read_csv(\"https://raw.githubusercontent.com/zief0002/epsy-5261/main/data/zillow.csv\")\n\n# View data\nzillow\n\n\n  \n\n\n# Compute sample statistics\ndf_stats(~price, data = zillow)\n\n\n  \n\n\n\nThese values are:\n\n\\(\\bar{x}=404.97\\),\n\\(\\text{SD} = 102.43\\), and\n\\(n=15\\)\n\nThen we substitute those values into the formula for the CI and get:\n\\[\n\\begin{split}\n\\text{CI} &= 404.97 \\pm 2 \\times \\frac{102.43}{\\sqrt{15}} \\\\[2ex]\n&= 404.97 \\pm 2 \\times 26.45 \\\\[2ex]\n&= 404.97 \\pm 52.9 \\\\[2ex]\n&= [352.07,~457.87]\n\\end{split}\n\\]\nOur CI tells us that, based on the data, we think the average price of a single-family house near the University of Minnesota is between $352.07k and $457.87k. Using this, we can now answer our follow-up questions. Is the average price of a single-family house near the UMN more or less expensive than in Minneapolis more broadly? And by how much? Based on the CI it seems the average price of a single-family house near the University of Minnesota is higher than the average single-family house price in Minneapolis more broadly ($322.46k). It may be more expensive by as little as $29.61k and as much as $135.41k.\n\nStatistician formally interpret a CI for the mean in a very particular way. The template for this interpretation is ‚ÄúWe are X% confident that the population mean is between LL and UL.‚Äù In this template, we substitute values in for X (the confidence level), LL (the lower limit of the CI), and UL (the upper limit of the CI). In general the value for X is 95%, but you will learn more about this in Chapter 21. For our example, the formal interpretation would be:\n\nWe are 95% confident that the population mean is between $29.61k and $135.41k.\n\n\nUsing substantive knowledge, one could then make decisions about whether differences this large is meaningful or not. For example, when it comes to real estate in the Twin Cities, a difference of around $30k is not so big, but a difference of $135k is pretty large. On the other hand, for many first time home buyers, even $30k is meaningful. In order to understand whether effects are meaningful, it is necessary to contextualize them in relation to the area of research.\n\nTo reiterate some of the vocabulary, the standard error (SE) was 26.45. This quantified the amount of uncertainty in the mean estimate that is due to sampling variation. The margin of error (\\(2\\times\\text{SE}\\)) was 52.9 this increases the uncertainty due to sampling error by a factor of two, which makes it more likely that our confidence interval will include the population mean‚Äîyou will learn more about this in class. Finally, the confidence interval (CI) is \\([352.07,~457.87]\\). This range includes plausible values for the population parameter, in our case the mean, based on the data and the estimated sampling uncertainty.",
    "crumbs": [
      "Effect Size",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Confidence Intervals</span>"
    ]
  },
  {
    "objectID": "07-01-confidence-intervals.html#estimating-lead-levels-in-mn-children",
    "href": "07-01-confidence-intervals.html#estimating-lead-levels-in-mn-children",
    "title": "19¬† Confidence Intervals",
    "section": "19.2 Estimating Lead Levels in MN Children",
    "text": "19.2 Estimating Lead Levels in MN Children\nTo estimate the proportion of all Minnesota children under 6 years of age who are above the MDH reference level in 2018, we will compute a CI for a proportion rather than a mean. Below we import the data and compute the proportions. From the data codebook we also know that the sample size is 91,706.\n\n# Import data\nmn_lead &lt;- read_csv(\"https://raw.githubusercontent.com/zief0002/epsy-5261/main/data/mn-lead.csv\")\n\nRows: 91706 Columns: 2\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (1): ebll\ndbl (1): lead_level\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# View data\nmn_lead\n\n\n  \n\n\n# Compute sample proportions\ndf_stats(~ebll, data = mn_lead, props)\n\n\n  \n\n\n\n\nYour Turn\nCompute the SE for the proportion of all Minnesota children under 6 years of age who are above the MDH reference level in 2018 using the appropriate formula from Table¬†19.1.\n\nShow/Hide Solution\n\n\nIn this case study we have a single sample that we want to estimate the proportion for (i.e., single proportion). Thus we can compute the SE as:\n\\[\n\\begin{split}\n\\text{SE} &= \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} \\\\[2ex]\n&= \\sqrt{\\frac{.014(1-.014)}{91706}} \\\\[2ex]\n&= .0004\n\\end{split}\n\\]\nSince we are interested in the proportion of children above the MDH reference level, we need to use the proportion for ‚ÄúYes‚Äù (\\(\\hat{p}=.014\\)) in the formula.\n\nUse the SE you computed to compute the margin of error.\n\nShow/Hide Solution\n\n\nWe compute the margin of error as:\n\\[\n\\begin{split}\n\\text{Margin of Error} &= 2 \\times \\text{SE} \\\\[2ex]\n&= 2 \\times .0004 \\\\[2ex]\n&= .0008\n\\end{split}\n\\]\n\nUse the initial sample estimate and the margin of error you just computed to compute the CI for the proportion of all Minnesota children under 6 years of age who are above the MDH reference level in 2018\n\nShow/Hide Solution\n\n\nWe compute the CI as:\n\\[\n\\begin{split}\n\\text{Sample Estimate} &\\pm \\text{Margin of Error} \\\\[2ex]\n\\hat{p} &\\pm \\text{Margin of Error} \\\\[2ex]\n.014 &\\pm .0008 \\\\[2ex]\n&[.0132,~.0148]\n\\end{split}\n\\] Based on the CI, we think the proportion of all Minnesota children under 6 years of age who are above the MDH reference level in 2018 is between .0132 and .0148.",
    "crumbs": [
      "Effect Size",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Confidence Intervals</span>"
    ]
  },
  {
    "objectID": "07-01-confidence-intervals.html#estimating-the-difference-between-two-sample-means",
    "href": "07-01-confidence-intervals.html#estimating-the-difference-between-two-sample-means",
    "title": "19¬† Confidence Intervals",
    "section": "19.3 Estimating the Difference Between Two Sample Means",
    "text": "19.3 Estimating the Difference Between Two Sample Means\nIn Chapter¬†13 we carried out a two-sample t-test to determine whether the effects on IQ were more adverse for users who started using marijuana as a teen Meier et al.¬†posited that persistent marijuana users that became dependent as teens would have a bigger decline in IQ than those who became dependent as adults. To do that we tested the following hypotheses:\n\\[\n\\begin{split}\n&H_0: \\mu_{\\text{Adult-onset}} - \\mu_{\\text{Teen-onset}} = 0 \\\\\n&H_A: \\mu_{\\text{Adult-onset}} - \\mu_{\\text{Teen-onset}} &gt; 0\n\\end{split}\n\\] The results of the t-test‚Äî\\(t(35)=2.47\\), \\(p=.009\\)‚Äî suggested that the difference in average IQ score change is greater for participants who became persistent marijuana users as adults than those that became persistent marijuana users as teens. So now, we want to ask the question: How much greater?\nIn this case study we have two samples that we want to estimate the difference in means for. Thus we can compute the CI as:\n\\[\n\\begin{split}\n\\text{Sample Estimate} &\\pm 2 \\times \\text{SE} \\\\[2ex]\n\\text{Sample Difference in Means} &\\pm 2 \\times \\text{SE for difference in means} \\\\[2ex]\n(\\bar{x}_1 - \\bar{x}_2) &\\pm 2 \\bigg(\\sqrt{\\frac{\\text{SD}_1^2}{n_1} + \\frac{\\text{SD}_2^2}{n_2}}\\bigg)\n\\end{split}\n\\]\nWe will use the data in cannabis.csv to obtain these sample values.\n\n# Import data\ncannabis &lt;- read_csv(\"https://raw.githubusercontent.com/zief0002/epsy-5261/main/data/cannabis.csv\")\n\n# View data\ncannabis\n\n\n  \n\n\n# Compute numerical summaries\ndf_stats(~ iq_change | cannabis_dep, data = cannabis)\n\n\n  \n\n\n\nSubstituting these values into the formula for the CI:\n\\[\n\\begin{split}\n(\\bar{x}_1 - \\bar{x}_2) &\\pm 2 \\bigg(\\sqrt{\\frac{\\text{SD}_1^2}{n_1} + \\frac{\\text{SD}_2^2}{n_2}}\\bigg) \\\\[2ex]\n(-2.07 - -8.26) &\\pm 2 \\bigg(\\sqrt{\\frac{7.77^2}{14} + \\frac{7.14^2}{23}}\\bigg) \\\\[2ex]\n6.19 &\\pm 2 \\bigg(2.56\\bigg) \\\\[2ex]\n6.19 &\\pm 5.12 \\\\[2ex]\n[1.07,&~11.31]\n\\end{split}\n\\]\n\nYour Turn\nUsing the information in the equations above, what is the margin of error?\n\nShow/Hide Solution\n\n\nThe margin of error is 5.12.\n\nUsing the context of the case study, interpret the confidence interval that was computed above. (What does this tell you?)\n\nShow/Hide Solution\n\n\nBased on the CI, we think the difference in average IQ score change is between 1.07 and 11.31 points higher for participants who became persistent marijuana users as adults than those that became persistent marijuana users as teens.",
    "crumbs": [
      "Effect Size",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Confidence Intervals</span>"
    ]
  },
  {
    "objectID": "07-01-confidence-intervals.html#estimating-the-difference-between-two-sample-proportions",
    "href": "07-01-confidence-intervals.html#estimating-the-difference-between-two-sample-proportions",
    "title": "19¬† Confidence Intervals",
    "section": "19.4 Estimating the Difference Between Two Sample Proportions",
    "text": "19.4 Estimating the Difference Between Two Sample Proportions\nIn Chapter¬†15 we carried out a two-sample z-test to determine whether the Bachelors or Bachelorettes were more successful in their selection of potential suitors by determining whether the proportion of couples that are still together is different for the Bachelors and Bachelorettes. To do that we tested the following hypotheses:\n\\[\n\\begin{split}\nH_0: \\pi_{\\text{Bachelor}} - \\pi_{\\text{Bachelorette}} &= 0 \\\\[1ex]\nH_A: \\pi_{\\text{Bachelor}} - \\pi_{\\text{Bachelorette}} &\\neq 0\n\\end{split}\n\\] The results of the z-test‚Äî\\(z=-.77\\), \\(p=.439\\)‚Äî suggested that the it is likely that the proportion of Bachelor contestants who are still together with their selected suitor is NOT different than the proportion of Bachelorette contestants who are still together with their selected suitor. Even if we fail to reject the null hypothesis, it can be useful to compute a CI.\nIn this case study we have two samples that we want to estimate the difference in proportions for. Thus we can compute the CI as:\n\\[\n\\begin{split}\n\\text{Sample Estimate} &\\pm 2 \\times \\text{SE} \\\\[2ex]\n\\text{Sample Difference in Proportions} &\\pm 2 \\times \\text{SE for difference in proportions} \\\\[2ex]\n(\\hat{p}_1 - \\hat{p}_2) &\\pm 2 \\bigg(\\sqrt{\\frac{\\hat{p}_1(1-\\hat{p}_1)}{n_1} + \\frac{\\hat{p}_2(1-\\hat{p}_2)}{n_2}}\\bigg)\n\\end{split}\n\\] Below are the sample proportions and sample sizes for the two groups.\nBachelor Contestants\n\\[\n\\begin{split}\n\\hat{p}_{\\text{No}} &= 0.89 \\\\[2ex]\n\\hat{p}_{\\text{Yes}} &= 0.11 \\\\[2ex]\nn &= 27\n\\end{split}\n\\]\nBachelorette Contestants\n\\[\n\\begin{split}\n\\hat{p}_{\\text{No}} &= 0.81 \\\\[2ex]\n\\hat{p}_{\\text{Yes}} &= 0.19 \\\\[2ex]\nn &= 21\n\\end{split}\n\\]\n\nYour Turn\nUsing the sample information provided above, compute the CI for the difference in the proportion of Bachelors and Bachelorettes that are still together with their suitors.\n\nShow/Hide Solution\n\n\n\\[\n\\begin{split}\n(\\hat{p}_1 - \\hat{p}_2) &\\pm 2 \\bigg(\\sqrt{\\frac{\\hat{p}_1(1-\\hat{p}_1)}{n_1} + \\frac{\\hat{p}_2(1-\\hat{p}_2)}{n_2}}\\bigg) \\\\[2ex]\n(.11 - .19) &\\pm 2 \\bigg(\\sqrt{\\frac{.11(1-.11)}{27} + \\frac{.19(1-.19)}{21}}\\bigg) \\\\[2ex]\n-.08 &\\pm 2 \\bigg(.10\\bigg) \\\\[2ex]\n-.08 &\\pm .20 \\\\[2ex]\n[-.28,&~.12]\n\\end{split}\n\\]\n\nUsing the context of the case study, interpret the confidence interval that was computed above. (What does this tell you?)\n\nShow/Hide Solution\n\n\nBased on the CI, we think the difference in proportion of Bachelors and Bachelorettes that are still together with their suitors is between \\(-.28\\) and .12.\nThat is, the proportion of Bachelors that are still together with their suitors might be lower than the proportion of Bachelorettes that are still together with their suitors by .28, or it might be higher than the proportion of Bachelorettes that are still together with their suitors by as much as .12, or anywhere in between.\n\nWhat does it mean that 0 is a value in the CI?\n\nShow/Hide Solution\n\n\nIf 0 is in the CI, it means it is a plausible value for the difference in the proportion of Bachelors and Bachelorettes that are still together with their suitors.\nThat is, the proportion of Bachelors that are still together with their suitors might be the same as the proportion of Bachelorettes that are still together with their suitors.",
    "crumbs": [
      "Effect Size",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Confidence Intervals</span>"
    ]
  },
  {
    "objectID": "07-01-confidence-intervals.html#footnotes",
    "href": "07-01-confidence-intervals.html#footnotes",
    "title": "19¬† Confidence Intervals",
    "section": "",
    "text": "Sometimes we use a different multiplier than two. We will talk about that in class.‚Ü©Ô∏é\nNote the SE for the single proportion is slightly different than how we computed it for the hypothesis test. Here we are using the sample proportion p rather than the hypothesized proportion \\(\\pi\\) in the formula for SE.‚Ü©Ô∏é",
    "crumbs": [
      "Effect Size",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Confidence Intervals</span>"
    ]
  },
  {
    "objectID": "07-02-confidence-intervals-computation.html",
    "href": "07-02-confidence-intervals-computation.html",
    "title": "20¬† Confidence Intervals Using R",
    "section": "",
    "text": "20.1 The confint() Function\nTo compute a confidence interval (CI), we fit a two-sided t-test and then call the confint() function on the results. For example, to compute a CI to estimate the average price of a single-family house near the University of Minnesota we can use the following syntax.\n# Load libraries\nlibrary(ggformula)\nlibrary(mosaic)\nlibrary(tidyverse)\n\n# Import data\nzillow &lt;- read_csv(\"https://raw.githubusercontent.com/zief0002/epsy-5261/main/data/zillow.csv\")\n\n# View data\nzillow\n\n\n  \n\n\n# Carry out two-sided t-test\nmy_t &lt;- t_test(~price, data = zillow, mu = 322.46, alternative = \"two.sided\")\n\n# Compute CI\nconfint(my_t)\nThe lower and upper values of the output give the lower and upper bounds of the CI, respectively. From this output, our CI is computed as \\([348.24,~461.69]\\).",
    "crumbs": [
      "Effect Size",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Confidence Intervals Using R</span>"
    ]
  },
  {
    "objectID": "07-02-confidence-intervals-computation.html#the-confint-function",
    "href": "07-02-confidence-intervals-computation.html#the-confint-function",
    "title": "20¬† Confidence Intervals Using R",
    "section": "",
    "text": "20.1.1 Some Computational Shortcuts for Computing a CI\nIn the house prices case study, we had initially tested a two-sided hypothesis, so we already had written the syntax for the t_test() function. This will be true in most applications. If, however, you haven‚Äôt carried out a t-test, and you want to compute a CI, you can shorten the syntax in the t_test() function by omitting the arguments mu= and alternative=. For example, if we hadn‚Äôt previously carried out a t-test on our Zillow data, we could use the syntax:\n\n# Carry out two-sided t-test\nmy_t &lt;- t_test(~price, data = zillow)\n\n# Compute CI\nconfint(my_t)\n\n\n  \n\n\n\nNotice that the CI is the same as we found earlier. This is because the computation of the CI does not use the argument mu=. That is only necessary when computing output for a hypothesis test. (If you looked at the results of the t-test, the t- and p-values would be different!) Thus, the value for mu= can be whatever you want or can be omitted completely. (If it is omitted, the t_test() function defaults to mu=0.) The default value for the argument alternative= is alternative=two.sided, so omitting the alternative= argument will automatically fit a two-sided t-test.",
    "crumbs": [
      "Effect Size",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Confidence Intervals Using R</span>"
    ]
  },
  {
    "objectID": "07-02-confidence-intervals-computation.html#computing-a-ci-for-a-proportion",
    "href": "07-02-confidence-intervals-computation.html#computing-a-ci-for-a-proportion",
    "title": "20¬† Confidence Intervals Using R",
    "section": "20.2 Computing a CI for a Proportion",
    "text": "20.2 Computing a CI for a Proportion\nWe can also use the confint() function to compute the CI for a proportion. In a similar fashion, we would need to carry out a two-sided z-test (using prop_test()) and then call confint() on the results of that z-test. For example to compute a CI to estimate the proportion of all Minnesota children under 6 years of age who are above the MDH reference level in 2018, we will use the following syntax:\n\n# Import data\nmn_lead &lt;- read_csv(\"https://raw.githubusercontent.com/zief0002/epsy-5261/main/data/mn-lead.csv\")\n\nRows: 91706 Columns: 2\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (1): ebll\ndbl (1): lead_level\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# View data\nmn_lead\n\n\n  \n\n\n# One-sample z-test\nmy_z &lt;- prop_test(\n  ~ebll == \"Yes\", \n  data = mn_lead, \n  p = .029, \n  alternative = \"two.sided\",\n  correct = FALSE\n  )\n\n# Compute CI\nconfint(my_z)\n\n\n  \n\n\n\nFrom this output, our CI is computed as \\([.013,~.015]\\) which suggests that based on the data, we think the proportion of all Minnesota children under 6 years of age who are above the MDH reference level in 2018 is between .013 and .015.",
    "crumbs": [
      "Effect Size",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Confidence Intervals Using R</span>"
    ]
  },
  {
    "objectID": "07-02-confidence-intervals-computation.html#computing-a-ci-for-the-difference-in-means-or-proportions",
    "href": "07-02-confidence-intervals-computation.html#computing-a-ci-for-the-difference-in-means-or-proportions",
    "title": "20¬† Confidence Intervals Using R",
    "section": "20.3 Computing a CI for the Difference in Means or Proportions",
    "text": "20.3 Computing a CI for the Difference in Means or Proportions\nYou can also use the confint() function on the results of a two-sided t- or z-test in the same way. For example, to estimate the difference in the proportion of Bachelor and Bachelorette contestants that are still together with the person they chose, we would use:\n\n# Import data\nbachelor &lt;- read_csv(\"https://raw.githubusercontent.com/zief0002/epsy-5261/main/data/bachelor.csv\")\n\nRows: 50 Columns: 10\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (8): show, run_dates, name, winner, runner_up, proposal, still_together,...\ndbl (2): season, age\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# View data\nbachelor\n\n\n  \n\n\n# Two-sample z-test with counts entered manually\nmy_z &lt;- prop_test(\n  x = c(3, 4),\n  n = c(27, 21),\n  alternative = \"two.sided\",\n  correct = FALSE\n  )\n\nWarning in stats::prop.test(x = x, n = n, p = p, alternative = alternative, :\nChi-squared approximation may be incorrect\n\n# Compute CI\nconfint(my_z)\n\n\n  \n\n\n\nFrom this output, our CI is computed as \\([-.28,~.13]\\) which suggests that based on the data, we think the the difference in the proportion of Bachelor and Bachelorette contestants that are still together with the person they chose is between \\(-.28\\) and 0.12.\nHow can we have a negative value when we are dealing with proportions you might ask. Remember, that this represents our estimate of a difference between two proportions. When you compute the difference between two things you can get a negative value if you are subtracting a bigger value from a smaller value. To interpret this, recall that R subtracts in alphabetical order based on the category names; thus it is computing:\n\\[\n\\pi_{\\text{Bachelor}} -\\pi_{\\text{Bachelorette}}\n\\] The lower bound of \\(-.28\\) tells us that the proportion of Bacheorette contestants that are still together with the person they chose may be higher than the proportion of Bachelor contestants that are still together with the person they chose by as much as .28. While the positive upper bound of .13 suggests that it may be that the proportion of Bachelor contestants still together with the person they chose is higher than the proportion of Bachelorette contestants still together with the person they chose by as much as .13.\nBecause of this, we have uncertainty about which group is more likely to stay together with the person they chose. It may be Bachelor contestants, or it may be Bachelorette contestants, we just can‚Äôt tell based on these data‚Äîthere is too much uncertainty. Another possibility is that the proportions are the same. If the proportions are the same, the difference between them is 0‚Äîwhich falls in the range of the CI. Remember, any value in the range is a plausible value for the difference in population proportions!\n\nYour Turn\nIn Section¬†13, we carried out a two-sample t-test to evaluate whether the effects on IQ were different for users who started using marijuana as a teen. The evidence from this test suggested that the difference in average IQ score change is likely different for participants who became persistent marijuana users as adults than those that became persistent marijuana users as teens. Compute a CI for the difference in the average amount of change in IQ scores between these groups.\n\nShow/Hide Solution\n\n\n\n# Import data\ncannabis &lt;- read_csv(\"https://raw.githubusercontent.com/zief0002/epsy-5261/main/data/cannabis.csv\")\n\nRows: 37 Columns: 2\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (1): cannabis_dep\ndbl (1): iq_change\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# One-sample t-test\nmy_t &lt;- t_test(\n  ~ iq_change | cannabis_dep, \n  data = cannabis, \n  mu = 0, \n  alternative = \"two.sided\", \n  var.equal = TRUE\n  )\n\n# Compute CI\nconfint(my_t)\n\n\n  \n\n\n\nThe CI is \\([1.11,~11.27]\\)\n\nInterpret the CI you computed.\n\nShow/Hide Solution\n\n\nBased on the data, the difference in the average amount of change in IQ scores between people who became persistent marijuana users as adults than those that became persistent marijuana users as teens is between 1.11 and 11.26.\n\nBased on the CI, is it more detrimental on IQ for people who became persistent marijuana users as adults or those that became persistent marijuana users as teens? Explain.\n\nShow/Hide Solution\n\n\nThe CI is computed alphabetically by category level, which means it is computed as \\(\\pi_{\\text{Adult}}-\\pi_{\\text{Teen}}\\). We can compute this difference using the sample means. In the output we see the average IQ change for adults (\\(-2.07\\)) is a smaller decrease than it is for teens (\\(8.26\\)). The difference in sample means is \\(-2.07--8.26=+6.19\\). So a positive difference between means suggests that the adult group has LESS of a decrease in IQ than the teen group.\nBecause both the lower and upper bounds of the CI are positive, it means that the data suggest that people who become persistent marijuana users as an adult have, on average, LESS of a decrease in IQ than people who become persistent marijuana users as a teen. And this difference might be as little as 1.11 IQ points or as large as 11.27 IQ points.\n\nBe very careful when the means are negative and you are computing or estimating a difference. Interpretations can be tricky and it may take some thought in how you interpret findings.\n\n\nIn Section¬†10, we carried out a one-sample t-test to evaluate whether Ethiopian primary teachers are measuring students‚Äô prior knowledge. The evidence from this test suggested that the empirical data were consistent with the hypothesis that the average response for all Ethiopian primary school teachers is 2.5 suggesting we were uncertain about whether, on average, they were measuring students‚Äô prior knowledge. Compute a CI for the average response score for Ethiopian primary teachers.\n\nShow/Hide Solution\n\n\n\n# Import data\ncontinuous_assessment &lt;- read_csv(\"https://raw.githubusercontent.com/zief0002/epsy-5261/main/data/continuous-assessment.csv\")\n\nRows: 30 Columns: 3\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\ndbl (3): prior_knowledge, only_achievement, prompt_feedback\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# One-sample t-test\nmy_t &lt;- t_test(~prior_knowledge, data = continuous_assessment, mu = 2.5, alternative = \"two.sided\")\n\n# Compute CI\nconfint(my_t)\n\n\n  \n\n\n\nBased on the output, the CI for the average response score is \\([2.10,~2.77]\\).\n\nUse the CI to compute the margin of error. Remember a CI is computed as \\(\\text{Sample Estimate} \\pm \\text{Margin of Error}\\).\n\nShow/Hide Solution\n\n\nThe sample estimate (\\(\\bar{x}\\)) is 2.43. Computing the distance from this value to the upper bound (orto the lower bound) will give us the margin of error.\n\\[\n2.77 - 2.43 = .34\n\\]\nThe margin of error is 0.34.",
    "crumbs": [
      "Effect Size",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Confidence Intervals Using R</span>"
    ]
  },
  {
    "objectID": "07-03-confidence-intervals-extras.html",
    "href": "07-03-confidence-intervals-extras.html",
    "title": "21¬† Confidence Intervals: Assumptions, Accuracy, and Precision",
    "section": "",
    "text": "21.1 Assumptions for the Confidence Interval\nThe assumptions underlying the use of a confidence interval are exactly the same as those underlying hypothesis tests. So, for using a CI to estimate a single mean, the assumptions are:\nWhereas the assumptions underlying the use of a CI to estimate a single proportion are:\nThe assumptions for a CI to estimate the differences in means between two groups are:\nAnd, those for a CI to estimate the differences in proportions between two groups are:",
    "crumbs": [
      "Effect Size",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Confidence Intervals: Assumptions, Accuracy, and Precision</span>"
    ]
  },
  {
    "objectID": "07-03-confidence-intervals-extras.html#assumptions-for-the-confidence-interval",
    "href": "07-03-confidence-intervals-extras.html#assumptions-for-the-confidence-interval",
    "title": "21¬† Confidence Intervals: Assumptions, Accuracy, and Precision",
    "section": "",
    "text": "The distribution of values in the population is normally distributed.\nThe values in the population are independent from each other.\n\n\n\nThe values in the population follow a binomial distribution. This is true so long as there are only two values the attribute can take on (e.g., ‚ÄúYes‚Äù or ‚ÄúNo‚Äù).\nThe values in the population are independent from each other.\nThe quantities \\(n(\\hat{p})\\) and \\(n(1-\\hat{p})\\) are both greater than 10, where n is the sample size and \\(\\hat{p}\\) is the sample proportion value.\n\n\n\nThe distribution of values in both populations is normally distributed.\nThe values in both population are independent from each other.\nBoth populations have the same variance.\n\n\n\nThe values in the two populations both follow a binomial distribution. This is true so long as there are only two values the attribute can take on (e.g., ‚ÄúYes‚Äù or ‚ÄúNo‚Äù) for each group being compared.\nThe values in the population are independent from each other.\nFor both groups, the quantities \\(n(\\hat{p})\\) and \\(n(1-\\hat{p})\\) are both greater than 10, where n is the sample size used in the group and \\(\\hat{p}\\) is the sample proportion value.",
    "crumbs": [
      "Effect Size",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Confidence Intervals: Assumptions, Accuracy, and Precision</span>"
    ]
  },
  {
    "objectID": "07-03-confidence-intervals-extras.html#unbiased-sampling-and-cis",
    "href": "07-03-confidence-intervals-extras.html#unbiased-sampling-and-cis",
    "title": "21¬† Confidence Intervals: Assumptions, Accuracy, and Precision",
    "section": "21.2 Unbiased Sampling and CIs",
    "text": "21.2 Unbiased Sampling and CIs\nThe key to generalization and accuracy in the CI is that the sample was chosen using an unbiased sampling method‚Äînamely random sampling. Without this, the resulting interval is biased and the interval given is far less likely to be accurate in estimating the population parameter. In the metaphor introduced in Chapter¬†17, a biased method would mean that Arthur‚Äôs search locations for their keys was systematically in the wrong place. If we extend this idea to confidence intervals, the search location (sample statistic) would produce a confidence interval (search area) that is also systematically in the wrong place. Figure¬†21.1 shows this idea visually.\n\n\n\n\n\n\n\n\nFigure¬†21.1: This figure is a metaphor for statistical bias.\n\n\n\n\n\nIn this picture the search area, which represents the estimate of where Arthur thought they lost their keys, is inaccurate‚Äîthe actual keys (population parameter) are not inside the bounds of the search area (inside the CI). This is because the search location (sample statistic) was initially produced by a biased method.\nFor example, in Chapter¬†20 we computed a CI for the difference in the average amount of change in IQ scores between users who started using marijuana as adults and those who started using marijuana as teens. The CI, \\([1.11,~11.27]\\), indicated the difference in the average amount of change in IQ scores between people who became persistent marijuana users as adults than those that became persistent marijuana users as teens is between 1.11 and 11.26. Unfortunately the sample of users was not chosen randomly‚Äîthey were all volunteers. Because our sample was not chosen using an unbiased sampling method, it is highly likely that the CI produced is inaccurate. That is, the true population difference in the average amount of change in IQ scores between people who became persistent marijuana users as adults than those that became persistent marijuana users as teens is PROBABLY NOT between 1.11 and 11.26.\n\n\n21.2.1 Deeper Understanding of Unbiasedness and Accuracy\nTo more deeply understand how an unbiased method affects accuracy of the CI, let‚Äôs consider another thought experiment. Imagine a population that is normally distributed with a mean of 10 and a standard deviation of 2. Now imagine that we are randomly sampling 25 observations from that population and using those 25 sampled observations to produce a CI that would be used to estimate the value of the population mean. We will repeat this process, say 100 times. A visual of this thought experiment is shown in Figure¬†21.2.\n\n\n\n\n\n\n\n\nFigure¬†21.2: A thought experiment in which we randomly sample n=25 observations from a N(10, 2) population. We do this many times (say 100 times). For each sample we compute the CI.\n\n\n\n\n\nA plot of the 100 CIs is shown in Figure¬†21.3. The population mean is shown as the vertical line at 10. Some of the CIs included the value of 10. For example, the first sample produced a CI of \\([9.64,~10.80]\\). It included 10 as a plausible value. This CI is the lowest CI on the plot. It is colored grey since it included the value of 10 as a plausible value. Similarly the second sample also included 10 as a plausible value, it‚Äôs CI was \\([9.34,~10.88]\\), so it is also colored grey (it is the second lowest CI in the plot). Some of the confidence intervals in Figure¬†21.3 are red. Those CIs do not include 10 as a plausible value.\n\n\n\n\n\n\n\n\nFigure¬†21.3: The 100 CIs for each of the 100 randomly drawn samples (unbiased sampling method). The vertical black line represents the value of 10, the population mean. Some of the CIs (grey) include the value of 10, while others do not (red).\n\n\n\n\n\nNow let‚Äôs carry out a thought experiment in which a biased sampling method is used. In this sampling method, the sample mean is, on average, higher than the population mean of 10. We will use this method to again draw 100 different samples of size 25. And again, we will produce a CI for each of the 100 samples.\n\n\n\n\n\n\n\n\nFigure¬†21.4: The 100 CIs for each of the 100 samples drawn using a biased sampling method. The vertical black line represents the value of 10, the population mean. Some of the CIs (grey) include the value of 10, while others do not (red).\n\n\n\n\n\nIn Figure¬†21.4 the CIs that include the population value of 10 are again colored grey and those that do not are colored red. Using an biased sampling method, we see that more of the CIs are red‚Äîthey do not include 10 as a plausible value for the population mean, despite 10 being the actual population mean!\nIn both Figure¬†21.3 and Figure¬†21.4 we can see that some of the CIs include 10 and some don‚Äôt. But, on average, the unbiased sampling method produces many more CIs that include 10 than the biased sampling method does. Because of this, we would say that the unbiased sampling method produces more accurate estimates of the sample mean. Accuracy refers to whether the CI includes the population parameter for most CIs that could be produced. It does not mean that any one CI will be accurate or not. It is just more likely that a CI will include the population parameter if the sample that produced the CI was selected using an unbiased method.\n\nIn practice we do not draw many samples‚Äîwe have one sample. This sample is used to create a single CI that we use to estimate the mean. Unlike in the thought experiment, in practice, we do not know what the value of the population parameter actually is. So we don‚Äôt know whether our CI includes this value (is a gray CI) or doesn‚Äôt (is a red CI). If we used an unbiased sampling method to select our sample, our CI is more likely to be gray than red.",
    "crumbs": [
      "Effect Size",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Confidence Intervals: Assumptions, Accuracy, and Precision</span>"
    ]
  },
  {
    "objectID": "07-03-confidence-intervals-extras.html#confidence-level-and-accuracy",
    "href": "07-03-confidence-intervals-extras.html#confidence-level-and-accuracy",
    "title": "21¬† Confidence Intervals: Assumptions, Accuracy, and Precision",
    "section": "21.3 Confidence Level and Accuracy",
    "text": "21.3 Confidence Level and Accuracy\nIn the previous section you saw that even if you use an unbiased sampling method (e.g., random sampling) you still occasionally draw a sample that produces a red CI‚Äîit does not include the population parameter as a plausible value. In fact, looking back at Figure¬†21.3, we see that this will happen about 5% of the time (five of the 100 samples produced a red CI). This is because we produced a confidence interval using a method that will include the population parameter for 95% of the intervals it creates, so long as the sampling method used to select those samples is unbiased. Another way to say this is the method we used to create the CIs was accurate 95% of the time.\nThis accuracy rate is referred to as the confidence level. In practice we say that we created a 95% Confidence Interval. But be careful, using this language. Here are some caveats as you start to use this terminology:\n\nThe 95% doesn‚Äôt refer to the single CI, but rather to the accuracy rate across producing many, many CIs.\n\nAcross many different samples, we expect 95% of the CIs that are created to be grey and 5% to be red. In practice we never draw more than a single sample so there is ever only a single interval. This interval is either grey (it included the parameter in the interval) or red (it did not). Because of this, for a single sample we CANNOT SAY:\n\nThere is a 95% chance that the population parameter is in the interval. (WRONG! üò¢)\n\nIt either is in the interval (100%) or it‚Äôs not (0%). In practice, we hope that our interval is grey and includes the true population parameter inside the interval, but there is not way to know if it does. If we used an unbiased sampling method to select the sample, then we know that 95% of all possible samples we could draw would produce a grey interval, and we are hoping that our interval is from a sample that produces a grey interval. (Again, this is far more likely if the sample is chosen using an unbiased sampling method.)\n\n\n21.3.1 Changing the Confidence Level\nWe can change the method we use to produce the CI to raise or lower the accuracy level. For example, rather than creating a 95% CI, we could use a method that is 99% accurate (99% of the samples will produce a grey CI). In order to do this, we change the multiplication factor in the formula for the CI. For example, the following was the formula we introduced to compute a CI, which produces a 95% CI:\n\\[\n\\text{Sample Estimate} \\pm 2 \\times \\text{SE}\n\\]\nTo create a 99% CI we use:\n\\[\n\\text{Sample Estimate} \\pm 3 \\times \\text{SE}\n\\]\nAnd to produce a 68% CI we use:\n\\[\n\\text{Sample Estimate} \\pm 1 \\times \\text{SE}\n\\] The higher the confidence level, the larger the multiplication factor in the margin of error. Think about how this impacts the CI. For example, in our marijuana case study the 95% CI was \\([1.11,~11.26]\\). A 99% CI for this difference is \\([-0.62,~13.00]\\). The margin of error is bigger which makes the interval width wider. That is, we have more uncertainty (i.e., less precision) in our estimate.\nTo see how the accuracy changes when using a 99% CI (rather than a 95% CI) we can carry out a thought experiement. In this thought experiment (using an unbiased sampling method), we will draw 100 different samples of size 25 and produce a 99% CI for each of the 100 samples. The result is shown in Figure¬†21.5.\n\n\n\n\n\n\n\n\nFigure¬†21.5: The 99% CIs for each of the 100 randomly drawn samples (unbiased sampling method). The vertical black line represents the value of 10, the population mean. Some of the CIs (grey) include the value of 10, while others do not (red).\n\n\n\n\n\nWhen we use a 99% CI only one of the 100 samples produced a CI that did not include the population mean of 10. Across the 100 sampes 99 of them (99%) included the population mean of 10. That implies that using a 99% CI is more accurate than using a 95% CI. Again note, that each individual interval either included the mean of 10 (was gray) or did not (was red)‚Äîthe accuracy rate refers to how well the method does across many random samples.\nThe drawback to changing the accuracy level from 95% to 99% is that the intervals are wider. This, again, means that we have more uncertainty in the value of the population parameter because there are more plausible values in the interval. There is always a tradeoff between accuracy and precision; increasing one decreases the other. In practice, social science researchers tend to use and report 95% CIs.\n\n\n\n21.3.2 Using R to Obtain a 99% CI\nTo change the confidence level for our CI, we need to include the argument conf.level= in the t_test() function. For example, to obtain a 99% CI for the difference in the average amount of change in IQ scores between users who started using marijuana as adults and those who started using marijuana as teens, we use the following syntax:\n\n# Load libraries\nlibrary(ggformula)\nlibrary(mosaic)\nlibrary(tidyverse)\n\n# Import data\ncannabis &lt;- read_csv(\"https://raw.githubusercontent.com/zief0002/epsy-5261/main/data/cannabis.csv\")\n\n# View data\ncannabis\n\n\n  \n\n\n# One-sample t-test\n# Include conf.level=\nmy_t &lt;- t.test(\n  iq_change ~  cannabis_dep, \n  data = cannabis, \n  var.equal = TRUE, \n  conf.level = .99\n  )\n\n# Compute CI\nconfint(my_t)\n\n\n  \n\n\n\nYou can set the conf.level= argument to whichever confidence level you would like. The default is conf.level=.95, so not including the conf.level= argument will produce a 95% CI.",
    "crumbs": [
      "Effect Size",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Confidence Intervals: Assumptions, Accuracy, and Precision</span>"
    ]
  },
  {
    "objectID": "07-03-confidence-intervals-extras.html#improving-precision-of-the-ci",
    "href": "07-03-confidence-intervals-extras.html#improving-precision-of-the-ci",
    "title": "21¬† Confidence Intervals: Assumptions, Accuracy, and Precision",
    "section": "21.4 Improving Precision of the CI",
    "text": "21.4 Improving Precision of the CI\nIdeally, the confidence interval will be precise enough to be useful to the researcher. For example, say a researcher was interested in estimating the mean starting salary for a teacher in a particular state. If the CI they produced suggested the average starting salary was between $20,000 and $80,000, that would not be very useful. While it gives a set of plausible values, the precision of the interval is too low (too much uncertainty) to be useful in determining the average starting salary. On the other hand, a CI that estimated the average starting salary to be between $49,800 and $50,200 is quite useful. The high amount of precision in the estimate reduces the amount of uncertainty around the actual mean value.\nThe amount of precision in the CI is all governed by the margin of error. In our keys metaphor, the margin of error is represented by the size of the area that Arthur is searching.1 In Figure¬†21.6 and Figure¬†21.7, the two scenarios show vastly different search areas for Arthur‚Äôs keys. The left-hand figure has a smaller search area reflecting higher precision and less uncertainty about where the keys are. The right-hand figure has a larger search area which reflects lower precision and more uncertainty about where the keys are.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†21.6: This figure is a metaphor for high precision. Note there is not much uncertainty in the area that needs to be searched.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†21.7: This figure is a metaphor for low precision. Note there is much more uncertainty in the area that needs to be searched.\n\n\n\n\n\n\n\nNumerically, the margin of error is half of the range of the confidence interval and is expressed as the part of the CI that gets added and subtracted from the sample estimate. For example the two CIs presented in the previous paragraph have a margin of error of $30,000 and $200, respectively. Their formulas to produce the CIs would be:\n\\[\n\\begin{split}\n50000 &\\pm 30000 = [20000,~80000]\\\\[2ex]\n50000 &\\pm 200 = [49800,~50200]\n\\end{split}\n\\]\nRecall that the way we obtain the margin of error (when we are estimating the 95% CI for a single mean) is:\n\\[\n\\begin{split}\n\\text{Margin of Error} &= 2 \\times \\text{SE} \\\\[2ex]\n&=2 \\times \\frac{\\text{SD}}{\\sqrt{n}} \\\\[2ex]\n\\end{split}\n\\]\nwhere the value 2 was a multiplication factor related to the confidence level, SD is the sample standard deviation, and n is the sample size. To improve precision, we need to make the margin of error smaller (less uncertainty). How can we do this?\n\nUse a smaller multiplication factor than 2 (i.e., make the confidence level smaller)\nHave a smaller SD\nHave a larger sample size\n\nIn the social sciences, since we always use a 95% CI, the multiplication factor will be 2, so we can‚Äôt really manipulate this without sacrificing accuracy. The SD is a function of the data, so there is really no way to manipulate this either (at least not easily). The only factor we as researchers can change is the sample size, and sometimes we don‚Äôt have control over that either.\n\nLarger sample sizes result in more precision (less uncertainty) in our estimates.\n\nThinking about this relationship between sample size and precision of the estimate prior to collecting any data can help you plan a more meaningful study. For example, say you wanted to be able to estimate the starting salary of teachers so that the margin of error was no more than $1,000 (a range of $2,000 in the CI). How big a sample size might you need? You could substitute the desired margin of error into our formula and solve for n.\n\\[\n\\begin{split}\n\\text{Margin of Error} &= 2 \\times \\text{SE} \\\\[2ex]\n1000 &=2 \\times \\frac{\\text{SD}}{\\sqrt{n}} \\\\[2ex]\n\\end{split}\n\\]\nTo solve for n, we also need an estimate for the SD we might expect in the data we collect. Often good guesses for this can be found in previous studies or the substantive literature. In our example, based on previous data, we expect that a reasonable guess for the SD might be about $10,000. Including this in our formula and solving for sample size:\n\\[\n\\begin{split}\n1000 &=2 \\times \\frac{10000}{\\sqrt{n}} \\\\[2ex]\n500 &= \\frac{10000}{\\sqrt{n}} \\\\[2ex]\n500(\\sqrt{n}) &= 10000 \\\\[2ex]\n\\sqrt{n} &= \\frac{10000}{500} \\\\[2ex]\n\\sqrt{n} &= 20 \\\\[2ex]\nn &= 20^2 \\\\[2ex]\nn &= 400\n\\end{split}\n\\]\nTo obtain a 95% CI with a margin of error of $1,000, we need a sample of salaries from 400 starting teachers (assuming that the SD in the data is $10,000).\n\nObtaining a high degree of precision is often quite costly in terms of the sample size. You generally need a very large sample size to ensure high precision in a CI, which is not always possible in practice. This often means that estimates in the social sciences typically have a lot of uncertainty.",
    "crumbs": [
      "Effect Size",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Confidence Intervals: Assumptions, Accuracy, and Precision</span>"
    ]
  },
  {
    "objectID": "07-03-confidence-intervals-extras.html#footnotes",
    "href": "07-03-confidence-intervals-extras.html#footnotes",
    "title": "21¬† Confidence Intervals: Assumptions, Accuracy, and Precision",
    "section": "",
    "text": "Technically it would be the radius of the search area.‚Ü©Ô∏é",
    "crumbs": [
      "Effect Size",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Confidence Intervals: Assumptions, Accuracy, and Precision</span>"
    ]
  },
  {
    "objectID": "07-04-standardized-effects-means.html",
    "href": "07-04-standardized-effects-means.html",
    "title": "22¬† Standardized Effects for Means",
    "section": "",
    "text": "22.1 Raw versus Standardized Effects\nConfidence intervals report effect sizes in the metric of the original variable. For example, when we found the CI for the average price of a house near the University of Minnesota, the metric we used to interpret the CI was thousands of dollars, the same metric as the data (i.e., the raw metric). Reporting effect sizes using the raw metric is useful if people consuming our scholarship can make sense of the metric and interpret the magnitude of the effect using that metric. In reporting an effect for the average house, thousands of dollars is a reasonable metric‚ÄîAmericans generally have a sense of what that means and can reasonably determine whether values reported using that metric are big or small.\nMany times, however, the metric being used is less interpretable. For example, in our cannabis example, the metric being reported in the CI is change in IQ points. Is a change of 1.11 IQ points (the lower bound of our CI) a small change? A big change? What about a change of 11.3 IQ points? Without a deep understanding of the IQ scale used, these are difficult questions to answer.\nTo alleviate the problems in interpretations of magnitude, researchers tend to report standardized effect sizes rather than raw effect sizes when the metric is not universally known. These effects use a standardized metric so that all researchers can make reasonable inference about the magnitude of the effect. In practice, there are two common standardized effect sizes that researchers use:\nWhile both of these standardized measures characterize the extent to which sample results diverge from the expectations specified in the null hypothesis, they do so in a different manner. In this chapter, we will introduce distance measures of effect.",
    "crumbs": [
      "Effect Size",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Standardized Effects for Means</span>"
    ]
  },
  {
    "objectID": "07-04-standardized-effects-means.html#raw-versus-standardized-effects",
    "href": "07-04-standardized-effects-means.html#raw-versus-standardized-effects",
    "title": "22¬† Standardized Effects for Means",
    "section": "",
    "text": "Distance measures, and\nVariance accounted for measures",
    "crumbs": [
      "Effect Size",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Standardized Effects for Means</span>"
    ]
  },
  {
    "objectID": "07-04-standardized-effects-means.html#cohens-delta",
    "href": "07-04-standardized-effects-means.html#cohens-delta",
    "title": "22¬† Standardized Effects for Means",
    "section": "22.2 Cohen‚Äôs \\(\\delta\\)",
    "text": "22.2 Cohen‚Äôs \\(\\delta\\)\nCohen (1962) introduced the first commonly recognized standardized effect size to measure the distance between two means. In his landmark book (Cohen, 1965), he named this standardized effect size \\(\\delta\\) (the Greek letter ‚Äúdelta‚Äù; equivalent to the Roman lowercase ‚Äúd‚Äù). It has henceforth been referred to as Cohen‚Äôs \\(\\delta\\). The calculation of this standardized effect size is:\n\\[\n\\delta = \\frac{|\\mu_1-\\mu_2|}{\\sigma}\n\\]\nwhere \\(\\mu_1\\) and \\(\\mu_2\\) are the population means for the two groups, and \\(\\sigma\\) is the standard deviation of the population. (Remember one of the assumptions when we compare two means is that the two populations have the same variance, which implies they have the same standard deviation.) An estimate of this effect size is obtained by substituting the sample estimates for the mean and standard deviation into this formula. To identify this as an estimate, it is renamed Cohen‚Äôs d:\n\\[\nd = \\frac{|\\bar{x}_1-\\bar{x}_2|}{s}\n\\]\nCohen pointed out that since the variances, and therefore the standard deviations, for the two populations are assumed to be equivalent, that the standard deviation estimate from either group could be used. However, in practice it is common to use the average of the two sample estimates. (If the groups have equal sample sizes, we use the simple average, but if they are different sizes, we use a weighted average.)\n\\[\n\\begin{split}\n\\mathbf{Simple~Average}:&~s = \\frac{s_1 + s_2}{2}\\\\[2ex]\n\\mathbf{Weighted~Average}:&~s = \\frac{n_1(s_1) + n_2(s_2)}{n_1 + n_2} \\\\[2ex]\n\\end{split}\n\\] where \\(s_1\\) and \\(s_2\\) are the standard deviations of the two groups, respectively, and \\(n_1\\) and \\(n_2\\) are the sample sizes.\nExamining the formula for Cohen‚Äô d, we see that the numerator is expressing the estimated difference between the two population means (a distance between the two distributions). Dividing this distance by the standard deviation changes the metric of this distance. As an example, consider two objects that are 36 inches apart. To convert the distance to feet we divide the distance by 12. Note that it was the operation of dividing the distance that changed the metric. The value you divide by sets the new metric. For example if we had divided our 36 inch distance by 36 rather than 12 the metric would be in yards rather than feet. In Cohen‚Äôs d, the value we divide by is the standard deviation, so the new metric is the distance in standard deviation units.\n\n\n22.2.1 Cannabis Case Study\nLet‚Äôs compute Cohen‚Äôs d for the cannabis case study. We will begin by importing the data and computing numerical summaries for the two groups being compared.\n\n# Load libraries\nlibrary(educate)\nlibrary(ggformula)\nlibrary(mosaic)\nlibrary(tidyverse)\n\n\n# Import data\ncannabis &lt;- read_csv(\"https://raw.githubusercontent.com/zief0002/epsy-5261/main/data/cannabis.csv\")\n\n# View data\ncannabis\n\n\n  \n\n\n# Compute numerical summaries\ndf_stats(~ iq_change | cannabis_dep, data = cannabis)\n\n\n  \n\n\n\nWe note that the sample sizes for the two groups are not the same (one is 14 and the other 23). This means that we need to compute the weighted average for the standard deviation we will use in the formula for Cohen‚Äôs d. To do this:\n\\[\n\\begin{split}\ns &= \\frac{n_1(s_1) + n_2(s_2)}{n_1 + n_2} \\\\[2ex]\n&= \\frac{14(7.77) + 23(7.14)}{14 + 23} \\\\[2ex]\n&= 7.38\n\\end{split}\n\\]\nWe can then compute Cohen‚Äôs d as:\n\\[\n\\begin{split}\nd &= \\frac{|\\bar{x}_1-\\bar{x}_2|}{s} \\\\[2ex]\n&= \\frac{|-2.07 - -8.26|}{7.38} \\\\[2ex]\n&= \\frac{6.19}{7.38} \\\\[2ex]\n&= .84\n\\end{split}\n\\] This is the distance between the two means in the standard deviation metric. In other words, the difference between average IQ score change between participants who became persistent marijuana users as adults than those that became persistent marijuana users as teens is 0.84 standard deviations. In general, we can use the following guidelines to interpret Cohen‚Äôs d values:\n\\[\n\\begin{split}\nd &\\approx 0.2 \\qquad \\text{Small Effect} \\\\[2ex]\nd &\\approx 0.5 \\qquad \\text{Moderate Effect} \\\\[2ex]\nd &\\approx 0.8 \\qquad \\text{Large Effect}\n\\end{split}\n\\] Using these guidelines suggests that there is a large effect of age on IQ change. Had we used the raw metric, we would have computed a difference between these groups of 6.19 IQ points (the numerator of Cohen‚Äôs d). Without a deep understanding of the IQ metric, we might have written this off as a small difference. Standardizing the metric to use standard deviation units helps us better understand effects that are in less interpretable metrics!\n\n\n\n22.2.2 Cohen‚Äôs d with One Sample\nWe can also compute Cohen‚Äôs d when we only have a single sample. Rather than computing the distance between two sample means in the numerator of Cohen‚Äôs d, we compute the distance between the sample mean and the hypothesized value of \\(\\mu\\) tested in a hypothesis test. In the denominator, we just employ the standard deviation for our sample:\n\\[\nd = \\frac{|\\bar{x} - \\mu_{\\text{Hyp}}|}{s}\n\\]\nAs an example, consider the house prices case study from Chapter¬†10. We evaluated whether the average price of a house near the University of Minnesota was different than $322.46k, the price of a typical single-family house in Minneapolis, by testing the following hypotheses:\n\\[\n\\begin{split}\nH_0: \\mu = 322.46 \\\\[1ex]\nH_A: \\mu \\neq 322.46\n\\end{split}\n\\] To compute Cohen‚Äôs d, we import the data and compute numerical summaries.\n\n# Import data\nzillow &lt;- read_csv(\"https://raw.githubusercontent.com/zief0002/epsy-5261/main/data/zillow.csv\")\n\nRows: 15 Columns: 1\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\ndbl (1): price\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# View data\nzillow\n\n\n  \n\n\n# Compute numerical summaries\ndf_stats(~ price, data = zillow)\n\n\n  \n\n\n\nThen we substitute these values along with the hypothesized mean of 322.46 (from the null hypothesis) into the formula for Cohen‚Äôs d:\n\\[\n\\begin{split}\nd &= \\frac{|\\bar{x} - \\mu_{\\text{Hyp}}|}{s} \\\\[2ex]\n&= \\frac{|404.97 - 322.46|}{102.43} \\\\[2ex]\n&= \\frac{82.51}{102.43} \\\\[2ex]\n&= 0.81\n\\end{split}\n\\]\nThe difference between average house price in neighborhoods near the UMN campus and the hypothesized price of $322.46k is 0.81 standard deviations. This is a large difference according to Cohen‚Äôs guidelines.\n\nThe choice of whether to report the effect in raw or standardized units is up to the researcher. In the house price example, it is probably better to report the raw effect rather than the standardized effect. Consider both the raw metric and the audience‚Äîwill your audience be able to understand the magnitude of the raw effect? Or would it be more helpful to standardize it so that the magnitude is more interpretable.\n\n\n\nYour Turn\nWhile differences in average age are probably best repoirted in the raw metric, as practice, compute Cohen‚Äôs d for the difference in the average age of the Bachelors and Bachelorettes.\nImport the bachelor.csv data and computing numerical summaries. Based on these summaries, compute s, the denominator for Cohen‚Äôs d.\n\nShow/Hide Solution\n\n\n\n# Import data\nbachelor &lt;- read_csv(\"https://raw.githubusercontent.com/zief0002/epsy-5261/main/data/bachelor.csv\")\n\nRows: 50 Columns: 10\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (8): show, run_dates, name, winner, runner_up, proposal, still_together,...\ndbl (2): season, age\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Compute numerical summaries\ndf_stats(~age | show, data = bachelor)\n\n\n  \n\n\n\nBecause the sample sizes are not equal (27 vs.¬†24), we need to compute s using a weighted average.\n\\[\n\\begin{split}\ns &= \\frac{n_1(s_1) + n_2(s_2)}{n_1 + n_2} \\\\[2ex]\n&= \\frac{27(3.80) + 23(3.03)}{27 + 23} \\\\[2ex]\n&= 3.45\n\\end{split}\n\\]\n\nCompute Cohen‚Äôs d using the values computed in the previous problem..\n\nShow/Hide Solution\n\n\n\\[\n\\begin{split}\nd &= \\frac{|\\bar{x}_1 - \\bar{x}_2|}{s} \\\\[2ex]\n&= \\frac{|30.70 - 28.17|}{3.45} \\\\[2ex]\n&= .733\n\\end{split}\n\\]\n\nInterpret the value of Cohen‚Äôs d. Also comment on its magnitude.\n\nShow/Hide Solution\n\n\nThe difference between the average age of Bachelors and Bachelorettes is 0.733 standard deviations. This is a fairly large effect.",
    "crumbs": [
      "Effect Size",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Standardized Effects for Means</span>"
    ]
  },
  {
    "objectID": "07-04-standardized-effects-means.html#using-r-to-compute-cohens-d",
    "href": "07-04-standardized-effects-means.html#using-r-to-compute-cohens-d",
    "title": "22¬† Standardized Effects for Means",
    "section": "22.3 Using R to Compute Cohen‚Äôs d",
    "text": "22.3 Using R to Compute Cohen‚Äôs d\nThe function smd() (standardized mean difference) can be used to compute Cohen‚Äôs d. This function is part of the {MBESS} package. (You will need to install this package.) To use the smd() function, we provide the means, standard deviations, and sample sizes of both groups. For example, the syntax to compute Cohen‚Äôs d for the Bachelor/Bachelorette ages example is shown below:\n\n# Load MBESS package\nlibrary(MBESS)\n\n# Compute Cohen's d\nsmd(\n  Mean.1 = 30.70, s.1 = 3.80, n.1 = 27, #Bachelor summaries\n  Mean.2 = 28.17, s.2 = 3.04, n.2 = 23  #Bachelorette summaries\n  )\n\n[1] 0.7286076\n\n\n\nIt doesn‚Äôt matter which group you input in as Group 1 or Group 2‚Ä¶just be consistent in the function.\n\nTo use the smd() function to compute Cohen‚Äôs d to measure the distance between a sample mean and a hypothesized mean (i.e., in the one-sample situation) we use Mean.1= and Mean.2=, similar to the previous syntax. We also use s= to include the sample standard deviation. (We do not need to provide the sample sizes.) The syntax to compute Cohen‚Äôs d for our Zillow example is:\n\n# Compute Cohen's d (one-sample)\nsmd(\n  Mean.1 = 404.97, #Sample mean\n  Mean.2 = 322.46, #Hypothesized mean\n  s = 102.43 #Sample SD\n)\n\n[1] 0.8055257\n\n\n\nYour Turn\nUse the smd() function to compute Cohen‚Äôs d for the cannabis example.\n\nShow/Hide Solution\n\n\n\n# Compute Cohen's d\nsmd(\n  Mean.1 = -2.07, s.1 = 7.77, n.1 = 14, #Adult summaries\n  Mean.2 = -8.26, s.2 = 7.14, n.2 = 23  #Teen summaries\n  )\n\n[1] 0.8387215\n\n\nDon‚Äôt forget to load the {MBESS} package if you haven‚Äôt already done so!",
    "crumbs": [
      "Effect Size",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Standardized Effects for Means</span>"
    ]
  },
  {
    "objectID": "07-04-standardized-effects-means.html#confidence-intervals-for-cohens-d",
    "href": "07-04-standardized-effects-means.html#confidence-intervals-for-cohens-d",
    "title": "22¬† Standardized Effects for Means",
    "section": "22.4 Confidence Intervals for Cohen‚Äôs d",
    "text": "22.4 Confidence Intervals for Cohen‚Äôs d\nCohen‚Äôs d is a point estimate (i.e., single number estimate) of the standardized population effect size Cohen‚Äôs \\(\\delta\\). As with raw estimates of the effect, it is important to consider uncertainty in the estimate and report an interval estimate (i.e., range of plausible values) for the effect.\nTo find a CI for Cohen‚Äôs \\(\\delta\\) in the one-sample situation‚Äîcomparing a sample mean to a hypothesized mean‚Äîwe can use the function ci.sm(), also part of the {MBESS} library. This function takes two arguments, sm= (Cohen‚Äôs d) and N= (the sample size). The syntax to compute a 95% CI for Cohen‚Äôs d in the Zillow example is:\n\n# Compute CI for Zillow example (one-sample)\nci.sm(\n  sm = .8055, #Cohen's d\n  N = 15      #Sample size\n  )\n\n$Lower.Conf.Limit.Standardized.Mean\n[1] 0.2088108\n\n$Standardized.Mean\n[1] 0.8055\n\n$Upper.Conf.Limit.Standardized.Mean\n[1] 1.380891\n\n\nThe CI for Cohen‚Äôs \\(\\delta\\) is \\([.21,~1.38]\\). That is the population effect size is likely between .21 and 1.38 standard deviations. Using Cohen‚Äôs guidelines, the population effect might be small, or huge, or anywhere in between. We have a lot of uncertainty in the true size of the effect (due to the small sample size).\nFor the two-sample situation‚Äîcomparing two samples‚Äîwe use the ci.smd() function (from the {MBESS} library) to compute a CI for Cohen‚Äôs \\(\\delta\\). This function takes three arguments: smd= (Cohen‚Äôs d), n.1=, and n.2= (the two sample sizes, respectively). The syntax to compute a 95% CI for Cohen‚Äôs d in the cannabis example is:\n\nci.smd(\n  smd = .8387, #Cohen's d\n  n.1 = 14,    #Sample size for group 1\n  n.2 = 23    #Sample size for group 2\n)\n\n$Lower.Conf.Limit.smd\n[1] 0.1405644\n\n$smd\n[1] 0.8387\n\n$Upper.Conf.Limit.smd\n[1] 1.525818\n\n\nThe CI for Cohen‚Äôs \\(\\delta\\) is \\([.14,~1.53]\\). That is the population effect size is likely between .14 and 1.52 standard deviations. Using Cohen‚Äôs guidelines, the population effect might be quite small, or huge, or anywhere in between. Again, we have a lot of uncertainty in the true size of the effect (due to the small sample sizes).\n\nTo have reasonable precision in the CIs for a standardized effect, you need very large samples!\n\n\nYour Turn\nUse the ci.smd() function to compute a 99% CI for Cohen‚Äôs \\(\\delta\\) for the Bachelor/Bachelorette age example. You can change the confidence level using the conf.level= argument. The default is conf.level=.95, which produces a 95% CI.\n\nShow/Hide Solution\n\n\n\n# Compute 99% CI for Cohen's d\nci.smd(\n  smd = .7286,     #Cohen's d\n  n.1 = 27,        #Sample size for group 1\n  n.2 = 23,        #Sample size for group 2\n  conf.level = .99 #99% confidence level\n)\n\n$Lower.Conf.Limit.smd\n[1] -0.03017543\n\n$smd\n[1] 0.7286\n\n$Upper.Conf.Limit.smd\n[1] 1.480727\n\n\nHere the CI for Cohen‚Äôs \\(\\delta\\) extends from \\(-.03\\) to 1.48. The negative value at one end of the interval and a positve value indicates that the direction of the effect is in question‚Ä¶In the population, is the Bachelor‚Äôs average age older than that of the Bachelorettes? Or are the Bachelorette‚Äôs older, on average, than the Bachelors? There is too much uncertainty to determine this. Moreover, there is a lot of uncertainty in the size of the effect‚Ä¶it could be small or large.",
    "crumbs": [
      "Effect Size",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Standardized Effects for Means</span>"
    ]
  },
  {
    "objectID": "07-04-standardized-effects-means.html#references",
    "href": "07-04-standardized-effects-means.html#references",
    "title": "22¬† Standardized Effects for Means",
    "section": "22.5 References",
    "text": "22.5 References\n\n\n\n\nCohen, J. (1962). The statistical power of abnormal-social psychological research. Journal of Abnormal and Social Psychology, 65(3), 145‚Äì153.\n\n\nCohen, J. (1965). Statistical power analysis for the behavioral sciences. Academic Press.",
    "crumbs": [
      "Effect Size",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Standardized Effects for Means</span>"
    ]
  },
  {
    "objectID": "07-05-standardized-effects-props.html",
    "href": "07-05-standardized-effects-props.html",
    "title": "23¬† Standardized Effects for Proportions",
    "section": "",
    "text": "23.1 Cohen‚Äôs h\nThere are several methods for computing standardizd effect sizes for differences in proportions. For example, Cohen (of Cohen‚Äôs d fame) developed a metric called Cohen‚Äôs h, which measures the distance between two proportions. This is based on an arcsine transformation of the proportions (remember your trigonometry??) and is computed as:\n\\[\nh = 2 \\arcsin(\\sqrt{p_1}) ‚Äì 2 \\arcsin(\\sqrt{p_2})\n\\]\nwhere \\(p_1\\) and \\(p_2\\) are the sample proportions you want to measure the effect between. We can illustrate how to compute this standardized effect using the bachelor.csv data to find Cohen‚Äôs h to between the proportion of Bachelor and Bachelorettes that are still together with their chosen suitors. Below we import the data and compute summary values for the two groups.\nlibrary(educate)\nlibrary(ggformula)\nlibrary(mosaic)\nlibrary(mosaicCore)\nlibrary(tidyverse)\n\n\n# Import data\nbachelor &lt;- read_csv(\"https://raw.githubusercontent.com/zief0002/epsy-5261/main/data/bachelor.csv\")\n\n# View data\nbachelor\n\n\n  \n\n\n# Compute proportions\ndf_stats(~still_together | show, data = bachelor, props)\n\nWarning: Excluding 2 rows due to missing data [df_stats()].\nBased on the proportion that are still together, \\(\\hat{p}_{\\text{Bachelor}} = .111, ~\\hat{p}_{\\text{Bachelorette}} = .174\\), the difference is .063‚Äîthis is a raw effect of the difference. To compute Cohen‚Äôs h, the standardized effect, we can employ those proportions in to the formula above. Because arcsine transformations might not be at the tip of your brain, we use R to do this with the function asin().\n# Compute Cohen's h\n2 * asin(sqrt(.174)) - 2 * asin(sqrt(.111))\n\n[1] 0.1812569\nCohen‚Äôs h value is .181. While the metric used for Cohen‚Äôs h is standardized, we typically don‚Äôt interpret the value; we just report it. We can, however, interpret the magnitude of Cohen‚Äôs h using the same guidelines as Cohen‚Äôs d:\n\\[\n\\begin{split}\nh &\\approx 0.2 \\qquad \\text{Small Effect} \\\\[2ex]\nh &\\approx 0.5 \\qquad \\text{Moderate Effect} \\\\[2ex]\nh &\\approx 0.8 \\qquad \\text{Large Effect}\n\\end{split}\n\\] In this example the difference between the two proportions indicates that it is a small effect.\nCohen‚Äôs h can also be computed when comparing a single sample proportion to a hypothesized proportion (one-sample situation). For example, in Chapter¬†12 we evaluated whether the proportion of all Minnesota children under 6 years of age who are above the MDH reference level in 2018 was different than 0.029 (the proportion in 2012). Here the two inputs to Cohen‚Äôs h are the sample proportion (\\(\\hat{p}=.0139\\)) and the value being tested in the null hypothesis (0.029)\n# Compute Cohen's h\n2 * asin(sqrt(.0139)) - 2 * asin(sqrt(.029))\n\n[1] -0.1059095\nCohen‚Äôs h value is \\(-0.11\\), which corresponds to a small effect. (Note that the sign is irrelevant when considering the size of the effect.)",
    "crumbs": [
      "Effect Size",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Standardized Effects for Proportions</span>"
    ]
  },
  {
    "objectID": "07-05-standardized-effects-props.html#cohens-h",
    "href": "07-05-standardized-effects-props.html#cohens-h",
    "title": "23¬† Standardized Effects for Proportions",
    "section": "",
    "text": "Your Turn\nImport the fastx-reviews.csv data and compute the proportion of all critics‚Äô ‚ÄúFresh‚Äù reviews.\n\nShow/Hide Solution\n\n\n\n# Import data\nfastx &lt;- read_csv(\"https://raw.githubusercontent.com/zief0002/epsy-5261/main/data/fastx-reviews.csv\")\n\nRows: 238 Columns: 5\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (5): reviewer, publication, score, fresh_rotten, review_text\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Compute sample proportion of Fresh reviews\ndf_stats(~fresh_rotten, data = fastx, props)\n\n\n  \n\n\n\n\nUse the nrow() function to compute the sample size. Just input the name of the data frame object into this function.\n\nShow/Hide Solution\n\n\n\n# Compute sample size\nnrow(fastx)\n\n[1] 238\n\n\n\nUse the formula (and R) to compute Cohen‚Äôs h comparing the sample proportion of ‚Äúfresh‚Äù reviews to the hypothesized value of 0.5. Also indicate the magnitude of the effect based on Cohen‚Äôs guidelines.\n\nShow/Hide Solution\n\n\n\n# Compute Cohen's h\n2 * asin(sqrt(.538)) - 2 * asin(sqrt(.5))\n\n[1] 0.07607335\n\n\nAn h of .076 is indicative of a very small effect.\n\n\n\n\n23.1.1 Confidence Interval for Cohen‚Äôs h\nThe ci_cohens_h() function from the {educate} package can be used to find Cohen‚Äôs h and compute a confidence level for the population effect size. This function takes the following arguments:\n\np1: Proportion for Sample 1\nn1: Sample size for Sample 1\nn1: Proportion for Sample 2\nn2: Sample size for Sample 2\nconf.level: The confidence level for the interval (default is conf.level = 0.95)\n\nFor example, to compute the 95% confidence interval for Cohen‚Äôs h in the population for our Bachelor/Bachelorette case study, we use the following syntax:\n\n# Compute CI for Cohen's h\nci_cohens_h(\n  p1 = 0.174, #Proportion for Bachelorette\n  n1 = 25,    #Sample size for Bachelorette\n  p2 = .111,  #Proportion for Bachelor\n  n2 = 27,    #Sample size for Bachelor\n  conf.level = 0.95\n  )\n\n\n--------------------------------------------------\n95% Confidence Interval\n--------------------------------------------------\n\nCohen's h = 0.09062846\n\nLower Limit = -0.3627418\nUpper Limit = 0.7252556\n\n--------------------------------------------------\n\n\nThe CI is \\([-0.36,~0.73]\\). Note that the lower limit is negative. This suggests that the proportion of Bachelors that stay together with their chosen suitor might be higher than the proportion of Bachelorettes that stay together with their chosen suitor. So, this CI is indicating that:\n\nThere might be a somewhat small effect in the direction that the proportion of Bachelors that stay together with their chosen suitor might be higher than the proportion of Bachelorettes that stay together with their chosen suitor.\nThere might be no difference in the proportion of Bachelors and Bachelorettes that stay together with their chosen suitor, Or,\nThere might be a fairly large effect in the direction that the proportion of Bachelorettes that stay together with their chosen suitor might be higher than the proportion of Bachelors that stay together with their chosen suitor.\n\n\nWe can also use the ci_cohens_h() function to compare a single sample to a hypothesized value (e.g., finding the effect for a one-sample situation). To do this, whichever ‚Äúsample‚Äù you use to input the hypothesized value (say p2), the corresponding sample size is inputted as Inf (i.e., n2=Inf). This ensures that only the actual sample summaries are used to compute the uncertainty in the CI.\n\n\n\nYour Turn\nUse the ci_cohens_h() function to compute the 95% confidence interval for the population effect in the Rotten Tomatoes example comparing to the hypothesized value of 0.5. For the sample size corresponding to the hypothesized value in the function, enter the value Inf.\n\nShow/Hide Solution\n\n\n\n# Compute CI for Cohen's h\nci_cohens_h(\n  p1 = 0.538, #Proportion for sample data\n  n1 = 238,   #Sample size for sample data\n  p2 = .5,    #Hypothesized proportion\n  n2 = Inf,    #Hypothesized sample size\n  conf.level = 0.95\n  )\n\n\n--------------------------------------------------\n95% Confidence Interval\n--------------------------------------------------\n\nCohen's h = 0.03803668\n\nLower Limit = -0.05097224\nUpper Limit = 0.2031189\n\n--------------------------------------------------\n\n\n\nInterpret the CI by commenting on the potential direction and magnitude of the effect.\n\nShow/Hide Solution\n\n\nThe CI of \\([-.05,~0.20]\\) indicates that:\n\nThere might be a tiny effect in the direction that the proportion of ‚ÄúFresh‚Äù reviews for Fast X may be less than 0.5.\nIt might be that the proportion of ‚ÄúFresh‚Äù reviews for Fast X is 0.5.\nThere might be a small effect in the direction that the proportion of ‚ÄúFresh‚Äù reviews for Fast X may be more than 0.5.",
    "crumbs": [
      "Effect Size",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Standardized Effects for Proportions</span>"
    ]
  },
  {
    "objectID": "07-05-standardized-effects-props.html#risk-ratio",
    "href": "07-05-standardized-effects-props.html#risk-ratio",
    "title": "23¬† Standardized Effects for Proportions",
    "section": "23.2 Risk Ratio",
    "text": "23.2 Risk Ratio\nA more commonly reported effect size is a risk ratio, also sometimes referred to as relative risk. This effect is most commonly used in medicine and health sciences, but is quite useful. A risk ratio measures the risk of a certain event happening in one group compared to the risk of the same event happening in another group. For example, a health research might compare the risk of COVID in low income communities to that in high income communities.\n‚ÄúRisk‚Äù is simply a proportion of something occurring in a group. In our Bachelor/Bachelorette example, ‚Äúrisk‚Äù might be staying together (or alternatively, breaking up). To compute the risk ratio, or relative risk, we are just computing the ratio of two proportions:\n\\[\n\\text{Risk Ratio} = \\frac{p_1}{p_2}\n\\] In our Bachelor/Bachelorette example the risk ratio of staying together is:\n\\[\n\\begin{split}\n\\text{Risk Ratio} &= \\frac{p_1}{p_2} \\\\[2ex]\n&= \\frac{.174}{.111} \\\\[2ex]\n&= 1.56\n\\end{split}\n\\] We can interpret this as Bachelorettes (numerator proportion) are 1.56 times as likely to stay together as Bachelors (denominator proportion).\n\nThe choice of which group goes in the numerator is irrelevant. However, interpretationally it is easier if you put the bigger proportion in the numerator.\n\n\n\n23.2.1 Risk Ratio with One Sample\nWe can also compute a risk ratio when we only have a single sample. Rather than computing the ratio of two sample proportions, we compute the ratio of the sample proportion and the hypothesized value of \\(\\pi\\) tested in a hypothesis test.\nAs an example, consider the lead levels case study from Chapter¬†12. We evaluated whether the the proportion of all Minnesota children under 6 years of age who are above the MDH reference level in 2018 different than .029 (the proportion in 2012?), by testing the following hypotheses:\n\\[\n\\begin{split}\nH_0: \\pi_{\\text{Above MDH}} = .029 \\\\[1ex]\nH_A: \\pi_{\\text{Above MDH}} \\neq .029\n\\end{split}\n\\]\nTo compute a risk ratio, we import the data and compute numerical summaries.\n\n# Import data\nmn_lead &lt;- read_csv(\"https://raw.githubusercontent.com/zief0002/epsy-5261/main/data/mn-lead.csv\")\n\nRows: 91706 Columns: 2\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (1): ebll\ndbl (1): lead_level\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# View data\nmn_lead\n\n\n  \n\n\n# Compute numerical summaries\ndf_stats(~ebll, data = mn_lead, props)\n\n\n  \n\n\n\nTo compute the risk ratio:\n\\[\n\\begin{split}\n\\text{Risk Ratio} &= \\frac{p}{\\pi} \\\\[2ex]\n&= \\frac{.014}{.029} \\\\[2ex]\n&= 0.48\n\\end{split}\n\\]\nWe can interpret this as the proportion of all Minnesota children under 6 years of age who are above the MDH reference level in 2018 is less than half of that is 2012. Although typically we would put the larger number in the numerator, here we want to make the comparison back to the 2012 values, so we put that referent in the denominator. Remember, the choice of which value to put in the denominator is arbitrary‚Äîit just changes the interpretation.",
    "crumbs": [
      "Effect Size",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Standardized Effects for Proportions</span>"
    ]
  },
  {
    "objectID": "07-05-standardized-effects-props.html#confidence-interval-for-risk-ratio",
    "href": "07-05-standardized-effects-props.html#confidence-interval-for-risk-ratio",
    "title": "23¬† Standardized Effects for Proportions",
    "section": "23.3 Confidence Interval for Risk Ratio",
    "text": "23.3 Confidence Interval for Risk Ratio\nWe can compute a confidence interval for a risk ratio using the ci_risk_ratio() function from the {educate} package. This function takes the following arguments:\n\np1: Proportion for Sample 1\nn1: Sample size for Sample 1\nn1: Proportion for Sample 2\nn2: Sample size for Sample 2\nconf.level: The confidence level for the interval (default is conf.level = 0.95)\n\nFor example, to compute the 95% confidence interval for the risk ratio in our Bachelor/Bachelorette case study, we use the following syntax:\n\n# Compute CI for risk ratio\nci_risk_ratio(\n  p1 = 0.174, #Proportion for Bachelorette\n  n1 = 25,    #Sample size for Bachelorette\n  p2 = .111,  #Proportion for Bachelor\n  n2 = 27,    #Sample size for Bachelor\n  conf.level = 0.95\n  )\n\n\n--------------------------------------------------\n95% Confidence Interval\n--------------------------------------------------\n\nRisk Ratio = 1.567568\n\nLower Limit = 0.7941019\nUpper Limit = 3.094399\n\n--------------------------------------------------\n\n\nThe CI is \\([0.79,~3.09]\\), indicating that Bachelorettes (numerator proportion) are between 0.79 and 3.11 times as likely to stay together as Bachelors (denominator proportion). Note that the lower limit is below 1. This suggests that Bachelors are more likely than Bachelorettes to stay together with their chosen suitor. A risk ratio of 1 suggests that both groups are equally likely to stay together with their chosen suitor. So, this CI is indicating quite a lot of uncertainty:\n\nIt may be that Bachelorettes are LESS likely than Bachelors to stay together with their chosen suitor (up to 0.79 times as likely).\nIt may be that both groups are EQUALLY likely to stay together with their chosen suitor. Or,\nIt may be that Bachelorettes are MORE likely than Bachelors to stay together with their chosen suitor (up to 3.09 times as likely).\n\n\n\n23.3.1 Using conf_risk_ratio() With a Single Sample\n\n\n\n\n\n\n\n\n\n\n\nWe can also use the ci_risk_ratio() function to compare a single sample to a hypothesized value (e.g., in our MN lead exposure case study). To do this, whichever ‚Äúsample‚Äù you use to input the hypothesized value (say p2), the corresponding sample size is inputted as Inf (i.e., n2=Inf). This ensures that only the actual sample summaries are used to compute the uncertainty in the CI.\nFor example, to compute the CI for the risk ratio we computed earlier for the MN lead exposure example, we would input:\n\n# Compute CI for risk ratio\nci_risk_ratio(\n  p1 = 0.014, #Sample proportion\n  n1 = 91706,  #Sample size\n  p2 = .029, #Hypothesized value\n  n2 = Inf,   #Inf goes with the hypothesized value\n  conf.level = 0.95\n  )\n\n\n--------------------------------------------------\n95% Confidence Interval\n--------------------------------------------------\n\nRisk Ratio = 0.4827586\n\nLower Limit = 0.4698893\nUpper Limit = 0.4959804\n\n--------------------------------------------------\n\n\nThe CI is \\([0.470,~.496]\\), indicating the proportion of all Minnesota children under 6 years of age who are above the MDH reference level in 2018 is between .470 and .496 times that in 2012. The high level of precision in the estimate is attributable to the large sample size, so we can say with some degree of certainty that the 2018 numbers are likely less than half of those in 2012.\n\n\nYour Turn\nUse the ci_risk_ratio() function to compute the risk ratio and the 99% CI for the population risk ratio that compares the proportion of ‚ÄúFresh‚Äù reviews to the hypothesized value of 0.5.\n\nShow/Hide Solution\n\n\n\n# Compute CI for risk ratio\nci_risk_ratio(\n  p1 = 0.537, #Sample proportion\n  n1 = 238,   #Sample size\n  p2 = .5,    #Hypothesized value\n  n2 = Inf,   #Inf goes with the hypothesized value\n  conf.level = 0.99\n  )\n\n\n--------------------------------------------------\n99% Confidence Interval\n--------------------------------------------------\n\nRisk Ratio = 1.074\n\nLower Limit = 1.011569\nUpper Limit = 1.140284\n\n--------------------------------------------------\n\n\n\nInterpret the confidence interval by commenting on the plausible values in the interval.\n\nShow/Hide Solution\n\n\nThe CI is \\([1.01,~1.14]\\) indicating that the proportion of ‚Äúfresh‚Äù reviews is between 1.01 and 1.14 times higher than 0.5. While this suggests that Fast X will likely have more than half of its reviews rated as ‚Äúfresh‚Äù, it won‚Äôt be much over half.",
    "crumbs": [
      "Effect Size",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Standardized Effects for Proportions</span>"
    ]
  },
  {
    "objectID": "08-00-relationships.html",
    "href": "08-00-relationships.html",
    "title": "Statistical Relationships",
    "section": "",
    "text": "In the previous chapters, you were introduced to methods that a researcher can use to examine differences and some effect sizes to quantify the magnitude of those differences. For example, we could use those methods to answer research questions such as:\n\nAre teens getting a different amount of sleep that 9 hours?\nIs the proportion of all Minnesota children under 6 years of age who are above the MDH reference level in 2018 different than the proportion in 2012?\nAre the effects of marijuana on IQ different for users who started using marijuana as a teen compared to users who start using marijuana as adults?\nIs the proportion of Bachelor contestants that are still together with the suitor they chose different from the proportion of Bachelor contestants that are still together with the suitor they chose?\n\nAnother type of question that is common in the social and educational sciences is about the relationship between two attributes. These types of questions lay the groundwork for looking at predictors of our outcomes of interest. For example,\n\nWhat is the relationship between socioeconomic status and happiness?\nIs education level a predictor of income?\nHow well do SAT scores predict how well first year students‚Äô GPAs in college?\n\nIn the following chapters, you will learn about some of the visualizations, numeric summaries, and inferential methods that are used to examine ‚Äúrelationship‚Äù type research questions.",
    "crumbs": [
      "Statistical Relationships"
    ]
  },
  {
    "objectID": "08-01-scatterplot-correlation.html",
    "href": "08-01-scatterplot-correlation.html",
    "title": "24¬† Scatterplots and Correlation",
    "section": "",
    "text": "24.1 Case Study: Income and House Prices\nIt is common knowledge that some cities have a higher cost of living than others. Those higher cost-of-living cities, however, also tend to be the more metropolitan areas where jobs (especially higher paying jobs) are more prevalent. One question that we may want to study is whether there is a relationship between people‚Äôs incomes and house prices (a reasonable proxy for the cost-of-living). To do this, we will use the median_income and median_house_price attributes from the housing-and-income.csv dataset.\nlibrary(educate)\nlibrary(ggformula)\nlibrary(mosaic)\nlibrary(mosaicCore)\nlibrary(tidyverse)\n\n\n# Import data\nhouse_income &lt;- read_csv(\"https://raw.githubusercontent.com/zief0002/epsy-5261/main/data/housing-and-income.csv\")\n\n# View data\nhouse_income",
    "crumbs": [
      "Statistical Relationships",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Scatterplots and Correlation</span>"
    ]
  },
  {
    "objectID": "08-01-scatterplot-correlation.html#data-exploration",
    "href": "08-01-scatterplot-correlation.html#data-exploration",
    "title": "24¬† Scatterplots and Correlation",
    "section": "24.2 Data Exploration",
    "text": "24.2 Data Exploration\nAs always, we will begin with an initial exploration of the sample data, in particular the distributions of the median_income and median_house_price attributes.\n\n# Explore median_income\ngf_density(\n  ~median_income, data = house_income,\n  xlab = \"Median Income\",\n  ylab = \"Density\"\n  )\n\n\n\n\n\n\n\ndf_stats(~median_income, data = house_income)\n\n\n  \n\n\n\nThe median income for the 42 cities in the sample have a right-skewed distribution with a typical city having a median income of close to $70k (median). There is a great deal of variation in the median income across these cities, however, with the median income ranging from $32k to $148k, and the middle 50% of cities having median incomes ranging from $52 to $91k.\n\n# Explore median_house_price\ngf_density(\n  ~median_house_price, data = house_income,\n  xlab = \"Median House Price\",\n  ylab = \"Density\"\n  )\n\n\n\n\n\n\n\ndf_stats(~median_house_price, data = house_income)\n\n\n  \n\n\n\nThe median house price for the 42 cities in the sample also have a right-skewed distribution with a typical city having a median house price of $394k (median). There is a great deal of variation in the median house prices across these cities, however, with the median house price ranging from $97k to $1.5m, and the middle 50% of cities having median house prices ranging from $271 to $723k.",
    "crumbs": [
      "Statistical Relationships",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Scatterplots and Correlation</span>"
    ]
  },
  {
    "objectID": "08-01-scatterplot-correlation.html#relationship-between-variables",
    "href": "08-01-scatterplot-correlation.html#relationship-between-variables",
    "title": "24¬† Scatterplots and Correlation",
    "section": "24.3 Relationship Between Variables",
    "text": "24.3 Relationship Between Variables\nAlthough examining the distributions of each attribute independently is an important first step, those descriptions do not help us directly answer our research question. To better understand any relationship between income and house prices we need to explore how the distribution of house prices co-varies with the distribution income. To do this, we will create a scatterplot of median income versus median house price.\nTo create a scatterplot, we will use the gf_point() function from the {ggformula} package. The syntax for this function is similar to the othergf_ functions:\n\ngf_point(y ~ x, data = data_name)\n\nwhere y is the name of the attribute you want on the y-axis, x is the name of the variable you want on the x-axis, and data_name is the name of your object that you imported your data into. For example, to create a scatterplot in which median house price is on the y-axis, median income is on the x-axis, we can use the following syntax:\n\ngf_point(\n  median_house_price ~ median_income, data = house_income,\n  xlab = \"Median Income\",\n  ylab = \"Median House Price\"\n  )\n\n\n\n\nScatterplot displaying the relationship between median income and median house price for 42 cities.\n\n\n\n\nThe plot visually shows the relationship (at least for these cities) between median income and median house price. When describing the relationship we want to touch on four characteristics of the relationship:\n\nFunctional form of the relationship\nDirection/Trend\nMagnitude of the line, and\nStrength \n\n\n\n24.3.1 Functional Form of the Relationship\nA functional form refers to the algebraic (mathematical) description of the relationship between the two attributes included in the relationship. Common functional forms used in the social and educational sciences are linear, quadratic, exponential, and cyclical (e.g., sinusoidal). Figure¬†24.1 shows examples of these four functional forms.\n\n\n\n\n\n\n\n\nFigure¬†24.1: Four functional forms commonly used to describe relationships in the educational and social sciences.\n\n\n\n\n\nNote that the data in a scatterplot won‚Äôt follow these patterns perfectly, but you want to pick out the general form of the function. In our example, the relationship between median house prices and median income seems linear.\n\n\n\n24.3.2 Direction/Trend\nOnce we pick the functional form, the next thing we want to do is identify the direction/trend of the relationship. The direction/trend describes the overall ‚Äúslope‚Äù of the data and can be positive, negative, or flat. Figure¬†24.2 shows examples of a positive, negative, and flat linear relationship.\n\n\n\n\n\n\n\n\nFigure¬†24.2: A positive, negative, and flat linear relationship.\n\n\n\n\n\nA positive relationship would imply that lower values of x are associated with lower values of y and higher values of x are associated with higher values of y. A negative relationship, on the other hand, would imply that lower values of x are associated with higher values of y and higher values of x are associated with lower values of y. A flat relationship implies there is no relationship between x and y since all values of x are associated with the same y value.\n\nWhen you describe what the direction/trend implies, be careful about the language you use. For example, we would not want to say ‚Äúwhen x goes up, y goes up‚Äù when describing a positive relationship. This is because that statement is not true for all of our cases. The trend describes the general pattern in the relationship, which does not apply to all cases. That is why we use the wording ‚Äúis associated with‚Äù, which to other researchers indicates the general pattern. Other ways to describe a positive relationship would be that:\n\nOn average, higher values of x correspond to higher values of y.\nObservations that have higher values of x tend to have higher values of y.\n\n\n\n\n\n24.3.3 Magnitude\nThe magnitude of the relationship constitutes a description of the magnitude of change in the y-values for a given change in the x-values. Is an increase in x associated with a small change in the y-values? A big change in the y-values?\nTo better understand this, consider the three linear relationships in Figure¬†24.3. All three relationships depicted have a positive relationship; higher values of x are associated with higher values of y. However, the magnitude of change in the y-values is quite different as we increase x in these plots.\n\n\n\n\n\n\n\n\nFigure¬†24.3: A steep, moderately steep, and shallow, positive linear relationship.\n\n\n\n\n\nIn the left-hand panel, the magnitude of the relationship is quite large. Not only are higher values of x are associated with higher values of y, but those y-values are a lot larger for higher values of x. We can see this in the high degree of steepness of the line.\nCompare that to the middle panel where, again, higher values of x are associated with higher values of y, but the magnitude of the change in the y-values is much smaller. That is, the line in the middle panel is less steep. Finally, in the right-hand panel, again, higher values of x are associated with higher values of y, but now the magnitude of change in the y-values is very small. Here, the slope of the line is very shallow.\n\n\n\n24.3.4 Strength\nThe strength of the relationship describes how well the data adhere to the functional form. For example a strong linear relationship would be one in which the observations lie close to the line. Figure¬†24.4 shows three positive linear relationships, one that has weak, one that is moderate, and one that is strong.\n\n\n\n\n\n\n\n\nFigure¬†24.4: A weak, moderate, and strong positive linear relationship.\n\n\n\n\n\nAs you describe the strength of a relationship, know that the qualifiers ‚Äòweak‚Äô, ‚Äòmoderate‚Äô, and ‚Äòstrong‚Äô are somewhat subjective. For now, use your best judgment.\n\nAfter positing the functional form, put that line or curve on the scatterplot in your mind. This will help you better consider and describe the strength of the relationship. In a later chapter, we will actually learn how to do this in R.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n24.3.5 Back to the Example\nLet‚Äôs return to the scatterplot showing the relationship between median income and median house prices and use what we have learned to describe that relationship using the context of the data.\n\ngf_point(\n  median_house_price ~ median_income, data = house_income,\n  xlab = \"Median Income\",\n  ylab = \"Median House Price\"\n  )\n\n\n\n\nScatterplot displaying the relationship between median income and median house price for 42 cities.\n\n\n\n\nThe scatterplot suggests that there is a positive, linear relationship between median income and median house price for the 42 cities in our sample. This suggests that cities that have higher median incomes tend to also have higher median house prices. The magnitude of the relationship seems large as the slope of the relationship seems quite steep, indicating that even small changes in median income is associated with a big change in median house price. This relationship seems pretty strong, with the data clustered pretty close to the line that describes this relationship.",
    "crumbs": [
      "Statistical Relationships",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Scatterplots and Correlation</span>"
    ]
  },
  {
    "objectID": "08-01-scatterplot-correlation.html#plot-scale-and-human-perception",
    "href": "08-01-scatterplot-correlation.html#plot-scale-and-human-perception",
    "title": "24¬† Scatterplots and Correlation",
    "section": "24.4 Plot Scale and Human Perception",
    "text": "24.4 Plot Scale and Human Perception\nOne issue that arises when we describe the magnitude and strength of the relationship is that our guesstimate for both the magnitude of the effect and the strength of the relationship can be influenced by the x- and y-scale on our scatterplot. To illustrate this, Figure¬†24.5 shows the median income and house price data with two different scales on the axes.\n\n\n\n\n\n\n\n\nFigure¬†24.5: The two plots show the exact same data plotted using different scales on the x- and y-axis. This difference in scales can influence how we perceive both the magnitude and the strength of the relationship.\n\n\n\n\n\nIn the right-hand graph of Figure¬†24.5, we may perceive a stronger relationship than in the left-hand graph. We would also perceive that the magnitude of the effect (i.e., the slope of the linear function) is larger, that is the line looks steeper. This is problematic as the strength of the relationship is exactly the same in both graphs as it is the same data that is plotted.\nBecause of this, we often compute and report a numerical summary measures to quantify both the strength and the magnitude of the relationship. These measures are useful as they are not impacted by the scale we use to plot the data.",
    "crumbs": [
      "Statistical Relationships",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Scatterplots and Correlation</span>"
    ]
  },
  {
    "objectID": "08-01-scatterplot-correlation.html#correlation-quantifying-the-strength-of-the-relationship",
    "href": "08-01-scatterplot-correlation.html#correlation-quantifying-the-strength-of-the-relationship",
    "title": "24¬† Scatterplots and Correlation",
    "section": "24.5 Correlation: Quantifying the Strength of the Relationship",
    "text": "24.5 Correlation: Quantifying the Strength of the Relationship\nThe correlation coefficient is a numerical summary of the strength of a linear relationship. To compute the correlation coefficient, we will use the cor() function from the {mosaic} package. This function uses syntax similar to many of the other functions you have encountered thus far:\ncor(y ~ x, data = data_name)\nFor example, to compute the correlation coefficient between median incomes and median house prices, we use the following syntax:\n\ncor(median_house_price ~ median_income, data = house_income)\n\n[1] 0.9080798\n\n\n\nThe order of attributes in the cor() function is irrelevant. For example, you could use the syntax cor(y ~ x, data = data_name) or cor(x ~ y, data = data_name). The reason we suggest using y~x (rather than x~y) is that in fitting regression models, the syntax has to be y~x.\n\nThe correlation between median house price and median income is 0.908. Mathematically we use the lower-case letter ‚Äúr‚Äù to indicate a correlation. In our example,\n\\[\nr_{\\text{Mdn House Price, Mdn Income}} = 0.908\n\\]\nAs we interpret the value of a correlation coefficient, keep in mind the following properties:\n\nCorrelation has no units, it is just a value.\nCorrelation coefficients always fall between \\(-1\\) and \\(+1\\), that is \\(-1 \\leq r \\leq +1\\).\nThe sign of the correlation coefficient (positive or negative) indicates the direction of the relationship.\n\nThe size of the correlation coefficient gives us an indication of the strength of the relationship. Here are some guidelines to help you think about the strength of the relationship:\n\nA value of 0 would indicate no relationship.\nValues around \\(-0.2\\) or \\(+0.2\\) might indicate a weak linear relationship.\nValues around \\(-0.5\\) or \\(+0.5\\) might indicate a moderate linear relationship.\nValues around \\(-0.8\\) or \\(+0.8\\) might indicate a strong linear relationship.\nValues of \\(-1\\) or \\(+1\\) indicate a perfect linear relationship (super-duper strong).\n\nThese guidelines may or may not be useful. You really have to know the substantive literature in your discipline to know for sure what values indicate a strong or weak relationship. For example, in the educational sciences most of the relationships we see with educational outcomes (e.g., GPA, test scores) have correlation values that are less than 0.4. So \\(r \\approx 0.5\\) would be considered a strong relationship.\nReturning to our example, the correlation coefficient of 0.908 indicates a strong linear relationship between median income and median house prices. The positive value of the correlation coefficient also indicates that the relationship between median income and median house prices is positive. That is, cities with higher median incomes also tend to have higher median house prices.\n\n\n24.5.1 Correlation Only Measures a Linear Relationship\nIt is important to keep in mind that the correlation coefficient is only useful as a measure of the strength of the relationship when the relationship between variables is linear. Here is an example where the correlation coefficient would be misleading about the strength of the relationship.\n\n\n\n\n\n\n\n\nFigure¬†24.6: Hours of daylight versus day of the year for \\(n=75\\) days in Minneapolis.\n\n\n\n\n\nHere there is a perfect relationship between day of the year and hours of daylight. If you fitted a nonlinear model here, your ‚Äúline‚Äù would match the data exactly (no residual error!). But the correlation coefficient does not reflect that. The correlation coefficient would suggest that the relationship between day of the year and hours of daylight is weak (\\(r=-0.34\\)).\nAnother situation in which correlation can mislead is when you have subpopulations in your data. Here is an example of that.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†24.7: Salary versus neuroticism (0 = not at all neurotic; 7= very neurotic) as measured by the Big Five personality survey for \\(n=1000\\) employees from a Fortune 500 company.\n\n\n\n\n\n\n\nWarning: A numeric `legend.position` argument in `theme()` was deprecated in ggplot2\n3.5.0.\n‚Ñπ Please use the `legend.position.inside` argument of `theme()` instead.\n\n\n\n\n\n\n\n\nFigure¬†24.8: Salary versus neuroticism (0 = not at all neurotic; 7= very neurotic) as measured by the Big Five personality survey for \\(n=1000\\) employees from a Fortune 500 company. The data are colored by education level.\n\n\n\n\n\n\n\nIf we treat these data as one population (an assumption for using the correlation) the relationship between neurotocism and salary is positive; employees who are more neurotic tend to have higher salaries, on average. However, if we account for education level, the relationship between neurotocism and salary is negative for each of the education levels; once we account for education level, employees who are more neurotic tend to have lower salaries, on average. This reversal of the direction of the relationship once we account for other variables is quite common (so common it has a name, Simpson‚Äôs Paradox) and makes it difficult to be sure about the ‚Äútrue‚Äù relationship between variables in observational data.\n\nYou should always create a scatterplot to examine the relationship graphically before computing a correlation coefficient to numerically summarize it.",
    "crumbs": [
      "Statistical Relationships",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Scatterplots and Correlation</span>"
    ]
  },
  {
    "objectID": "08-01-scatterplot-correlation.html#references",
    "href": "08-01-scatterplot-correlation.html#references",
    "title": "24¬† Scatterplots and Correlation",
    "section": "24.6 References",
    "text": "24.6 References",
    "crumbs": [
      "Statistical Relationships",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Scatterplots and Correlation</span>"
    ]
  },
  {
    "objectID": "08-02-linear-regression-description.html",
    "href": "08-02-linear-regression-description.html",
    "title": "25¬† Linear Regression‚ÄîDescription",
    "section": "",
    "text": "25.1 Case Study: College Completion Rates and ACT Scores\nThe ACT is designed to measure the skills that are acquired in secondary education that are most important for success in postsecondary education. If this is the case, we would expect that postsecondary institutions that admit students with higher ACT scores would have better outcomes. In other words:\nTo answer this question, we are going to examine the relationship between the 75th percentile ACT scores and the six-year completion rates for a sample of 92 postsecondary institutions in Minnesota and its adjacent states. To do this, we will be using the attributes act and completion_rate from the midwest-college-scorecard.csv dataset.\nlibrary(educate)\nlibrary(ggformula)\nlibrary(mosaic)\nlibrary(mosaicCore)\nlibrary(tidyverse)\n\n\n# Import data\ncolleges &lt;- read_csv(\"https://raw.githubusercontent.com/zief0002/epsy-5261/main/data/midwest-college-scorecard.csv\")\n\n# View data\ncolleges",
    "crumbs": [
      "Statistical Relationships",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Linear Regression---Description</span>"
    ]
  },
  {
    "objectID": "08-02-linear-regression-description.html#case-study-college-completion-rates-and-act-scores",
    "href": "08-02-linear-regression-description.html#case-study-college-completion-rates-and-act-scores",
    "title": "25¬† Linear Regression‚ÄîDescription",
    "section": "",
    "text": "Are ACT scores predictive of better institutional outcomes?\n\n\n\n\n25.1.1 Data Exploration\nAs always, we will begin with an initial exploration of the sample data, in particular the distributions of the act and completion_rate attributes.\n\n# Explore completion rates\ngf_density(\n  ~completion_rate, data = colleges,\n  color = \"black\",\n  fill = \"#722F37\",\n  xlab = \"Completion rate\",\n  ylab = \"Density\"\n  )\n\n\n\n\nDensity plot of completion rates for the 92 institutions in the sample.\n\n\n\ndf_stats(~completion_rate, data = colleges)\n\n\n\n\nDensity plot of completion rates for the 92 institutions in the sample.\n\n\nThe distribution of completion rates for the 92 colleges in the sample is unimodal and symmetric, with a typical institution having a completion rate of around 0.62 (mean). There is a great deal of variation in completion rates, with institutional completion rates ranging from 0.23 to 0.91. Most institutions have a completion rate between 0.48 and 0.76 (SD = 0.14).\n\n# Explore wine rating\ngf_density(\n  ~act, data = colleges,\n  color = \"black\",\n  fill = \"#722F37\",\n  xlab = \"75th percentil ACT score\",\n  ylab = \"Density\"\n  )\n\n\n\n\nDensity plot of ACT scores for the 92 colleges in the sample.\n\n\n\ndf_stats(~act, data = colleges)\n\n\n\n\nDensity plot of ACT scores for the 92 colleges in the sample.\n\n\nThe sample distribution of 75th percentile ACT scores is right skewed, with a typical institution having a 75th percentile ACT score of 26 (median). There is variation in these scores, with institutions having 75th percentile ACT score between 20 and 35. The middle 50% of the institutions have 75th percentile ACT score between 24 and 28.\n\n\n\n25.1.2 Relationship Between Variables\nTo explore the relationship between ACT scores and completion rates we will create a scatterplot of these attributes. Because we ultimately want to predict institutions‚Äô completion rates based on their ACT scores, we will put completion rate (the outcome, or attribute we want to predict) on the y-axis and ACT score (predictor) on the x-axis. We will also compute the correlation coefficient between these attributes.\n\ngf_point(\n  completion_rate ~ act, data = colleges,\n  xlab = \"75th percentile ACT score\",\n  ylab = \"Completion rate\"\n  )\n\n\n\n\nScatterplot displaying the relationship between wine price and rating for the 90 wines in the sample.\n\n\n\ncor(completion_rate ~ act, data = colleges)\n\n[1] 0.8083368\n\n\nThe plot visually shows the relationship (at least for these institutions) between 75th percentile ACT score and completion rate. When describing the relationship, remember, we want to touch on four characteristics of the relationship:\n\nFunctional form of the relationship\nDirection/Trend\nMagnitude of the line, and\nStrength\n\nThe scatterplot suggests that there is a positive, linear relationship between 75th percentile ACT score and completion rate for the 92 institutions in our sample. This suggests that colleges that have higher 75th percentile ACT scores tend to also have higher completion rates. The magnitude of the relationship seems large as the slope of the relationship seems quite steep, indicating that even small changes in 75th percentle ACT score is associated with a big change in completion rates. This relationship seems pretty strong, with the data clustered pretty close to the line that describes this relationship (\\(r = 0.808\\)).",
    "crumbs": [
      "Statistical Relationships",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Linear Regression---Description</span>"
    ]
  },
  {
    "objectID": "08-02-linear-regression-description.html#statistical-model-mathematical-description-of-the-data",
    "href": "08-02-linear-regression-description.html#statistical-model-mathematical-description-of-the-data",
    "title": "25¬† Linear Regression‚ÄîDescription",
    "section": "25.2 Statistical Model: Mathematical Description of the Data",
    "text": "25.2 Statistical Model: Mathematical Description of the Data\nSince the relationship‚Äôs functional form seems reasonably linear, we will use a linear model to describe the data. We can express this model mathematically as,\n\\[\nY = \\beta_0 + \\beta_1(X) + \\epsilon\n\\]\nIn this equation,\n\n\\(Y\\) is the outcome/response value,\n\\(\\beta_0\\) is the intercept of the line that best fits the data,\n\\(\\beta_1\\) is the slope of the line that best fits the data,\n\\(X\\) is the predictor value,\n\\(\\epsilon\\) is the error term (a.k.a. residual).\n\nThe regression model describes the relationship between Y-values and X-values in the population. Every term in the model denoted using a Greek letter is an unknown parameter in this model. In the model we have written there are three unknown parameters denoted in the model: the intercept term (\\(\\beta_0\\)), the slope term (\\(\\beta_1\\)), and the residual term (\\(\\epsilon_i\\)).1\n\n\n25.2.1 Visual Representation of the Regression Model\nTo help better understand the model, consider the following plot:\n\n\n\n\n\n\n\n\nFigure¬†25.1: Plot displaying conditional distribution of Y at several X values. The OLS fitted regression line (dotted) is also shown. The red points show the mean value of Y for each conditional distribution.\n\n\n\n\n\nThis plot shows that at each value of X there is a distribution of Y. These distributions are called conditional distributions. For example, there would be a conditional distribution of completion rates for the institutions with a 75th percentile ACT score of 20 (in the population). There would be another distribution of completion rates for the institutions with a 75th percentile ACT score of 21 (in the population). And so on.\nEach conditional distribution of Y has a mean; the conditional mean, which we denote as \\(\\hat{Y}\\). These conditional means can be connected using a line. This is what it means to be able to express the conditional mean of Y as a linear function of X, or to say that the relationship between X and Y is linear.\n\n\n\n25.2.2 Two Components of the Statistical Model\nThe linear statistical model (i.e., the regression model) can be separated into two components: the conditional mean component and an error component.\n\\[\nY = \\underbrace{\\beta_0 + \\beta_1(X)}_{\\substack{\\text{Conditional} \\\\ \\text{Mean}}} + \\underbrace{\\epsilon}_{\\substack{\\text{Error}}}\n\\]\nThe first part of the equation gives the conditional mean value of Y, that is the mean value of Y for a particular X-value. The conditional mean of Y given a particular X value is denoted as \\(\\hat{Y}\\). We express the conditional mean mathematically as,\n\\[\n\\hat{Y} = \\beta_0 + \\beta_1(X)\n\\]\nThis part of the regression model is a description, in mathematical form, of how the conditional mean Y is related to X. The equation here indicates that the conditional mean of Y is a linear function of X. This implies that the conditional mean value of Y differs by a constant amount for a constant difference in X.\nFor example, the difference between the mean completion rate for institutions that have a 75th percentile ACT score of 20 and those that have a 75th percentile ACT score of 21 is the same as the difference between the mean completion rate for institutions that have a 75th percentile ACT score of 30 and those that have a 75th percentile ACT score of 31.\nFrom the visual representation of the model, Figure¬†27.5, we can see that there is a distribution of Y-values at each X-value; this is represented by the normal distributions in the picture. In our example, there are many institutions who have the same 75th percentile ACT score, but have different completion rates. The error term in the statistical model accounts for this variation in Y for those cases that have the same X-value. Mathematically we can understand this by re-writing the statistical model, substituting \\(\\hat{Y}\\) into the first part of the model.\n\\[\n\\begin{split}\nY &= \\beta_0 + \\beta_1(X) + \\epsilon \\\\[2ex]\nY &= \\hat{Y} + \\epsilon\n\\end{split}\n\\]\nThis equation implies that each observed Y-value is the sum of the conditional mean value of Y (which is based on the X-value) and some residual (or error) term.\nTo further understand the residual term, consider the plot below. This figure shows the relationship between 75th percentile ACT scores and completion rates we plotted earlier. It also includes the regression line.\n\n\n\n\n\nScatterplot displaying the relationship between 75th percentile ACT scores and completion rates. The OLS fitted regression line is also displayed. The blue point is the mean completion rate for colleges with a 75th percentile ACT score of 21.\n\n\n\n\nConsider the three institutions that have a 75th percentile ACT score of 21. The conditional mean completion rate for these institutions is approximately 0.42. This is denoted by the blue point. (Remember, the conditional means are on the regression line.) The error (residual) term allows for a discrepancy between the conditional mean of Y and the observed Y. In other words, none of these three institutions have an actual completion rate of 0.42. The residual represents the difference between an institution‚Äôs observed completion rate and the conditional mean completion rate.\nGraphically, the residual is represented by the vertical distance between the line and a given point on the scatterplot. Some of those points are above the line (they have a positive residual) and some are below the line (they have a negative residual). Also note that for some observations the error term is smaller than for others.",
    "crumbs": [
      "Statistical Relationships",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Linear Regression---Description</span>"
    ]
  },
  {
    "objectID": "08-02-linear-regression-description.html#estimating-parameters-in-the-regression-model",
    "href": "08-02-linear-regression-description.html#estimating-parameters-in-the-regression-model",
    "title": "25¬† Linear Regression‚ÄîDescription",
    "section": "25.3 Estimating Parameters in the Regression Model",
    "text": "25.3 Estimating Parameters in the Regression Model\nThe terms \\(\\beta_0\\) and \\(\\beta_1\\) in the statistical model are referred to as the regression parameters. One of the primary goals of a regression analysis is to estimate the values of the regression parameters (i.e., the intercept and slope terms).\nIn most statistical analyses, you will use a sample of data (not the entire population) to estimate the parameter values. Because a sample is only a subset of the population, the values we obtain for the parameters are imperfect estimates. To denote that the parameters are sample-based estimates, we denote estimates using Roman letters. For example, estimates of the parameters \\(\\beta_0\\) and \\(\\beta_1\\) are obtained after fitting the model to data. For example the estimated conditional means can be expressed mathematically as:\n\\[\n\\hat{Y} = b_0 + b_1(X)\n\\]\n\n\n25.3.1 Fitting a Regression Model to Data Using R\nTo fit the regression model to data using R, we will use the lm() function. The syntax for this function looks like this:\n\nlm(outcome ~ 1 + predictor, data = dataframe)\n\nwhere outcome is the name of the outcome/response attribute, predictor is the name of the predictor attribute, and dataframe is the name of the data frame. (The 1 on the right side of the tilde tells R to include the intercept in its computation.) When we fit a regression model in R, we will also assign the output to a new object in R. Below, we fit the model using education level to predict income. Here the output is assigned to an object called lm.a. We can print the regression parameter estimates by typing the lm() object name and hitting enter.\n\n# Fit regression model\nlm.a = lm(completion_rate ~ 1 + act, data = colleges)\n\n# Print regression coefficients\nlm.a\n\n\nCall:\nlm(formula = completion_rate ~ 1 + act, data = colleges)\n\nCoefficients:\n(Intercept)          act  \n   -0.36421      0.03738  \n\n\nHere the parameter estimates (or regression coefficients) are:\n\n\\(b_0 = -0.36\\)\n\\(b_1 = .04\\)\n\nRemember that these are estimates obtained from fitting the model to the sample data, and therefore we use the Roman letters to denote their values. Once we have the parameter estimates, we write the fitted equation which gives the mathematical description of the conditional means of Y. Based on our estimates, the fitted equation is:\n\\[\n\\hat{\\mathrm{Completion~Rate}} = -0.36 + 0.04(\\mathrm{ACT})\n\\]\n\n\n\n25.3.2 Intercept Interpretation\nThe estimate for the intercept was \\(-0.36\\). Graphically, this value indicates the value where the line passes through the Y-axis (i.e., Y-intercept). As such, it gives the \\(\\hat{Y}\\) or predicted conditional mean value when \\(X=0\\). Algebraically we get the same thing if we substitute 0 in for X in the fitted regression equation.\n\\[\n\\begin{split}\n\\hat{\\mathrm{Completion~Rate}} &= -0.36 + 0.04(\\mathrm{ACT}) \\\\[2ex]\n&= -0.36 + 0.04(0) \\\\[2ex]\n&= -0.36\n\\end{split}\n\\]\nInterpreting the intercept coefficient in our example,\n\nThe intercept of \\(-0.36\\) is the predicted mean completion rate for all institutions that have a 75th percentile ACT score of 0.\n\n\n\n\n25.3.3 Slope Interpretation\nRecall from algebra that the slope of a line describes the change in Y versus the change in X. In regression, the slope describes the predicted change in \\(\\hat{Y}\\) for a one-unit difference in X. In our example,\n\\[\nb_1 = \\frac{\\Delta\\hat{Y}}{\\Delta X} = \\frac{0.04}{1}\n\\]\nAgain, because \\(\\hat{Y}\\) is a conditional mean, the slope represents the difference in predicted mean completion rates for each one-point difference in 75th percentile ACT score. Interpreting the slope coefficient in our example,\n\nEach one-point difference in 75th percentile ACT score is associated with a model predicted difference of 4 percentage points in mean completion rate.\n\nTo better understand this, consider colleges with different 75th percentile ACT scores. The first set of colleges have a 75th percentile ACT score of 20. The second set has a 75th percentile ACT score of 21, and the third set has a 75th percentile ACT score of 22. Now let‚Äôs compute the predicted mean completion rate for each of these institutions using our fitted equation.\n\\[\n\\begin{split}\n\\mathbf{ACT=20:~~} \\hat{\\mathrm{Completion~Rate}} &= -0.36 + 0.04(20) \\\\[2ex]\n&= 0.44\n\\end{split}\n\\]\n\\[\n\\begin{split}\n\\mathbf{ACT=21:~~} \\hat{\\mathrm{Completion~Rate}} &= -0.36 + 0.04(21) \\\\[2ex]\n&= 0.48\n\\end{split}\n\\]\n\\[\n\\begin{split}\n\\mathbf{ACT=22:~~} \\hat{\\mathrm{Completion~Rate}} &= -0.36 + 0.04(22) \\\\[2ex]\n&= 0.52\n\\end{split}\n\\]\nThe completion rate for colleges having a 75th percentile ACT score that differs by one point (e.g., 20 to 21) is expected, on average, to differ by 4 percentage points (.04).",
    "crumbs": [
      "Statistical Relationships",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Linear Regression---Description</span>"
    ]
  },
  {
    "objectID": "08-02-linear-regression-description.html#estimating-errorsresiduals",
    "href": "08-02-linear-regression-description.html#estimating-errorsresiduals",
    "title": "25¬† Linear Regression‚ÄîDescription",
    "section": "25.4 Estimating Errors/Residuals",
    "text": "25.4 Estimating Errors/Residuals\nNote that we can also use the estimated regression coefficients to obtain estimates for the residuals, often referred to as the observed residuals. Here we make use of the earlier idea that the residual term was the difference between the observed value of Y and the conditional mean of Y for a given X-value. Mathematically,\n\\[\n\\epsilon = Y - \\hat{Y}\n\\]\nOnce we use data to obtain estimates for the intercept and slope (\\(b_0\\) and \\(b_1\\)) we can substitute those into the fitted equation and obtain an estimate for the conditional mean (\\(\\hat{Y}\\)). This value can then be used to obtain an estimate for the residual.\n\\[\ne = Y - \\hat{Y}\n\\]\nRemember, the use of the roman letter ‚Äúe‚Äù for the residual indicates it is an estimate based on values obtained from the data!\nAs an example, consider the data for the Marquette University.\n\n\n\n  \n\n\n\nMarquette University has a 75th percentile ACT score of 30, and its observed completion rate is 0.814.\nUsing the fitted regression equation, we can compute the predicted conditional mean completion rate for institutions with a 75th percentile ACT score of 30 as,\n\\[\n\\begin{split}\n\\hat{\\mathrm{Completion~Rate}} &= -0.3642 + 0.0374(30) \\\\[2ex]\n&= 0.757\n\\end{split}\n\\]\nNow we can use the estimated conditional mean to also compute Marquette University‚Äôs residual.\n\\[\n\\begin{split}\ne &= \\mathrm{Completion~Rate} - \\hat{\\mathrm{Completion~Rate}}\\\\[2ex]\n&= 0.814 - 0.757 \\\\[2ex]\n&= 0.057\n\\end{split}\n\\]\nThe positive residual suggests that Marquette University has a completion rate that is 0.057 higher than the average predicted completion rate for colleges with a 75th percentile ACT score of 30. We can also represent these values graphically.\n\n\n\n\n\nPlot displaying the 75th ACT scores and completion rates along with the fitted regression line (blue). Marquette University‚Äôs observed completion rate (pink dot) and the predicted mean for colleges with a 75th percentile ACT score of 30 (blue dot) are both plotted. A visual representation of Marquette University‚Äôs residual (green line) is also displayed.",
    "crumbs": [
      "Statistical Relationships",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Linear Regression---Description</span>"
    ]
  },
  {
    "objectID": "08-02-linear-regression-description.html#answering-the-research-question",
    "href": "08-02-linear-regression-description.html#answering-the-research-question",
    "title": "25¬† Linear Regression‚ÄîDescription",
    "section": "25.5 Answering the Research Question",
    "text": "25.5 Answering the Research Question\nRemember that this whole analysis was driven because we wanted to answer a question, namely whether 75th percentile ACT scores are predictive of college completion rates. The results from the regression analysis allow us to answer this question.\n\nTo answer the question of whether 75th percentile ACT scores are predictive of college completion rates, a linear regression model was fitted to the data. The results of this analysis suggested that 75th percentile ACT scores are positively related to completion rates for the 92 sample colleges (\\(b_1 = 0.037\\)). Each 1-point difference in 75th percentile ACT scores of education is associated with a 0.037-unit difference in completion rates, on average.",
    "crumbs": [
      "Statistical Relationships",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Linear Regression---Description</span>"
    ]
  },
  {
    "objectID": "08-02-linear-regression-description.html#footnotes",
    "href": "08-02-linear-regression-description.html#footnotes",
    "title": "25¬† Linear Regression‚ÄîDescription",
    "section": "",
    "text": "Technically there are many unknown residuals, one for each case, but the assumptions we put on the linear model make it so that we only care about the variance of the residuals, hence a single unknown.‚Ü©Ô∏é",
    "crumbs": [
      "Statistical Relationships",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Linear Regression---Description</span>"
    ]
  },
  {
    "objectID": "08-03-r-squared.html",
    "href": "08-03-r-squared.html",
    "title": "26¬† \\(R^2\\): Quantifying the Strength of the Linear Relationship",
    "section": "",
    "text": "26.1 Recap: College Completion Rates and ACT Scores\nIn Chapter 25, we fitted a linear regression model to answer the research question of whether ACT scores are predictive of better institutional outcomes.\nlibrary(educate)\nlibrary(ggformula)\nlibrary(mosaic)\nlibrary(mosaicCore)\nlibrary(tidyverse)\n\n\n# Import data\ncolleges &lt;- read_csv(\"https://raw.githubusercontent.com/zief0002/epsy-5261/main/data/midwest-college-scorecard.csv\")\n\n# View data\ncolleges\n\n\n  \n\n\n# Compute correlation\ncor(completion_rate ~ act, data = colleges)\n\n[1] 0.8083368\n\n# Fit regression model\nlm.a = lm(completion_rate ~ 1 + act, data = colleges)\n\n# Print regression coefficients\nlm.a\n\n\nCall:\nlm(formula = completion_rate ~ 1 + act, data = colleges)\n\nCoefficients:\n(Intercept)          act  \n   -0.36421      0.03738\nThe data suggested that there was a positive, linear relationship between 75th percentile ACT score and completion rate for the 92 institutions in our sample (\\(r = 0.808\\)), indicating that colleges with higher 75th percentile ACT scores tended to also have higher completion rates. The fitted equation was:\n\\[\n\\hat{\\mathrm{Completion~Rate}} = -0.36 + 0.04(\\mathrm{ACT})\n\\]\nThe results of the regression analysis suggested that each 1-point difference in 75th percentile ACT scores of education is associated with a 0.037-unit difference in completion rates, on average.",
    "crumbs": [
      "Statistical Relationships",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>$R^2$: Quantifying the Strength of the Linear Relationship</span>"
    ]
  },
  {
    "objectID": "08-03-r-squared.html#recap-college-completion-rates-and-act-scores",
    "href": "08-03-r-squared.html#recap-college-completion-rates-and-act-scores",
    "title": "26¬† \\(R^2\\): Quantifying the Strength of the Linear Relationship",
    "section": "",
    "text": "26.1.1 Quantifying Aspects of the Relationship\nRemember that when we describe a relationship between two quantitative attributes, we touch on four characteristics of the relationship:\n\nFunctional form of the relationship\nDirection/Trend\nMagnitude of the line, and\nStrength\n\nThe functional form helps us decide the mathematical form that the model should take (e.g., linear, quadratic). It also helps us determine the appropriate summary measures that can help quantify the other three characteristics we describe. For example, the correlation coefficient (r) helps us quantify the direction of the relationship, as does the slope of the regression line (\\(b_1\\)). The slope of the regression line also quantifies the magnitude (i.e., ‚Äústeepness‚Äù) of the relationship.\nNeither the correlation coefficient, nor the slope, however, provide a quantification of the strength of the relationship. Remember that the strength of the relationship describes how well the data adhere to the functional form (i.e., how closely the observations lie to the line).\nOnce we have the fitted equation, we can add that to the scatterplot to better evaluate the strength of the linear relationship. To do this we will use the geom_abline() function, which takes the arguments intercept= and slope=. We provide the estimates for these coefficients from our fitted equation to these arguments, and then literally add this function to the scatterplot.\n\ngf_point(\n  completion_rate ~ act, data = colleges,\n  xlab = \"75th percentile ACT score\",\n  ylab = \"Completion rate\"\n  ) +\n  geom_abline(\n    intercept = -0.36421, \n    slope = 0.03738,\n    color = \"blue\"\n    )\n\n\n\n\nScatterplot displaying the relationship between wine price and rating for the 90 wines in the sample. The fitted linear regression line is also displayed on the plot.\n\n\n\n\nThis relationship seems pretty strong, with the data generally clustered pretty close to the line that describes this relationship.",
    "crumbs": [
      "Statistical Relationships",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>$R^2$: Quantifying the Strength of the Linear Relationship</span>"
    ]
  },
  {
    "objectID": "08-03-r-squared.html#residuals-the-key-to-measuring-closeness-to-the-line",
    "href": "08-03-r-squared.html#residuals-the-key-to-measuring-closeness-to-the-line",
    "title": "26¬† \\(R^2\\): Quantifying the Strength of the Linear Relationship",
    "section": "26.2 Residuals: The Key to Measuring ‚ÄúCloseness‚Äù to the Line",
    "text": "26.2 Residuals: The Key to Measuring ‚ÄúCloseness‚Äù to the Line\nRemember that visually, the residual is the vertical distance between the point and the regression line. In the previous chapter, we illustrated this by showing the residual for the Marquette University, which was 0.057.\n\n\n\n\n\nPlot displaying the 75th ACT scores and completion rates along with the fitted regression line (blue). Marquette University‚Äôs observed completion rate (pink dot) and the predicted mean for colleges with a 75th percentile ACT score of 30 (blue dot) are both plotted. A visual representation of Marquette University‚Äôs residual (green line) is also displayed.\n\n\n\n\nGraphically, the length of the vertical line represents the value of the residual‚Äîin the case of Marquette University, the length of the vertical line is 0.057 units. (The metric is the same as the original y attribute; in this case completion rate.) Because the vertical line is above the regression line, we know the sign on the residual is positive. Figure¬†26.1 shows the plotted residuals for all 92 observations. (Note that for any set of colleges with the same ACT score, there is potential for their residual lines to be on top of other residual lines.)\n\n\n\n\n\n\n\n\nFigure¬†26.1: Plot displaying the 75th ACT scores and completion rates along with the fitted regression line (blue). A visual representation of each university‚Äôs residual (green lines) is also displayed.\n\n\n\n\n\nIn general, if the observation is close to the line, the green line for the residuals is short, whereas if the observation is far away from the line the green line for the residuals is long. We can use this idea to quantify the strength of the relationship. That is, we can consider whether, in general, the green residual lines are short or long.\nWhile we can eyeball this from the plot, we want to quantify how close the observations are to the line. Recall that we can compute each observation‚Äôs residual using:\n\\[\ne = Y - \\hat{Y}\n\\]\nWe can use the resid() function to compute the residuals in R. We provide this function with the name of the lm() object, in our case lm.a.\n\n# Get residuals\nmy_residuals &lt;- resid(lm.a)\n\n# View residuals\nmy_residuals\n\n            1             2             3             4             5 \n 0.0574753580  0.0910753580  0.0493379949 -0.1195312342  0.0585314027 \n            6             7             8             9            10 \n-0.0131125527  0.1380940396 -0.0850872789 -0.0589433235  0.0493193134 \n           11            12            13            14            15 \n-0.0379565080  0.0780314027 -0.1584180497  0.0173500842  0.0056500842 \n           16            17            18            19            20 \n 0.1207193134  0.0813940396  0.0626127211 -0.0007872789  0.0443127211 \n           21            22            23            24            25 \n-0.1474433235  0.0911940396 -0.0993993682  0.0477566765 -0.0944246420 \n           26            27            28            29            30 \n 0.0606314027 -0.0296378265  0.1345940396  0.1034127211 -0.0106125527 \n           31            32            33            34            35 \n 0.0412940396  0.0275248104 -0.0520246420  0.0101061289 -0.0357685973 \n           36            37            38            39            40 \n-0.0011246420  0.1217127211 -0.0610433235  0.1046314027 -0.0191751896 \n           41            42            43            44            45 \n 0.0065127211  0.0985314027 -0.0136059604  0.0596753580 -0.0945806866 \n           46            47            48            49            50 \n 0.0235566765 -0.2144433235 -0.0305620051  0.0100940396  0.0409940396 \n           51            52            53            54            55 \n 0.0362379949  0.0232314027 -0.0707620051 -0.1402059604 -0.0217246420 \n           56            57            58            59            60 \n 0.0770566765 -0.0572433235 -0.1116806866 -0.1967499158  0.0251753580 \n           61            62            63            64            65 \n 0.0306753580  0.0532566765  0.0522314027  0.1167006318  0.0291127211 \n           66            67            68            69            70 \n 0.0353127211 -0.0157059604 -0.0273938711 -0.0768872789  0.0628379949 \n           71            72            73            74            75 \n 0.0563687658 -0.0973312342  0.0860006318 -0.0623872789 -0.0246872789 \n           76            77            78            79            80 \n 0.0605500842  0.0386940396  0.1017566765  0.0727940396 -0.0242246420 \n           81            82            83            84            85 \n 0.1224940396 -0.0719685973  0.0562379949 -0.1178433235 -0.0466059604 \n           86            87            88            89            90 \n-0.1031433235  0.0600061289 -0.0968246420 -0.0181059604 -0.0039246420 \n           91            92 \n-0.0158246420 -0.2539499158 \n\n\nThese residuals are in the same order as the observations in the data; the first observation in the data is Buena Vista University which corresponds to the first residual of 0.0574753580. To quantify the strength we need to determine whether these residuals are small or big, in general. One way to do that is to find the size of the average residual:\n\n# Compute average residual\nmean(my_residuals)\n\n[1] 2.413528e-18\n\n\nThe value we get is in scientific notation. The e-18 means ‚Äútimes 10 to the \\(-18\\)th power. That is:\n\\[\n\\begin{split}\n-1.046491e-18 &= -1.046491 \\times 10^{-18} \\\\[2ex]\n&= -0.00000000000000000104691\n\\end{split}\n\\]\nThis is essentially equal to 0. We are saying that the average residual is 0! That is completely not true. Looking at the scatterplot, it is clear that the average residual will have some length‚Ä¶not 0. The problem is that some of the residuals are positive and some are negative, so adding them together gives a sum of 0.\n\\[\n\\sum e = 0\n\\]\nBecause of this finding the average does not help us quantify the strength of the relationship.\n\n\n26.2.1 Sum of Squared Error\nTo remedy this problem before we sum the residuals, we will square them to make them all positive. Mathematically, we are computing:\n\\[\n\\sum e^2\n\\]\nUsing R, we will square the residuals and then use the sum() function to add them together.\n\nsum(my_residuals ^ 2)\n\n[1] 0.6120481\n\n\nThis value is refer to as the Sum of Squares Residual or the Sum of Squared Error (SSE). It is a quantification of the total amount of error in the model (albeit in a squared metric). In our example,\n\\[\n\\text{SSE} = 0.612\n\\]",
    "crumbs": [
      "Statistical Relationships",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>$R^2$: Quantifying the Strength of the Linear Relationship</span>"
    ]
  },
  {
    "objectID": "08-03-r-squared.html#comparing-sse-to-a-baseline-model",
    "href": "08-03-r-squared.html#comparing-sse-to-a-baseline-model",
    "title": "26¬† \\(R^2\\): Quantifying the Strength of the Linear Relationship",
    "section": "26.3 Comparing SSE to a Baseline Model",
    "text": "26.3 Comparing SSE to a Baseline Model\nWhile the SSE gives us a quantification of the total amount of error in the model it isn‚Äôt useful (by itself) for considering the strength of the relationship. This is for two reasons. First finding the average of this sum is not helpful as the metric has changed to squared completion rates. Even if we converted back to the original metric by taking the square root after finding the average, we still don‚Äôt know if the value represents a ‚Äúweak‚Äù, ‚Äúmoderate‚Äù, or ‚Äústrong‚Äù relationship. This is because the quantification would be dependent on the metric used in the y attribute, which is our second problem. This implies that you would have to evaluate strength differently depending on how you measured the attribute you use as your outcome. Ideally, we want to use a measure that does not depend on the metric used in the attribute.\nThe solution to this is to compare the SSE value to a SSE value computed from a ‚Äúbaseline‚Äù model. The baseline model that we will use is the intercept-only model. The intercept-only model is mathematically expressed as:\n\\[\nY = \\beta_0 + \\epsilon\n\\]\nThat is, it only includes the y-intercept and does not include any other effects. If we use this model to predict completion rates we are saying that ACT scores do not matter in predicting colleges‚Äô completion rates as it is not included in the model. To fit this model we use lm(y ~ 1, data=dataframe).\n\n# Fit intercept-only model\nlm.0 = lm(completion_rate ~ 1, data = colleges)\n\n# View coefficient\nlm.0\n\n\nCall:\nlm(formula = completion_rate ~ 1, data = colleges)\n\nCoefficients:\n(Intercept)  \n     0.6175  \n\n\nHere the fitted equation is:\n\\[\n\\hat{\\text{Completion Rate}} = 0.618\n\\]\nWe can plot this regression line using geom_abline() in the same way we plot any other regression line, noting that the slope of this line is 0.\n\ngf_point(\n  completion_rate ~ act, data = colleges,\n  xlab = \"75th percentile ACT score\",\n  ylab = \"Completion rate\"\n  ) +\n  geom_abline(\n    intercept = 0.6175, \n    slope = 0,\n    color = \"blue\"\n    )\n\n\n\n\nScatterplot displaying the relationship between wine price and rating for the 90 wines in the sample. The fitted intercept-only linear regression line is also displayed on the plot.\n\n\n\n\nThe intercept-only line is a flat line. Think about what this means for predictions. Consider a college that has a 75th percentile ACT score of 20. Their predicted completion rate from this model is 0.6175. What about a college that has a 75th percentile ACT score of 25? Their predicted completion rate from this model is also 0.6175. How about a college that has a 75th percentile ACT score of 35. Their predicted completion rate from this model is also 0.6175. ACT score DOES NOT matter in the prediction of completion rate!\n\nOne interesting fact about the value of 0.6175 is that it is the mean completion rate for all schools in the sample.\n\ndf_stats(~completion_rate, data = colleges)\n\n\n  \n\n\n\nThis implies that the predicted value for the intercept-only model, regardless of a school‚Äôs ACT score will be the mean completion rate. That is, when we aren‚Äôt using any information (predictors) to predict something, the best prediction is the mean.\n\n\n\n26.3.1 SSE from the Baseline Model\nWe can also compute the residuals and SSE for the baseline model. Figure¬†26.2 shows the residuals for both the intercept only model and the model that included ACT as a predictor of completion rates. From these plots, you can see that the residuals from the intercept-only model tend to be larger (the green segments are longer) than the residuals from the model that used ACT as a predictor. This means that the squared residuals, and susequently the sum of the squared residuals will also be larger for the intercept-only model.\n\n\n\n\n\n\n\n\nFigure¬†26.2: LEFT: Plot displaying the 75th ACT scores and completion rates along with the fitted regression line for the intercept-only model (blue). A visual representation of each university‚Äôs residual (green lines) is also displayed. RIGHT: Plot displaying the 75th ACT scores and completion rates along with the fitted regression line using ACT as a predictor (blue). A visual representation of each university‚Äôs residual (green lines) is also displayed.\n\n\n\n\n\nWe can compute the SSE for the intercept-only model similar to how we computed it for our model that included ASCT as a predictor.\n\n# Get residuals for intercept-only model\nmy_residuals &lt;- resid(lm.0)\n\n# View residuals\nmy_residuals\n\n            1             2             3             4             5 \n 0.0103423913  0.0439423913 -0.0725576087  0.0202423913  0.1235423913 \n            6             7             8             9            10 \n 0.1640423913  0.1283423913 -0.0574576087 -0.1434576087 -0.1099576087 \n           11            12            13            14            15 \n 0.2513423913  0.1430423913 -0.3924576087  0.1197423913  0.1080423913 \n           16            17            18            19            20 \n-0.0385576087  0.0716423913  0.0902423913  0.0268423913  0.0719423913 \n           21            22            23            24            25 \n-0.2319576087  0.0814423913 -0.2960576087 -0.0367576087 -0.1415576087 \n           26            27            28            29            30 \n 0.1256423913  0.2970423913  0.1248423913  0.1310423913  0.1665423913 \n           31            32            33            34            35 \n 0.0315423913  0.2794423913 -0.0991576087  0.2246423913  0.0292423913 \n           36            37            38            39            40 \n-0.0482576087  0.1493423913 -0.1455576087  0.1696423913  0.2327423913 \n           41            42            43            44            45 \n 0.0341423913  0.1635423913 -0.0233576087  0.0125423913 -0.2538576087 \n           46            47            48            49            50 \n-0.0609576087 -0.2989576087 -0.1524576087  0.0003423913  0.0312423913 \n           51            52            53            54            55 \n-0.0856576087  0.0882423913 -0.1926576087 -0.1499576087 -0.0688576087 \n           56            57            58            59            60 \n-0.0074576087 -0.1417576087 -0.2709576087 -0.0943576087 -0.0219576087 \n           61            62            63            64            65 \n-0.0164576087 -0.0312576087  0.1172423913 -0.0799576087  0.0567423913 \n           66            67            68            69            70 \n 0.0629423913 -0.0254576087  0.1871423913 -0.0492576087 -0.0590576087 \n           71            72            73            74            75 \n 0.1961423913  0.0424423913 -0.1106576087 -0.0347576087  0.0029423913 \n           76            77            78            79            80 \n 0.1629423913  0.0289423913  0.0172423913  0.0630423913 -0.0713576087 \n           81            82            83            84            85 \n 0.1127423913 -0.0069576087 -0.0656576087 -0.2023576087 -0.0563576087 \n           86            87            88            89            90 \n-0.1876576087  0.2745423913 -0.1439576087 -0.0278576087 -0.0510576087 \n           91            92 \n-0.0629576087 -0.1515576087 \n\n# Compute SSE\nsum(my_residuals ^ 2)\n\n[1] 1.765905\n\n\nAlthough this value is a sum of squared residuals, because it comes from the intercept-only model we refer to it as the Sum of Squared Total (SST). This is because it is a quantification of the total amount of variation in the data (again, in a squared metric). In our example,\n\\[\n\\text{SST} = 1.766\n\\] If we again consider the mathematics behind the SST, we can gain some insight into why it is a quantification of the variation in the data, and also how it relates to other measures of variation that you already know. The way we computed SST was:\n\\[\n\\text{SST} = \\sum(Y - \\hat{Y})^2\n\\]\nBut in the intercept only model we saw that the predicted value (i.e., \\(\\hat{Y}\\)) is the mean value of Y. So the SST can also be written as:\n\\[\n\\text{SST} = \\sum(Y - \\bar{Y})^2\n\\]\nThis quantity is seen in our formulas for the variance and standard deviation. The formulas for these are:\n\\[\n\\text{Var}(Y) = \\frac{\\sum(Y - \\bar{Y})^2}{n-1} \\qquad\\qquad \\text{SD}(Y) = \\sqrt{\\frac{\\sum(Y - \\bar{Y})^2}{n-1}}\n\\] Note that the variance formula is essentially a mean‚Äîit is a sum divided by how many things there are.1 So the variance is finding the mean amount of variation (from the sample mean) in the data in a squared metric. The SD is the square root of the variance, so it is getting rid of the squared metric. That is why we interpret the SD as the average amount of variation from the sample mean.",
    "crumbs": [
      "Statistical Relationships",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>$R^2$: Quantifying the Strength of the Linear Relationship</span>"
    ]
  },
  {
    "objectID": "08-03-r-squared.html#using-the-sst-and-sse-to-quantify-strength",
    "href": "08-03-r-squared.html#using-the-sst-and-sse-to-quantify-strength",
    "title": "26¬† \\(R^2\\): Quantifying the Strength of the Linear Relationship",
    "section": "26.4 Using the SST and SSE to Quantify Strength",
    "text": "26.4 Using the SST and SSE to Quantify Strength\nNow that we have both the SST and SSE values we can use them to quantify the strength of the initial relationship between 75th percentile ACT scores and completion rates. To do this, we are going to compute the proportion reduction in error (PRE) between the baseline (intercept-only) and ACT predictor models. This will tell us how much smaller the SSE is after we include ACT in the model relative to the SSE from the baseline model. That is, we are going to compute:\n\\[\n\\begin{split}\n\\text{PRE} &= \\frac{\\text{SSE}_{\\text{Baseline Model}} - \\text{SSE}_{\\text{ACT Model}}}{\\text{SSE}_{\\text{Baseline Model}}} \\\\[2ex]\n&= \\frac{\\text{SST} - \\text{SSE}}{\\text{SST}}\n\\end{split}\n\\]\nFor our example:\n\\[\n\\begin{split}\n\\text{PRE} &= \\frac{1.766 - 0.612}{1.766} \\\\[2ex]\n&= \\frac{1.154}{1.766} \\\\[2ex]\n&= 0.65\n\\end{split}\n\\] To interpret this we say,\n\nIncluding 75th percentile ACT scores as a predictor of completion rates reduces the error variation in the model by 65.3%.\n\nOr, another way to interpret this value is to consider our sum of squares values. Mathematically, sums of squares are additive in that the SSE and another sum of squared value (the sum of squared model; SSM) add together to equal the SST.\n\\[\n\\text{SST} = \\text{SSM} + \\text{SSE}\n\\] Because of this the SSM is:\n\\[\n\\text{SSM} = \\text{SST} - \\text{SSE}\n\\]\nFor us the values of these sum of squares are:\n\n\\(\\text{SST} = 1.766\\)\n\\(\\text{SSM} = 1.154\\)\n\\(\\text{SSE} = 0.612\\)\n\nThe SSM represents the amount of variation (in a squared metric) that is explained by the model. Using the three quantities the total amount of variation in the data (SST) is equal to the amount of variation explained by the model (SSM) and the amount of variation that is unexplained by the model (SSE). That is after including 75th percentile ACT score in the model we explain some of the total variation in completion scores, but not all of it. There is still some variation in completion scores that is unexplained by differences in 75th percentile ACT scores.\nIn other words, we see that there is variation in colleges‚Äô completion rates (total variation in the data). Some of this is because colleges have different 75th percentile ACT scores (the explained variation by the model). Some of it is because of other factors (unexplained variation after ACT is included).\nAlso notice that in our formula to compute the PRE, the SSM is the numerator value in this expression.\n\\[\n\\begin{split}\n\\text{PRE} &= \\frac{\\text{SST} - \\text{SSE}}{\\text{SST}} \\\\[2ex]\n&= \\frac{\\text{SSM}}{\\text{SST}}\n\\end{split}\n\\]\nSo the PRE is not only telling us the proportion of error that was reduced after including ACT in the model, but it also is a proportion of the explained variation relative to the total variation in the data. This gives us an alternative interpretation of the PRE, namely:\n\nDifferences in 75th percentile ACT scores EXPLAIN 65.3% of the original variation in completion rates.\n\nThis is the interpretation that most applied researchers use for PRE. It is a measure of the strength of the relationship because it tells us how ‚Äúgood‚Äù a predictor is in explaining variation in the outcome we are trying to predict.\n\n\n26.4.1 Shortcut to Computing PRE\nIt turns out that in a regression model that only includes a single predictor there is a shortcut for computing the PRE. The PRE is equal to the square of the correlation coefficient:\n\\[\n\\text{PRE} = r^2\n\\]\nIn applied work, the PRE metric is often referred to as \\(R^2\\). An alternative computation is to therefore, compute the correlation coefficient and square it.\n\n# Compute R2\ncor(completion_rate ~ act, data = colleges) ^ 2\n\n[1] 0.6534083\n\n\nBecause this strength metric is related to the correlation coefficient, we now can think about what different values of \\(R^2\\) indicate based on how they relate to the correlation value (r). Consider the following correlation values and \\(R^2\\) values:\n\n\n\n\n  \n  \n\nCorrelation (r) and the corresponding \\(R^2\\) value.\n\n\nr\nR2\n\n\n\n\n0.00\n0.000\n\n\n¬±0.10\n0.010\n\n\n¬±0.20\n0.040\n\n\n¬±0.30\n0.090\n\n\n¬±0.40\n0.160\n\n\n¬±0.50\n0.250\n\n\n¬±0.60\n0.360\n\n\n¬±0.70\n0.490\n\n\n¬±0.80\n0.640\n\n\n¬±0.90\n0.810\n\n\n¬±1.00\n1.000\n\n\n\n\n\n\n\n\nUnless the correlation value is 0 or 1, the \\(R^2\\) value is always less than the correlation value (after all, we are squaring decimal values). This means that the amount of variation in the outcome that a predictor explains will generally be less than its level of correlation. In fact, until you get to correlations of \\(r &gt; 0.70\\), the amount of variation explained by a predictor is less than half.\nBecause the \\(R^2\\) value is generally smaller than the \\(r\\) value, it makes it a better indication of the strength of the relationship than the correlation coefficient, which is overly optimistic. Moreover, the value of \\(R^2\\) is based on the residuals which measure the fit of the data to the line‚Äîwhich is how we defined strength.\nLastly, we point out that \\(R^2\\) is often reported as an effect size for a regression model. We will come back to this in the next chapter when we discuss inference to see how this value measures the extent to which sample regression results diverge from the expectations specified in the null hypothesis.\n\nAs with other quantitative metrics, whether a predictor is a ‚Äúgood‚Äù predictor can not be determined by the \\(R^2\\) value alone. It also depends on the substantive field. An \\(R^2\\) value of 0.34 might constitute a worthless predictor in some fields but a great predictor in another field. Only by reading and understanding the literature in a field can you make this judgement.",
    "crumbs": [
      "Statistical Relationships",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>$R^2$: Quantifying the Strength of the Linear Relationship</span>"
    ]
  },
  {
    "objectID": "08-03-r-squared.html#footnotes",
    "href": "08-03-r-squared.html#footnotes",
    "title": "26¬† \\(R^2\\): Quantifying the Strength of the Linear Relationship",
    "section": "",
    "text": "Technically we divide by \\(n-1\\), but for larger sample sizes n and \\(n-1\\) are approximately the same.‚Ü©Ô∏é",
    "crumbs": [
      "Statistical Relationships",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>$R^2$: Quantifying the Strength of the Linear Relationship</span>"
    ]
  },
  {
    "objectID": "08-04-regression-inference.html",
    "href": "08-04-regression-inference.html",
    "title": "27¬† Inference for Linear Relationship",
    "section": "",
    "text": "27.1 Recap: College Completion Rates and ACT Scores\nIn Chapter 25, we fitted a linear regression model to answer the research question of whether ACT scores are predictive of better institutional outcomes.\nlibrary(educate)\nlibrary(ggformula)\nlibrary(mosaic)\nlibrary(mosaicCore)\nlibrary(tidyverse)\n\n\n# Import data\ncolleges &lt;- read_csv(\"https://raw.githubusercontent.com/zief0002/epsy-5261/main/data/midwest-college-scorecard.csv\")\n\n# View data\ncolleges\n\n\n  \n\n\n# Compute correlation\ncor(completion_rate ~ act, data = colleges)\n\n[1] 0.8083368\n\n# Fit regression model\nlm.a = lm(completion_rate ~ 1 + act, data = colleges)\n\n# Print regression coefficients\nlm.a\n\n\nCall:\nlm(formula = completion_rate ~ 1 + act, data = colleges)\n\nCoefficients:\n(Intercept)          act  \n   -0.36421      0.03738\nThe fitted equation was:\n\\[\n\\hat{\\mathrm{Completion~Rate}} = -0.364 + 0.037(\\mathrm{ACT})\n\\]\nThe results of the regression analysis suggested that each 1-point difference in 75th percentile ACT scores of education is associated with a 0.037-unit difference in completion rates, on average.",
    "crumbs": [
      "Statistical Relationships",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Inference for Linear Relationship</span>"
    ]
  },
  {
    "objectID": "08-04-regression-inference.html#recap-college-completion-rates-and-act-scores",
    "href": "08-04-regression-inference.html#recap-college-completion-rates-and-act-scores",
    "title": "27¬† Inference for Linear Relationship",
    "section": "",
    "text": "The slope coefficient is often referred to as the effect of the predictor. In our example, the sample effect of 75th percentile ACT scores on completion rates is 0.037. Note that although it is referred to as an ‚Äúeffect‚Äù, that this nomenclature has nothing to do with cause-and-effect (i.e., it is not causal).",
    "crumbs": [
      "Statistical Relationships",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Inference for Linear Relationship</span>"
    ]
  },
  {
    "objectID": "08-04-regression-inference.html#hypothesis-test-of-the-slope",
    "href": "08-04-regression-inference.html#hypothesis-test-of-the-slope",
    "title": "27¬† Inference for Linear Relationship",
    "section": "27.2 Hypothesis Test of the Slope",
    "text": "27.2 Hypothesis Test of the Slope\nIn regression analyses, it is common to evaluate whether the slope parameter is really different from 0, or whether the sample effect is only due to sampling variation. A research question might be:\n\nIs there an effect of 75th percentile ACT scores on college completion rates for the population of colleges?\n\nSince a slope of 0 would indicate no relationship (i.e., no effect) between the predictor and outcome, evaluating whether or not \\(\\beta_1=0\\) would give us insight about the answer to this research question. We will perform a hypothesis test to evaluate whether the population slope is different from 0. The null and alternative hypotheses for this test are:\n\\[\n\\begin{split}\nH_0: \\beta_1 &= 0 \\\\[1ex]\nH_A: \\beta_1 &\\neq 0\n\\end{split}\n\\]\nWe proceed with this test using the same process we use with every other hypothesis test:\n\nAssume the null hypothesis is true.\nFind a distribution of the sample statistic (in this case \\(b_1\\)) based on this assumption.\nCompare the observed sample statistic (our \\(b_1\\) of 0.037) to the other slopes in the distribution creates based on the null hypothesis.\nObtain a p-value.\nMake a decision based on the p-value and communicate your conclusion in context.\n\n\n\n27.2.1 Distribution of the Slope Under the Null Hypothesis\nThe thought experiment for this test is shown in Figure¬†27.1.\n\n\n\n\n\n\n\n\nFigure¬†27.1: Thought experiment underlying the hypothesis test for the slope.\n\n\n\n\n\nPlotting the slopes from these samples gives us the sampling distribution for the slope (see Figure¬†27.2). This distribution is symmetric with a mean of 0 (the value assumed in the null hypothesis). The standard error for this distribution is estimated based on the sample data and quantifies the uncertainty (i.e., the variation that is due to random sampling). In our example, the SE is 0.00287.\n\n\n\n\n\n\n\n\nFigure¬†27.2: Sampling distribution of the slope under the null hypothesis. The mean of this distribution is 0 and the SE is 0.00287, which was estimated from the sample data.\n\n\n\n\n\n\n\n\n27.2.2 Compare Observed Slope to Other Slopes in the Distribution\nBased on the sampling distribution of the slope, we expect that if the null hypothesis is true, we expect slopes in the range of \\(-.00861\\) and .000861. Our observed slope of .0374 is quite large relative to what we expect if the null hypothesis is true.\nTo further quantify how large our slope of .0374 is relative to what we expect, we convert each of the sample slopes in the sampling distribution to a t-value by using the formula:\n\\[\nt = \\frac{b_1}{SE}\n\\]\nFor example, to convert our observed slope of 0.0374 to a t-value, we use:\n\\[\n\\begin{split}\nt &= \\frac{0.0374}{0.00287} \\\\[1ex]\n&= 13\n\\end{split}\n\\]\nThis value indicates that our observed slope of 0.0374, is 13 standard errors higher than the mean of 0. After converting all of the sample slopes in the sampling distribution to t-values, we get a t-distribution. The t-distribution is shown in Figure¬†27.3.\n\n\n\n\n\n\n\n\nFigure¬†27.3: T-distribution under the null hypothesis. This distribution is based on 90 degrees-of-freedom.\n\n\n\n\n\nRecall that the exact shape of the t-distribution is based on the degrees-of-freedom (df). For the t-distribution for the slope, the df are calculated as:\n\\[\n\\textit{df} = n - p - 1\n\\]\nwhere n is the sample size and p is the number of predictors. So for our t-distribution, the degrees-of-freedom are:\n\\[\n\\begin{split}\n\\textit{df} &= 92 - 1 - 1 \\\\[1ex]\n&= 90\n\\end{split}\n\\]\nThis distribution is based 90 degrees-of-freedom.\n\n\n\n27.2.3 Obtain a p-value.\nTo evaluate whether the observed slope of 0.037 is consistent with the null hypothesis, we compute the probability of seeing a slope t-value as extreme or more extreme than 13 if the null hypothesis is true (the p-value). This is depicted in Figure¬†27.4.\n\n\n\n\n\n\n\n\nFigure¬†27.4: Sampling distribution of the slope under the null hypothesis. The observed slope of 0.037 is shown as a vertical line in this distribution. Since the test was two-tailed, the slope of -0.037 is also demarcated. The p-value is shown as the shaded area under the curve that is at least as extreme os those slopes.\n\n\n\n\n\nTo compute the p-value (along with the SE and t-value), we use the tidy() function from the {broom} package. To use this function we load the {broom} package (you may need to install it) and then provide the tidy() function the name of our fitted model. The syntax to do this for our example is shown below.\n\n# Load library\nlibrary(broom)\n\n# Get coefficient information\ntidy(lm.a)\n\n\n  \n\n\n\nNote that tidy() outputs information for both the intercept and slope of our fitted model. The information displayed includes:\n\nterm: This indicates which term (intercept, slope) the information is for. Note that the slope will be the name of the predictor used in the model. (For us this is act.)\nestimate: This is the coefficient estimate for the terms. In our example the coefficient for the slope is .374 (i.e., \\(b_1=.374\\)).\nstd.error: This is the standard error estimated from the data. In our example the standard error for the slope is .00287 (i.e., \\(\\textrm{SE}_{b_1}=.00287\\)).\nstatistic: This is the t-value we get after converting our coefficient estimate to a t-statistic. For us that value is 13.0.\np.value: This is the p-value based on a two-sided alternative hypothesis. For the slope this is \\(p=2.02 \\times 10^{-22} = .0000000000000000000002022\\).\n\nIf we were writing up the results of the hypothesis test for the slope, we might report the following:\n\nA hypothesis test was conducted to determine if there is an effect of 75th percentile ACT scores on college completion rates. The results of this test‚Äî\\(t(90)=13.0\\), \\(p&lt;.001\\)‚Äîsuggest that it is incredibly unlikely to observe an estimated slope of .0374 (or a slope value more extreme than .0374) if \\(\\beta_1 = 0\\).\n\n\n\n\n27.2.4 Make a Decision Based on the p-Value and Communicate Results in Context\nUsing the criterion of \\(\\alpha = .05\\), we would reject the null hypothesis that \\(\\beta_1 = 0\\) as our p-value is smaller than .05. It is likely that the population slope value is different than zero. This indicates that there likely IS an effect of 75th percentile ACT scores on completion rates for colleges in the population, and that the slope value of .0374 that we observed in the sample is not entirely due to sampling variation.",
    "crumbs": [
      "Statistical Relationships",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Inference for Linear Relationship</span>"
    ]
  },
  {
    "objectID": "08-04-regression-inference.html#confidence-interval-for-the-slope",
    "href": "08-04-regression-inference.html#confidence-interval-for-the-slope",
    "title": "27¬† Inference for Linear Relationship",
    "section": "27.3 Confidence Interval for the Slope",
    "text": "27.3 Confidence Interval for the Slope\nBased on the results of the hypothesis test, we believe there is an effect of 75th percentile ACT scores on completion rates for colleges in the population‚Äîthat is, the slope is likely not 0. A natural question is, in the population, what is the value of the slope? What is the size of the effect?\nBased on the sample regression results, we have a point-estimate (single number guess) for the population effect, namely .0374. But, as we have learned, we also have to account for sampling uncertainty in our estimate. To do that, we compute a confidence interval for \\(\\beta_1\\) using:\n\\[\n\\mathrm{CI~for~}\\beta_1 = b_1 \\pm 2(\\mathrm{SE}_{b_1})\n\\]\nThat is, we compute the uncertainty by doubling the standard error for the slope and then adding and subtracting that quantity from the sample slope estimate. For our example,\n\\[\n\\begin{split}\n\\mathrm{CI~for~}\\beta_1 &= b_1 \\pm 2(\\mathrm{SE}_{b_1}) \\\\[2ex]\n&= .0374 \\pm 2(.00287) \\\\[2ex]\n&= [0.032, .043]\n\\end{split}\n\\]\nInterpreting this interval,\n\nWe are 95% confident1 that the population slope is between .032 and .043.\n\nThis means that in the population each one-point difference in 75th percentile ACT score is associated with a model predicted difference of between 3.2 and 4.3 percentage points in mean completion rate.\nTo obtain the confidence limits for the 95% CI directly, we add the argument conf.int=TRUE to the tidy() function.\n\n# Get confidence limits\ntidy(lm.a, conf.int = TRUE)\n\n\n  \n\n\n\nThe confidence limits are outputted in the conf.low and conf.high columns. For the slope those values are 0.0317 and 0.0431.",
    "crumbs": [
      "Statistical Relationships",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Inference for Linear Relationship</span>"
    ]
  },
  {
    "objectID": "08-04-regression-inference.html#assumptions",
    "href": "08-04-regression-inference.html#assumptions",
    "title": "27¬† Inference for Linear Relationship",
    "section": "27.4 Assumptions",
    "text": "27.4 Assumptions\nAs with other hypothesis tests and confidence intervals, the hypothesis test and CI for the slope also have a set of assumptions that we need to adhere to in order for the results to be valid. These assumptions are:\n\nLinearity\nIndependence\nNormality\nEqual variances\n\nNote you can use the acronym LINE to help remember these assumptions. Remember the visual depiction of the regression model we introduced in Chapter 25.\n\n\n\n\n\n\n\n\nFigure¬†27.5: Plot displaying conditional distribution of Y at several X values. The OLS fitted regression line (dotted) is also shown. The red points show the mean value of Y for each conditional distribution.\n\n\n\n\n\nRemember that this plot shows that at each value of X there is a conditional distribution of Y-values. Each conditional distribution of Y has a mean (denoted as \\(\\hat{Y}\\)). Each conditional distribution of Y is normally distributed. The variance for all these conditional distributions are all the same value.\nThis\nBelow we give a further description of each of these assumptions and also indicate how to evaluate them.\n\n\n27.4.1 Linearity\nThe linearity assumption is that the functional form for the model in the population is linear. Referring back to Figure¬†27.5, this assumption basically says that in the population, the conditional means can be connected using a line.If this is not the case, then we have mis-specified the model, fitting a linear model to the sample.\nTo evaluate the linearity assumption, we typically look at a scatterplot of the data and make a judgment about whether the relationship between the predictor and outcome is linear.\n\n# Examine linearity\ngf_point(\n  completion_rate ~ act, data = colleges,\n  xlab = \"75th percentile ACT score\",\n  ylab = \"Completion rate\"\n  )\n\n\n\n\n\n\n\n\nBased on this plot, it seems that the relationship for the 92 colleges is reasonably linear. While we don‚Äôt know about the population, the linearity in the sample relationship is consistent with the population relationship also being linear.\n\n\n\n27.4.2 Independence\nIndependence is evaluated similarly to how we have assessed it for other tests/CIs. If random chance was used in the study design (either to randomly select cases or randomly assign values to the predictor), the independence assumption is satisfied. If random chance was not employed in the study design, we need to make a logical argument about whether knowing one case‚Äôs outcome value would convey any information about any other case‚Äôs outcome value.\nIn our example, random chance was not used in the study design. The 92 colleges were not selected randomly not were 75th percentile ACT scores randomly assigned to institutions. Making a logical argument, it may be that knowing one institution‚Äôs completion rate may give us some information about other institutions‚Äô completion rates in the sample. For example, there are several University of Minnesota campuses in the data (e.g., Twin Cities, Duluth). These schools are governed by the same set of policies which may influence their completion rates in similar ways. This would suggest that the independence assumption may be violated.\n\n\n\n27.4.3 Normality\nA third assumption is that the outcome is normally distributed at each value of the predictor. Referring back to Figure¬†27.5, we see this assumption in the fact that each conditional distribution of Y is normally distributed.\nTo evaluate this, we would hypothetically take all the outcome values for a particular predictor value‚Äîe.g., all the completion rates for colleges with a 75th percentile ACT score of 20‚Äîand make a judgment about whether that distribution was normally distributed. Then we would do the same for all the completion rates for colleges with a 75th percentile ACT score of 21. And all the completion rates for colleges with a 75th percentile ACT score of 22. We would need to do this for every value of the predictor in the population.\nIn practice, we have to work on the sample data and then make a judgment about the population. Carrying out this process, even on the sample is all but impossible. Because of this, researchers often evaluate the normality assumption by examining the shape of the distribution of the sample outcome values without separating them by different predictor values. If the sample distribution of the outcome seems approximately normal, we would say that this would be consistent with the population outcome distribution also being normal.\n\n# Evaluate normality of outcome\ngf_histogram(\n  ~completion_rate, data = colleges,\n  color = \"black\",\n  fill = \"#722F37\",\n  xlab = \"Completion rate\",\n  ylab = \"Count\"\n  )\n\n\n\n\n\n\n\n\nThe sample distribution of completion rates looks symmetric and unimodal. This is probably reasonable evidence to say that the normality assumption is tenable.\n\n\n\n27.4.4 Equal Variances\nThe equal variances assumption is that the variance of the outcome at each value of the predictor is the same. Referring back to Figure¬†27.5, we see this assumption in the fact that each conditional distribution of Y has the same width (i.e., the same variance and standard deviation).\nTo evaluate this, we would hypothetically take all the outcome values for a particular predictor value‚Äîe.g., all the completion rates for colleges with a 75th percentile ACT score of 20, and compute the variance of the completion rates. We would do this for completion rates at every predictor value in the population and then check to see that those values are equal.\nIn practice, we again make this judgment based on the sample data. However, the sample size at some levels of the predictor are quite small, so computing a variance of the completion rates is problematic. For example, we only have one college with a 75th percentile ACT value of 20, so we can‚Äôt compute a variance. Moreover, many times there are just too many predictor values to make this a reasonable approach.\nInstead, we look at whether the ranges of the completion rates for a smaller set of conditional distributions are all approximately equal. To get a sense for this, split the 75th percentile ACT scores into bins and look at the range of the completion scores for the schools in each bin. An example of this is given in Figure¬†27.6.\n\n\n\n\n\n\n\n\nFigure¬†27.6: Scatterplot showing thew relationship between 75th percentil ACT scores and completion rate. Colleges with similar ACT scores have been binned together in a box. The vertical length of the box indicates the range of the completion rates for those schools in the bin.\n\n\n\n\n\nThe range of the completion rates corresponds to the length of the box in the vertical direction. Are the vertical lengths of the boxes all roughly the same? It looks like‚Ä¶yes, except for the box on the far right. The range of completion rates in that box is smaller than in the others.\nOne thing that psychologists have found is that comparing things that are not level is more difficult for humans. In this plot, the boxes are not all level‚Äîthe boxes to the right are higher than the boxes on the left.\n\n\n\n\n\n\n\n\nFigure¬†27.7: Leveling the boxes makes it easier for people to judge whether the range of the completion rates for those schools in each bin (i.e., vertical length of each box) is roughly the same.\n\n\n\n\n\nOne way to make the boxes level, we need to subtract the conditional mean completion rate (the mean completion rate in the box) from the actual completion rate for each school. But remember, the conditional mean value is the predicted value (\\(\\hat{Y}\\)). That is we are essentially computing:\n\\[\nY - \\hat{Y}\n\\]\nThis, recall, is the error or residual. That means we can create a scatterplot of the predictor on the x-axis versus the residuals on the y-axis. To do this we will use the augment() function from the {broom} library to obtain a data frame that includes the predictor and residual values for each case. This function takes the name of the fitted model object as its only argument.\n\n# Get data frame that includes predictor values and residuals\nout = augment(lm.a)\n\n# View augmented data\nout\n\n\n  \n\n\n\nThe attribute act is the column that has the predictor values (same name as in our original data), and the column .resid includes the residual values. Then we can use gf_point() to create the levelled scatterplot.\n\n# Scatterplot of residuals versus ACT values\ngf_point(\n  .resid ~ act, data = out,\n  xlab = \"75th percentile ACT score\",\n  ylab = \"Residuals\"\n  )\n\n\n\n\n\n\n\n\nAgain, imagine the boxes on this plot and ask whether the vertical edge of each box is roughly the same length. If the answer is ‚Äúyes‚Äù we say the equal variances assumption is tenable, and if the answer is ‚Äúno‚Äù then we say the assumption isn‚Äôt tenable (it may be violated).\nBased on this plot, it looks like the equal variances assumption may be violated as the imaginary boxes on the right-hand side of the plot would be shorter than the imaginary boxes on the left-hand side of the plot.\n\n\n\n27.4.5 Summarizing the Results of Checking the Assumptions\nBased on the sample evidence:\n\nIt seems that the relationship for the 92 colleges is reasonably linear.\nThe symmetric and unimodal distribution of completion rates suggests that the normality assumption is tenable.\n\nHowever.\n\nThe independence assumption may be violated.\nThe equal variances assumption also may be violated as the variation in completion rates for schools with larger ACT scores seems higher than the variation in completion rates for schools with smaller ACT scores.\n\nWhere does this leave us? The violation of the assumptions make the inferential evidence (e.g., the SEs, t-values, and p-values) suspect. It is probably not a good idea to place much trust in the results.\n\nStatisticians have tools for dealing with violations of assumptions‚Äîfor linear regression, and for all of the other analyses you have learned about. Several of these methods are introduced in advanced coursework such as EPSY 8251 and EPSY 8252. You can also learn more about regression and extensions to the methods you learned about in this class in EPSY 5262. You can learn more about these courses in the UMN Course Catalog.",
    "crumbs": [
      "Statistical Relationships",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Inference for Linear Relationship</span>"
    ]
  },
  {
    "objectID": "08-04-regression-inference.html#footnotes",
    "href": "08-04-regression-inference.html#footnotes",
    "title": "27¬† Inference for Linear Relationship",
    "section": "",
    "text": "Remember that doubling the SE produces a 95% CI.‚Ü©Ô∏é",
    "crumbs": [
      "Statistical Relationships",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Inference for Linear Relationship</span>"
    ]
  },
  {
    "objectID": "09-00-data-codebooks.html",
    "href": "09-00-data-codebooks.html",
    "title": "Data and Codebooks",
    "section": "",
    "text": "How to Download a CSV File to Your Computer\nTo download a data (CSV) file, click on the data set. Then click the RAW button. Now you should be able to right-click the dataset and save it. If you are using Safari on a Mac, make sure that the downloaded data does not have an extra .txt appended to it when it downloads. If it does, just delete the extra .txt suffix.",
    "crumbs": [
      "Data and Codebooks"
    ]
  }
]