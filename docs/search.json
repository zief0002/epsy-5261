[
  {
    "objectID": "04-03-one-sample-test.html#statistical-inference-and-hypothesis-testing",
    "href": "04-03-one-sample-test.html#statistical-inference-and-hypothesis-testing",
    "title": "7  Hypothesis Testing: One-Sample t-Test",
    "section": "7.1 Statistical Inference and Hypothesis Testing",
    "text": "7.1 Statistical Inference and Hypothesis Testing\nOne common approach to statistical inference—the drawing of conclusions about populations based on sample observations—is to use the sample observations to test a priori hypothesis1 about the population. Hypotheses are mathematical statements about population parameters which are often formed based on prior knowledge and substantive literature in the area of content.\nIn the social sciences, we typically write out two hypotheses about the population parameters: the null hypothesis (\\(H_0\\)), often referred to as a statement of no effect, and the alternative hypothesis (\\(H_A\\)), often termed the research (or alternative) hypothesis. For example, here are a set of potential hypotheses about teen sleep:\n\\[\n\\begin{split}\n&H_0: \\textrm{The mean amount of sleep for all teens is equal to 9 hours.} \\\\[1ex]\n&H_A: \\textrm{The mean amount of sleep for all teens is less than 9 hours.}\n\\end{split}\n\\] There are a few things to notice about these hypotheses:\n\nThe statements are about the mean amount of sleep (i.e., summary measure).\nThe statements are about the population (all teens), not the sample.\nThe null hypothesis (\\(H_0\\)) is a statement of equality (is equal to).\nThe alternative hypothesis often indicates the researcher’s belief about the population summary (e.g., we think the average amount of sleep for all teens is less than 9 hours).\n\nStatisticians often use the language of mathematics to express these hypotheses. The same hypotheses expressed via the language of mathematics are:\n\\[\n\\begin{split}\n&H_0: \\mu_{\\textrm{Sleep}}=9 \\\\[1ex]\n&H_A: \\mu_{\\textrm{Sleep}} < 9\n\\end{split}\n\\]\nThe Greek letter mu (\\(\\mu\\)) denotes a population mean. In general Greek letters represent population parameters while Roman letters represent sample statistics. Here are a list of common statistical summaries and the mathematical notation used to denote them.\n\n\n\n\n\n  \n  Table 7.1:  Some common statistical summaries and the mathematical notation used to denote them. \n  \n    \n    \n      Summary\n      Sample\n      Population\n    \n  \n  \n    Mean\n$$\\bar{x},~\\textit{M}$$\n$$\\mu$$\n    Standard Deviation\n$$\\textit{s},~\\textit{SD}$$\n$$\\sigma$$\n    Variance\n$$s^2,~\\textit{Var}$$\n$$\\sigma^2$$\n  \n  \n  \n\n\n\n\n\nThe alternative hypothesis is always an inequality. In this example, the alternative hypothesis is the mean is LESS THAN 9 hours. Another potential alternative hypothesis would be that the mean is GREATER THAN 9 hours, while a third possibility is that the mean is NOT EQUAL TO 9 hours. Mathematically these could be expressed as \\(\\mu_{\\textrm{Sleep}}<9\\), \\(\\mu_{\\textrm{Sleep}}>9\\), and \\(\\mu_{\\textrm{Sleep}}\\neq9\\). The alternative hypothesis you choose is based on your conjecture about the population. For example, if we believed that teens sleep, on average, less than 9 hours a night, then the alternative hypothesis we choose would be \\(\\mu_{\\textrm{Sleep}}<9\\). If we thought they sleep more than 9 hours, on average, we would adopt the alternative hypothesis of \\(\\mu_{\\textrm{Sleep}}>9\\). If we are unsure about whether they sleep less or more than 9 hours, then our alternative hypothesis would be \\(\\mu_{\\textrm{Sleep}}\\neq9\\).\n\n\n7.1.1 The Null Model\nA hypothesis test is predicated on the assumption that the null hypothesis is true. Thus, we want to produce a sampling distribution of potential sample summaries that we could see if \\(H_0: \\mu_{\\textrm{Sleep}}=9\\) is actually true. In other words, we are carrying out a thought experiment assuming that the average amount of sleep for all teens is actually 9 hours.\n\n\n\n\n\nFigure 7.1: Visual depiction of the thought experiment underlying a hypothesis test assuming that the mean amount of sleep for all tennagers is 9 hours.\n\n\n\n\nIf we were able to carry out this thought experiment, here is what the sampling distribution of the sample means would look like:\n\n\n\n\n\nFigure 7.2: Density plot of the sampling distribution of the sample means based on the thought experiment underlying a hypothesis test assuming that the mean amount of sleep for all tennagers is 9 hours.\n\n\n\n\nThis distribution is also known as the null distribution since it is the sampling distribution that arises from the thought experiment assuming the null hypothesis is true. Describing the features (shape, center, and variation) of this null distribution we find:\n\nThe distribution is unimodal and symmetric.\nThe mean (center) of the distribution is at 9 hours.\nThe SD of this distribution (the SE) is approximately 0.20.\n\nInterpreting these features, we find that in the thought experiment where we assume the mean amount of sleep is 9 hours, a typical mean is 9 hours! But, sample means will vary from 9 hours. That is, even if the true mean amount of sleep is 9 hours, we could expect a sample mean that differs from 9 hours. How much they will vary depends on the SE, which is approximately 0.20.2 So, it would not be unusual to see a sample mean as low as 8.6 (\\(9 - 2(0.20) = 8.6\\)) or as high as 9.4 (\\(9 + 2(0.20) = 9.4\\)).\n\nThe null distribution will always be centered at the parameter value specified in the null hypothesis! The SE of the null distribution gives us an indication of how much a sample statistic is likely to vary from the parameter specified in the null hypothesis. We expect most values will be within 2 standard errors of the center.\n\n\n\n\n7.1.2 Evaluating the Observed Sample Mean\nThe null distribution gives us an indication of the range of sample mean values that are expected assuming the null hypothesis is true. Using the null distribution as a reference, we can evaluate the mean we obtained from the observed data, which was 7.5 hours (see Chapter 5).\n\n\n\n\n\nFigure 7.3: Density plot of the sampling distribution of the sample means based on the thought experiment underlying a hypothesis test assuming that the mean amount of sleep for all tennagers is 9 hours. The blue shaded area represents the sample mean values we expect under the hypothesis that the average amount of sleep for all tennagers is 9 hours. The pink dot represnts the sample mean of 7.5 that we observed in the teen sleep data.\n\n\n\n\nWe can see from Figure 7.3 that the observed mean of 7.5 is not a value we expect if the population mean amount of sleep teenagers get is truly 9 hours. It is, in fact, far less than we expect. In other words,\n\nThe sample mean of 7.5 hours of sleep we observed in the data is not consistent with the hypothesis that the average amount of sleep teenagers get a night is 9 hours.\n\nBecause the data were not consistent with our initial hypothesis, we would reject the null hypothesis, that is, the empirical evidence (data) does not support the hypothesis.\nWhile the method we used allows us to say whether the empirical data are consistent with the null hypothesis that teenagers get, on average, 9 hours of sleep, it does not tell us the level of consistency. Is it slightly inconsistent? Or really inconsistent? Because of this, applied researchers will often quantify this via two measures: (1) the t-value, and the p-value."
  },
  {
    "objectID": "04-03-one-sample-test.html#references",
    "href": "04-03-one-sample-test.html#references",
    "title": "7  Hypothesis Testing: One-Sample t-Test",
    "section": "7.6 References",
    "text": "7.6 References"
  },
  {
    "objectID": "04-02-simulation.html#bootstrapping",
    "href": "04-02-simulation.html#bootstrapping",
    "title": "6  Bootstrapping: Using Simulation to Estimate the Uncertainty",
    "section": "6.1 Bootstrapping",
    "text": "6.1 Bootstrapping\nThe key question addressed by using any statistical method of inference is “how much variation is expected in a particular test statistic if one repeatedly draws random samples from the same population?” In the thought experiment we introduced in Chapter 5, the method for quantifying the uncertainty was to repeatedly sample from the population and measure the variation in the sample means. Recall that the quantification of the uncertainty (i.e., variation in the sample means) is referred to as the standard error.\n\n\n\n\n\nFigure 6.1: Thought experiment for drawing random samples of size 75 from the population to obtain different samples. The average amount of sleep per night is computed for each sample drawn.\n\n\n\n\nBradley Efron introduced the methodology of bootstrapping in the late 1970s as an alternative method to compute the standard error.\ncomputer-based simulation framework to replace the inaccurate and complicated approximations that theoretical methods provide.1\nEfron’s big discovery was that in the thought experiment, we could replace the population with a sample, and then randomly sample from that initial sample. He proved that using this methodology, you can obtain a good estimate of the sampling variation.\n\n\n\n\n\nFigure 6.2: Thought experiment for bootstrapping random samples of size 75 from the original sample of 75 students’ sleep times to obtain different samples. The average amount of sleep per night is computed for each re-sample drawn.\n\n\n\n\nBecause we need to randomly sample 75 observations out of the original sample (which itself only includes 75 observations), we need to sample WITH REPLACEMENT when we draw our re-samples. In this way, we mimic drawing random samples from a larger population without actually needing the larger population."
  },
  {
    "objectID": "04-02-simulation.html#importing-the-teen-sleep-data",
    "href": "04-02-simulation.html#importing-the-teen-sleep-data",
    "title": "6  Bootstrapping: Using Simulation to Estimate the Uncertainty",
    "section": "6.2 Importing the Teen Sleep Data",
    "text": "6.2 Importing the Teen Sleep Data\nWe will use the data in teen-sleep.csv to bootstrap a standard error of the mean. These data include the bedtime, wake-up time, and hours slept for a sample of \\(n=75\\) American teens in Grades 9–12.\n\nteen-sleep.csv\nData Codebook\n\nWe will prepare for the analysis by loading in the {tidyverse}, {ggformula}, and {mosaicCore} libraries and importing the teen sleep data. We will also load the {mosiaic} package.\n\nlibrary(ggformula)\nlibrary(mosaicCore)\nlibrary(mosaic)\nlibrary(tidyverse)\n\n\n# Import data\nteen_sleep <- read_csv(\"https://raw.githubusercontent.com/zief0002/epsy-5261/main/data/teen-sleep.csv\")\n\n# View data\nteen_sleep"
  },
  {
    "objectID": "04-02-simulation.html#bootstrapping-from-the-teen-sleep-data",
    "href": "04-02-simulation.html#bootstrapping-from-the-teen-sleep-data",
    "title": "6  Bootstrapping: Using Simulation to Estimate the Uncertainty",
    "section": "6.3 Bootstrapping from the Teen Sleep Data",
    "text": "6.3 Bootstrapping from the Teen Sleep Data\nThe process for computing the standard error via bootstrapping is:\n\nSTEP 1: Randomly sample n observations from the observed sample of size n (with replacement) This is called a bootstrap sample or a re-sample.\nSTEP 2: Compute the mean of the bootstrap sample.\nSTEP 3: Repeat the first two steps in the process many times (say 1000 times), each time recording the mean.\nSTEP 4: Find the standard deviation of these means (i.e., the standard error of the mean).\n\nThe computations we do will parallel each step of this process. As you learn how to do this, it is easy to get lost in the computing and forget why you are doing this. Remember, the end goal is to mimic the thought experiment so we can quantify the variation in the sample means.\n\n\n6.3.1 STEP 1: Randomly sample 75 observations from the observed sample of size 75 teen sleep amounts (with replacement)\nTo randomly sample from a set of values we use the sample() function. We will need to specify the values we are sampling from (i.e., the original sample) as an input to the function. The data we want to randomly sample from is in a column called hrs_sleep inside the data object called teen_sleep. To specify a particular column in a data object we use the following notation: teen_sleep$hrs_sleep. We also need to set the number of observations to randomly sample, and tell this function that we are sampling with replacement.\nThus to draw a random sample of values from our data we use:\n\n# Randomly sample from the hrs_sleep column located in the teen_sleep data object\n# Draw 75 observations\n# Sample with replacement\nsample(teen_sleep$hrs_sleep, size = 75, replace = TRUE)\n\n [1]  6.666667  9.166667  8.083333  9.166667  7.583333  8.416667  4.416667\n [8]  7.833333  5.416667  7.166667  6.500000  7.750000  5.916667  9.916667\n[15]  7.750000  7.166667  6.333333  9.916667  7.166667  6.583333  6.916667\n[22]  7.083333  7.500000  7.916667  8.083333  8.583333  9.750000  7.333333\n[29]  8.083333  4.166667 10.083333  7.083333  6.333333  7.583333  8.500000\n[36]  7.333333  6.083333  9.166667  7.833333  7.333333  7.916667  7.000000\n[43]  7.833333  7.583333  4.416667  9.916667  7.916667  8.416667  6.333333\n[50]  7.583333  6.500000  6.583333  4.583333  7.750000  6.416667  6.500000\n[57]  7.500000  5.916667  4.416667  7.750000  7.750000  7.500000  4.500000\n[64]  7.500000  7.583333  4.500000  6.083333  6.583333  7.083333  4.500000\n[71]  7.500000  7.333333  7.416667  4.166667  7.750000\n\n\nThis is akin to drawing a bootstrap sample from the original sample. Note that because we are drawing randomly, if you are trying this on your computer, you might get a different bootstrap sample than the one shown here. If you re-run this syntax, you will get a different bootstrap sample.\n\n# Draw a second bootstrap sample of 75 observations\nsample(teen_sleep$hrs_sleep, size = 75, replace = TRUE)\n\n [1]  4.833333  8.333333  8.750000  4.666667  6.333333  7.500000  7.666667\n [8]  5.416667  6.500000  7.416667  7.583333  8.916667  6.083333  7.583333\n[15]  7.583333  4.500000  8.750000  5.916667  7.583333  8.083333  8.333333\n[22]  7.000000  7.833333  6.666667  4.583333  7.083333  7.666667  6.083333\n[29]  7.500000  7.583333 10.333333  7.083333  7.583333  8.333333  9.166667\n[36]  7.416667  6.833333  6.500000  4.166667  8.583333  7.583333  6.916667\n[43]  8.333333  7.083333  7.666667  5.916667  4.666667  9.083333  7.916667\n[50]  7.916667  7.000000  6.333333 10.333333  8.083333  7.333333  7.500000\n[57]  7.916667  6.083333  7.750000  8.833333  7.500000  8.500000  7.833333\n[64]  8.416667  6.083333  6.083333  7.916667  8.833333  8.250000  9.083333\n[71]  4.833333  9.750000  4.166667  4.666667  7.750000\n\n\n\n\n\n6.3.2 STEP 2: Compute the mean of the bootstrap sample.\nTo compute the mean of a bootstrap sample, we are just going to embed our sample() syntax inside of the mean() function. For example,\n\n# Draw a bootstrap sample of 75 observations and compute the mean\nmean(sample(teen_sleep$hrs_sleep, size = 75, replace = TRUE))\n\n[1] 7.502222\n\n\nYou could re-run this syntax to draw another bootstrap sample and compute the mean.\n\n\n\n6.3.3 STEP 3: Repeat the first two steps in the process many times (say 1000 times), each time recording the mean.\nTo repeat a set of computations, we are going to use the do() function from the {mosaic} package. As a reminder, you will need the {mosiac} package loaded prior to using this function. The syntax for the do() function takes the following format:\ndo(N times) * {Computations to repeat}\nAs an example, if we wanted to carry out our computations to draw a bootstrap sample and compute the mean 10 times, the synatx is:\n\n# Draw a bootstrap sample of 75 observations and compute the mean\n# Do this 10 times \ndo(10) * {mean(sample(teen_sleep$hrs_sleep, size = 75, replace = TRUE))}\n\n\n\n  \n\n\n\nThe computations are carried out 10 times and the results are recorded in a column (result) of a data object. Because we will ultimately want to compute on this data object, when we run this, we will want to assign the data into an object. Below, we draw 1000 bootstrap samples, each time computing the mean, and assign them into a data object called bootstrap_means.\n\n\n\n\n# Draw a bootstrap sample of 75 observations and compute the mean\n# Do this 1000 times \n# Assign these into an object called bootstrap_means\nbootstrap_means <- do(1000) * {mean(sample(teen_sleep$hrs_sleep, size = 75, replace = TRUE))}\n\n# View the results\nbootstrap_means\n\n\n\n  \n\n\n\n\n\n\n6.3.4 STEP 4: Find the standard deviation of these means (i.e., the standard error of the mean).\nRemember our goal was to compute the standard error, which quantifies the uncertainty in the sample mean estimates that is due to sampling variation. Before we do that, we will visualize the distribution of bootstrapped means.\n\n# Create a density plot of the bootstrapped means\ngf_density(\n  ~result, data = bootstrap_means,\n  xlab = \"Mean value\",\n  ylab = \"Density\"\n)\n\n\n\n\nFigure 6.3: Distribution of 1000 bootstrapped means.\n\n\n\n\nThe distribution of bootstrapped means is unimodal and symmetric. This indicates that the standard deviation is a reasonable numeric summary of the variation. Again, since the cases in the distribution are means (summary measures), the standard deviation is referred to as a standard error. To compute the standard error, we use df_stats():\n\n# Compute SE\ndf_stats(~result, data = bootstrap_means)\n\n\n\n  \n\n\n\nHere the standard error (found in the sd column) is 0.17.\n\nThe distribution of bootstrapped means should be centered at the value of the original sample mean. In our teen sleep example, the original sample had a mean of 7.4. This value is roughly at the center of the distribution in Figure 6.3. This can be a self-check when you create a bootstrap distribution."
  },
  {
    "objectID": "04-02-simulation.html#references",
    "href": "04-02-simulation.html#references",
    "title": "6  Bootstrapping: Using Simulation to Estimate the Uncertainty",
    "section": "6.4 References",
    "text": "6.4 References\n\n\n\n\nRaspe, R. E. (1948). Singular travels, campaigns and adventures of Baron Munchausen (J. Carswell, Ed.). Cresset Press."
  },
  {
    "objectID": "04-03-one-sample-test.html#quantifying-the-level-of-consistency-with-the-null-hypothesis-the-t-value",
    "href": "04-03-one-sample-test.html#quantifying-the-level-of-consistency-with-the-null-hypothesis-the-t-value",
    "title": "7  Hypothesis Testing: One-Sample t-Test",
    "section": "7.2 Quantifying the Level of Consistency with the Null Hypothesis: The t-Value",
    "text": "7.2 Quantifying the Level of Consistency with the Null Hypothesis: The t-Value\nThe t-value quantifies how far away the observed mean is from the hypothesized mean value in standard error units. To compute the t-value we use the following:\n\\[\nt = \\frac{\\mathrm{Obs.~Mean} - \\mathrm{Hyp.~Mean}}{SE}\n\\]\nwhere, Obs. Mean is the observed sample mean from the data, Hyp. Mean is the hypothesized value in the null hypothesis, and SE is the standard error in the null distribution (which we compute via bootstrapping). Computing this for our example,\n\\[\n\\begin{split}\nt &= \\frac{7.5 - 9}{0.17} \\\\[2ex]\n&= -8.82\n\\end{split}\n\\] The t-value indicates that our observed sample mean of 7.5 is 8.82 standard errors below the hypothesized population mean value of 9. Changing the distance metric to standard error units helps standardize the distance for other scholars so they can better interpret how discrepant the observed mean is from the hypothesized value.\nFor example, if we hadn’t divided by the SE, we would have said our observed mean of 7.5 hours of sleep is 1.5 hours less than the hypothesized mean of 9 hours of sleep. Is this a lot less? Or a little less? The answer to that depends on how much we expect sample means to vary from the population mean under random sampling. This is what the SE quantifies. So dividing by the SE accounts for this expected variation and also changes the units from “hours of sleep” to “standard errors”.\nNow that we have a t-value, how do we judge its magnitude? To do this, we can again look back to the null distribution in Figure 7.3. Based on the null distribution, we said we expected sample means to fall in between 8.6 and 9.4. What are the t-values associated with 8.6 and 9.4?\n\\[\n\\begin{split}\nt &= \\frac{8.6 - 9}{0.17} \\\\[2ex]\n&= -2.35 \\\\[4em]\nt &= \\frac{9.4 - 9}{0.17} \\\\[2ex]\n&= 2.35\n\\end{split}\n\\]\nExpecting a sample mean between 8.6 and 9.4 is essentially the same as expecting a t-value between \\(-2.35\\) and 2.35.\n\nRule-of-Thumb: An observed mean that has a t-value with an absolute value less than 2 is fairly consistent with the null hypothesis being true. An observed mean that has a t-value with an absolute value greater than 2 is less consistent with the null hypothesis being true, and the further away from 2, the more evidence against the null hypothesis.\n\n\n\n7.2.1 The t-Distribution\nRecall that the null distribution is simply a distribution of sample means we expect if the null hypothesis is true. Because each case in this distribution is a sample mean, we could transform each case into a t-value. If we do that, the resulting distribution is a t-distribution.\n\n\n\n\n\nFigure 7.4: Density plot of the t-distribution of the sample means based on the thought experiment underlying a hypothesis test assuming that the mean amount of sleep for all tennagers is 9 hours (t value of 0). The blue shaded area represents the t-values we expect if the null hypothesis is true. The pink dot represents the observed t-value of -8.82.\n\n\n\n\nThe t-distribution is is the sampling distribution that arises from converting the null distribution from the thought experiment assuming the null hypothesis is true to t-values. Describing the features (shape, center, and variation) of this t-distribution we find:\n\nThe distribution is unimodal and symmetric.\nThe mean (center) of the t-distribution is 0.\nThe SD of this t-distribution (the SE) is approximately 1.\n\nNote that the descriptions referred to “this t-distribution”. That is because there are many different t-distributions; in fact there are an infinite number of them. Each t-distribution is based on a parameter called the degrees-of-freedom (df), which is in turn based on the sample size for the observed data. The df for the t-distribution is computed as:\n\\[\n\\mathit{df} = n - 1\n\\]\nwhere n is the sample size.\nThe degrees-of-freedom parameter impacts the shape and SE (variation) in the t-distribution. Figure 7.5 shows the t-distribution based on a few different degrees-of-freedom values. From this figure we can see:\n\nEvery t-distribution is unimodal and symmetric, although t-distributions with smaller degrees-of-freedom parameters are shorter and have thicker tails than t-distributions with higher degrees-of-freedom parameters.\nThe mean (center) of every t-distribution is 0.\nThe SD of this t-distribution (the SE) depends on the degrees-of-freedom, and t-distributions with smaller degrees-of-freedom parameters have a higher SE than t-distributions with higher degrees-of-freedom parameters.\n\n\n\n\n\n\nFigure 7.5: Density plot of three different t-distributions. The t-distributions shown have 3 degree-of-freedom (SE = 1.73), 5 degree-of-freedom (SE = 1.29), and 99 degree-of-freedom (SE = 1.01), respectively. Note that the degrees-of-freedom value impacts the shape and variation in the distribution.\n\n\n\n\nThe SE of a t-distribution depends directly on the degrees-of-freedom. Specifically,\n\\[\n\\mathit{SE} = \\begin{cases}\n\\mathrm{Undefined}, & \\text{if } &\\mathit{df}\\leq1\\\\[2ex]\n\\infty, & \\text{if } &1<\\mathit{df}\\leq2\\\\[2ex]\n\\sqrt{\\frac{\\mathit{df}}{\\mathit{df}-2}}, & \\text{if } &\\mathit{df}>2\n\\end{cases}\n\\]\nIn empirical data analyses, the df will almost always be higher than 2 since the sample size for most analyses will be \\(n\\geq3\\). Memorizing these formulas is not important (you an always look them up on Wikipedia), the important thing to see is that when df gets bigger the SE becomes approximately 1.\n\nWhen you report t-values or give information about a t-distribution, you should always report the degrees-of-freedom.\n\n\n\n\n7.2.2 The t-Distribution for the Teen Sleep Example\nNow that we understand a bit more about the properties of the t-distribution, we can sketch the t-distribution for the teen sleep example. Recall that the sample size for the observed data was \\(n=75\\). The df for the resulting t-distribution is:\n\\[\n\\begin{split}\n\\mathit{df} &= 75 - 1 \\\\[1ex]\n&= 74\n\\end{split}\n\\]\nThis helps us think about the properties for this t-distribution:\n\nThe distribution is unimodal and symmetric.\nThe mean (center) of the t-distribution is 0.\nThe SD of this t-distribution (the SE) is \\(\\sqrt{\\frac{74}{74-2}}=1.014\\).\n\nUsing these properties, we can sketch this t-distribution. We can also add the observed t-value of \\(-8.82\\) into the distribution. (Note: We will have to go out about 9 SEs from the center value of 0 to place the observed t-value onto the distribution!)\n\n\n\n\n\nFigure 7.6: Sketch of the t-distribution with 74 degrees-of-freedom. The observed value (purple dot) of -8.82 is also shown. The shaded blue area indicates the magnitude of t-values that would be expected if the null hypothesis is true.\n\n\n\n\nBeing able to create this sketch helps us understand how the observed data fit with or don’t fit with the null hypothesis. It also helps us understand the mechanics of what the computations for the t-test actually mean. In practice, you would not create this distribution for a manuscript, but rather report the pertinent information from these computations, namely the t-value, and the df for the t-distribution. In our example, we might report this as:\n\n\\(t(74)=-8.82\\)\n\nThis small amount of information allows another researcher to re-create the sketch of the t-distribution that we made in Figure 7.6. We can also see that the observed data is not very consistent with the null hypothesis. If the true mean amount of sleep for all teenagers is 9 hours, we would expect that the magnitude of an observed t-value would be between \\(-2.028\\) and \\(+2.2028\\). (The t-value of zero corresponds to an average of 9 hrs of sleep, but we expect deviation from this in a sample mean because of sampling variation.) In the data, we found a t-value of \\(-8.82\\)! This indicates that the sample mean for the observed data was 8.82 standard errors below the expected t-value of 0. Moreover, a t-value of \\(-8.82\\) is quite a bit lower than we would expect if teenagers actually average 9 hours of sleep a night."
  },
  {
    "objectID": "04-03-one-sample-test.html#quantifying-the-level-of-consistency-with-the-null-hypothesis-the-p-value",
    "href": "04-03-one-sample-test.html#quantifying-the-level-of-consistency-with-the-null-hypothesis-the-p-value",
    "title": "7  Hypothesis Testing: One-Sample t-Test",
    "section": "7.3 Quantifying the Level of Consistency with the Null Hypothesis: The p-Value",
    "text": "7.3 Quantifying the Level of Consistency with the Null Hypothesis: The p-Value\nComputing the observed t-value gives us a method for determining how far (in SE units) the sample mean for the observed data are from a mean value specified in the null hypothesis. By placing the observed t-value in the appropriate t-distribution, we can also say whether the observed data are consistent with the claim made in the null hypothesis. Applied researchers also augment this information with one more piece of evidence called the p-value.\nThe p-value provides a quantification of the probability of observing data at least as extreme as what we observed if the null hypothesis is true. In other words, with the t-value and t-distribution w can say that it is unlikely that we would observe a sample mean as small as 7.5 if teenagers really do average 9 hours of sleep a night. The p-value will take this one step further and quantify exactly how unlikely that would be.\nThe computation of the p-value is based around the alternative (research) hypothesis. Recall that the alternative hypothesis was a statement of inequality about the population mean value. In our sleep example the alternative hypotheis was:\n\\[\nH_A: \\mu < 9\n\\]\nBut it could also have been one of these other inequalities depending on the researcher’s hypothesis about how the population mean compared to 9 hours.\n\\[\n\\begin{split}\nH_A: \\mu > 9 \\\\[1ex]\nH_A: \\mu \\neq 9\n\\end{split}\n\\] In computing p-value, we have to identify values that are at least as extreme as the observed data. Extremeness varies depending on the direction of the inequality. For example in the example alternative hypothesis that we had: \\(H_A: \\mu < 9\\), a value more extreme than our observed sample mean of 7.5 would be less than 7.5. So to compute the p-value for this alternative hypothesis, w need to find:\n\\[\nP(\\bar{y} \\leq 7.5) ~~~ \\text{if the null hypothesis is true}\n\\]\nNote that \\(P(\\cdot)\\) is the notation to indicate the probability of whatever is in the parentheses. In our case we are finding the probability of a sample mean (\\(\\bar{y}\\)) that is at least as extreme as the one we saw in our observed data (7.5) where extreme is defined in the alternative hypothesis (\\(\\leq\\)).\nTo find this probability we have to go back to the null distribution—which is based on the null hypothesis being true. (The probability defined above assumed the null hypothesis to be true.) We then need to identify all values that are less than or equal to the observed value and find their probability within that distribution. Typically, we do this in the t-distribution, so rather than finding the probability of values less than or equal to 7.5, we need to find:\n\\[\nP(t \\leq -8.82)\n\\]\nAs an example, consider the dotplot in Figure 7.7.\n\n\n\n\n\nFigure 7.7: Dot plot of an example t-distribution. The vertical blue dashed line indicates the observed value of -8.82. The yellow dots (to the left of -8.82) are the t-values that are at least as extreme as -8.82 based the alternative hypothesis (mu < -8.82).\n\n\n\n\nThis plot shows 300 t-values that are part of a t-distribution created by assuming the null hypothesis was true. Of these 300 t-values, only 2 of them are less than or equal to the observed value of \\(-8.82\\). Thus we can compute the probability of observing data at least as extreme as what we observed as:\n\\[\n\\begin{split}\nP(t \\leq -8.82) &= \\frac{2}{300} \\\\[1ex]\n&= .007\n\\end{split}\n\\]\nThat is, if the null hypothesis is true, the probability we would observe a sample mean at least as extreme as we did is .007. (We report p-values as: p = .007) This is a very unlikely event if the null hypothesis is true. So because we did actually observe a mean this extreme, it causes us to reject the null hypothesis in favor of the alternative hypothesis. The empirical evidence does not seem consistent with teenagers getting 9 hours of sleep a night. It is more consistent with teenagers getting less than 9 hours of sleep a night, on average.\n\nRule-of-Thumb: A p-value that is less than .05 usually is evidence against the null hypothesis in favor of the alternative hypothesis. In contrast, a p-value that is .05 or higher means that the evidence is consistent with the null hypothesis.\nBeing consistent with the null hypothesis does not mean that the null hypothesis is necessarily true, but rather that it could be true. Because of this, if \\(p \\geq .05\\) we never “accept the null hypothesis”, but instead we “fail to reject the null hypothesis”.\n\n\n\n7.3.1 Computing the p-Value for Other Alternative Hypotheses\nIn the example, we computed the p-value based on the alternative hypothesis, \\(H_A:\\mu<9\\). To do this we counted the cases in the t-distribution that were more extreme than our observed t-value of \\(-8.82\\), which in this alternative hypothesis corresponded to the t-values that were less than or equal to \\(-8.82\\) and computed a probability (proportion) by dividing by the total number of values in the distribution. To compute this for other null hypotheses, we do the same thing, but we have to re-define extreme.\nFor example if we had the alternative hypothesis \\(H_A:\\mu>9\\), values at least as extreme as \\(-8.82\\) correspond to all the values that are greater than or equal to \\(-8.82\\). These are shown a the yellow cases in the distribution below.\n\n\n\n\n\nFigure 7.8: Dot plot of an example t-distribution. The vertical blue dashed line indicates the observed value of -8.82. The yellow dots (to the right of -8.82) are the t-values that are at least as extreme as -8.82 based the alternative hypothesis (mu > -8.82).\n\n\n\n\nBased on this alternative hypothesis, we would have counted 298 cases that have a t-value greater than or equal to \\(-8.82\\). Based on this alternative hypothesis, the p-value would be computed as:\n\\[\n\\begin{split}\np &= \\frac{298}{300} \\\\[1ex]\n&= .993\n\\end{split}\n\\]\nThis level of evidence does not support the alternative hypothesis since the p-value is not less than .05. Because of this, we do not think the average amount of sleep teenagers get a night is greater than 9 hours. The empirical evidence doesn’t support this. However, it isn’t clear from this test that the empirical evidence supports that students get 9 hours of sleep (i.e., \\(\\mu=9\\)); it may be they are getting less than 9 hours of sleep (\\(\\mu<9\\)). That is why we cannot accept the null hypothesis that \\(\\mu=9\\). The test has only ruled out values for \\(\\mu\\) that are greater than 9 hours; the mean actually being 9 hours is only one possibility of many that remain after we eliminate those values greater than 9!\nAnother potential alternative hypothesis that a researcher might have is \\(H_A:\\mu\\neq9\\). In this research hypothesis the researcher is not positing a direction—they are just saying we think it differs from 9 hours; it might be higher, it might be lower. What this means for identifying cases in the t-distribution that are at least as extreme as \\(-8.82\\) is that we have to identify all values less than or equal to \\(-8.82\\) AND all values greater than or equal to \\(+8.82\\). These are shown a the yellow cases in the distribution below.\n\n\n\n\n\nFigure 7.9: Dot plot of an example t-distribution. The vertical blue dashed lines indicates the observed value of -8.82 and its counterpart at +8.82. The yellow dots (to the left of -8.82 and to the right of +8.82) are the t-values that are at least as extreme as -8.82 based the alternative hypothesis (mu ≠ -8.82).\n\n\n\n\nBased on this alternative hypothesis, we would have counted 4 cases that have a t-value at least as extreme as \\(-8.82\\). Based on this alternative hypothesis, the p-value would be computed as:\n\\[\n\\begin{split}\np &= \\frac{4}{300} \\\\[1ex]\n&= .013\n\\end{split}\n\\]\nBased on this p-value, which is less than .05, we would reject the null hypothesis in favor of the alternative hypothesis. This implies that the empirical evidence does not support the claim that teenagers get, on average, 9 hours of sleep, but rather that they get a different amount of sleep on average. Based on the results of this test, we cannot tell whether they get, on average, more or less sleep than 9 hours—only that it is likely a different amount.\n\n\n\n7.3.2 p-Values in Density Plots\nIn the previous example we have looked at to compute the p-value, the t-distribution was presented as a dotplot. This makes it easy to count the observations at least as extreme as the observed value. In most cases, the t-distribution is presented as a density plot. Because individual cases are not shown in a density plot, we need to have another method of computing the p-value hat is not based on counting.\nThe method we use with density plots is to compute the area under the density curve that corresponds to at least as extreme as the observed value. Figure 7.10 shows both the dotplot and superimposed density curve for an example t-distribution. If the alternative hypothesis was \\(H_A:\\mu<9\\), rather than counting the cases to that are less than the observed value of \\(-8.82\\), we would find the area under the curve that is less than \\(-8.82\\). This area is shaded in the figure.\n\n\n\n\n\nFigure 7.10: Dot plot of an example t-distribution wityh superimposed density. The vertical blue dashed line indicates the observed value of -8.82. The yellow dots (to the left of -8.82) are the t-values that are at least as extreme as -8.82 based the alternative hypothesis (mu < -8.82). The area under the density curve that is less than -8.82 is also shaded.\n\n\n\n\nFinding the area under the density curve requires calculus, or software. We will show you how to use R to find this area in ?sec-using-r-for-t-tests. We can, however estimate this area for a quick approximation. Since the area under the entire density curve is 1, the shaded area (p-value) is found by determining the proportion that the shaded area is of the whole curve. (Remember that a proportion is a value between 0 and 1; it is not a percent.) In this example, the shaded area is roughly .01 of the whole curve, so we would say the p-value was .01.\n\nIt is very difficult to get an accurate p-value from estimating it from the density curve, especially when the p-value is small. In practice, we always use software to obtain the p-value. However, understanding that the software is calculating the area under the density curve is useful for “gut-checking” the size of the p-value that the software gives us. For example, based on the shaded area in Figure 7.10, we would not expect a p-value of 0.5 since the shaded are is not half of the whole curve."
  },
  {
    "objectID": "04-03-one-sample-test.html#putting-it-all-together",
    "href": "04-03-one-sample-test.html#putting-it-all-together",
    "title": "7  Hypothesis Testing: One-Sample t-Test",
    "section": "7.4 Putting It All Together",
    "text": "7.4 Putting It All Together\nIt is important to not lose the forest in the trees when you are conducting a hypothesis test. We set out to answer a substantive question about whether or not teens are getting the recommended amount of sleep. All of the steps we carried out in the hypothesis test were a means to an end of actually answering this question based on the data we collected. So when we report results from the t-test, we need to not only report the pertinent statistical evidence (t-value, df, p-value), but we also need to answer the substantive/research question that drove this test in the first place. Below is an example write-up that an applied researcher might use:\n\nTo determine whether or not teens are getting the recommended amount of sleep, a one-sample t-test was used to compare the sample mean amount of sleep for 75 teens to a hypothesized population mean of 9 hours (the amount of sleep recommended by medical experts). The sample mean of 7.40 hours of sleep (SD = 1.52) was found to be inconsistent with the hypothesis that teens are getting 9 (or more) hours of sleep a night, on average; \\(t(74) = −8.82\\), \\(p = .007\\). This suggest that teens might not be getting the recommended amount of sleep every night."
  },
  {
    "objectID": "04-03-one-sample-test.html#looking-forward",
    "href": "04-03-one-sample-test.html#looking-forward",
    "title": "7  Hypothesis Testing: One-Sample t-Test",
    "section": "7.5 Looking Forward",
    "text": "7.5 Looking Forward\nIn the next chapter, we will introduce how to use R to carry out the one-sample t-test. Then in chapter ?sec-one-sample-examples, you will get you a chance to practice working through the process of carrying out a one-sample t-test.\nAs you work through these chapters, you will become more comfortable with the vocabulary and ideas that underlie hypothesis tests. This same set of vocabulary and ideas will come up again when we use hypothesis tests when we compare a sample proportion to a standard and to compare two samples. Because of this it may be useful to put together a summary of the ideas and vocabulary from this chapter that you can refer to (e.g., on a notecard). Here are some of the ideas and vocabulary that are important in hypothesis testing to get you started:\n\nStatistical inference\nNull hypothesis\nNull model\nAlternative hypothesis\nStandard error\nt-value\nt-distribution\np-value"
  }
]